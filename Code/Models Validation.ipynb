{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyNaiOKqMKPgIb3oOZHanYI5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xIX3cu15F4pe","executionInfo":{"status":"ok","timestamp":1718260848653,"user_tz":-300,"elapsed":2837,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"6deff3b0-439a-436b-bbb7-edcd267472eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from skimage.feature import hog\n","import joblib\n","import os\n","\n","# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Debug: Print column names to ensure they are correct\n","print(\"Columns in the DataFrame:\", df.columns)\n","\n","# Filter the dataset to include only rows where \"Key_Frame\" is 'Y' and 'General Percentage' is between 0 and 90.0\n","if 'Key_Frame' not in df.columns or 'Frame Path' not in df.columns or 'Senti' not in df.columns or 'General Percentage' not in df.columns:\n","    raise ValueError(\"Required columns are missing from the DataFrame\")\n","\n","df = df[(df['Key_Frame'] == 'Y')]\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    if not os.path.exists(filepath):\n","        print(f\"File not found: {filepath}\")\n","        return None\n","    img = cv2.imread(filepath)\n","    if img is None:\n","        print(f\"Failed to read image: {filepath}\")\n","        return None\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = cv2.resize(img, (48, 48))\n","    img = cv2.equalizeHist(img)\n","    return img\n","\n","# Apply preprocessing to each image and prepare labels\n","images = []\n","labels = []\n","for idx, fp in enumerate(df['Frame Path']):\n","    processed_img = preprocess_image(fp)\n","    if processed_img is not None:\n","        images.append(processed_img)\n","        labels.append(df['Senti'].iloc[idx])\n","\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","# Extract HOG features from the images\n","hog_features = [hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys') for image in images]\n","X = np.array(hog_features)\n","\n","# Load the saved model\n","joblib_file = \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\"\n","loaded_rf_model = joblib.load(joblib_file)\n","\n","# Evaluate the model\n","y_pred = loaded_rf_model.predict(X)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(labels, y_pred)\n","precision = precision_score(labels, y_pred, average='weighted')\n","recall = recall_score(labels, y_pred, average='weighted')\n","f1 = f1_score(labels, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f\"Validation accuracy: {accuracy*100:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['Random Forest'],\n","    'Model Path': [joblib_file],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Save the DataFrame to a CSV file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_Sqj73IF_D-","executionInfo":{"status":"ok","timestamp":1718108289284,"user_tz":-300,"elapsed":11095,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"0f0318f3-f97b-4071-c050-57c2e56cc736"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in the DataFrame: Index(['Video Name', 'Frame Path', 'Time in Seconds', 'Key_Frame',\n","       'Positive Sentiment', 'Negative Sentiment', 'key_frame', 'Senti',\n","       'General Percentage'],\n","      dtype='object')\n","Validation accuracy: 25.55%\n","Precision: 0.78\n","Recall: 0.26\n","F1 Score: 0.35\n","Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file\n","results_df = pd.read_csv('/content/drive/MyDrive/work2/Final/validation_results.csv')\n","\n","# Show the first 5 rows\n","results_df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"AVRGH0mpHYTH","executionInfo":{"status":"ok","timestamp":1718109235388,"user_tz":-300,"elapsed":391,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"dcb6a7ea-ac6c-4587-8610-066cdf72cd03"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Model Name                                         Model Path  Accuracy  \\\n","0  Random Forest  /content/drive/MyDrive/work2/Final/Image_Model...  0.255528   \n","1    MobileNetV2  /content/drive/MyDrive/work2/Final/Image_Model...  0.366914   \n","\n","   Precision    Recall  F1 Score  \n","0   0.783576  0.255528  0.350567  \n","1   0.346832  0.366914  0.329704  "],"text/html":["\n","  <div id=\"df-42805a0b-7edc-4ca8-9fcc-9cc55706e9bd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Model Path</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.255528</td>\n","      <td>0.783576</td>\n","      <td>0.255528</td>\n","      <td>0.350567</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MobileNetV2</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.366914</td>\n","      <td>0.346832</td>\n","      <td>0.366914</td>\n","      <td>0.329704</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42805a0b-7edc-4ca8-9fcc-9cc55706e9bd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-42805a0b-7edc-4ca8-9fcc-9cc55706e9bd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-42805a0b-7edc-4ca8-9fcc-9cc55706e9bd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b94e93e5-9c9b-4054-af85-bd9face26c30\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b94e93e5-9c9b-4054-af85-bd9face26c30')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b94e93e5-9c9b-4054-af85-bd9face26c30 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"MobileNetV2\",\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5\",\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07876131843322867,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.3669135802469135,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3669135802469135,\n          0.2555282555282555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3088244953133305,\n        \"min\": 0.3468322544366896,\n        \"max\": 0.7835760441018279,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3468322544366896,\n          0.7835760441018279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07876131843322867,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.3669135802469135,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3669135802469135,\n          0.2555282555282555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01475302060664578,\n        \"min\": 0.3297035133944206,\n        \"max\": 0.3505674352223088,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3297035133944206,\n          0.3505674352223088\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from tensorflow.keras.utils import to_categorical\n","import os\n","\n","# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    if not os.path.exists(filepath):\n","        print(f\"File not found: {filepath}\")\n","        return None\n","    img = cv2.imread(filepath)\n","    if img is None:\n","        print(f\"Failed to read image: {filepath}\")\n","        return None\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img, (224, 224))  # Resize to match MobileNetV2 input\n","    img = preprocess_input(img)  # Preprocess as per MobileNetV2 requirements\n","    return img\n","\n","# Apply preprocessing to each image and prepare labels\n","images = []\n","labels = []\n","for idx, fp in enumerate(df['Frame Path']):\n","    processed_img = preprocess_image(fp)\n","    if processed_img is not None:\n","        images.append(processed_img)\n","        labels.append(df['Senti'].iloc[idx])\n","\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","# One-hot encode labels for categorical crossentropy\n","labels = to_categorical(labels, num_classes=3)\n","\n","# Load the saved TensorFlow model\n","model_path = '/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5'\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# Evaluate the loaded model on the entire dataset\n","test_loss, test_accuracy = loaded_model.evaluate(images, labels)\n","print(f\"Validation Loss: {test_loss}, Validation Accuracy: {test_accuracy}\")\n","\n","# Make predictions\n","y_pred_prob = loaded_model.predict(images)\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","y_true = np.argmax(labels, axis=1)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_true, y_pred)\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f\"Accuracy: {accuracy*100:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['MobileNetV2'],\n","    'Model Path': [model_path],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqcmVccQQTGv","executionInfo":{"status":"ok","timestamp":1718109164947,"user_tz":-300,"elapsed":422992,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"fbdf5dee-485d-442a-c02a-995826388a8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["64/64 [==============================] - 77s 1s/step - loss: 1.7751 - accuracy: 0.3669\n","Validation Loss: 1.775099754333496, Validation Accuracy: 0.3669135868549347\n","64/64 [==============================] - 74s 1s/step\n","Accuracy: 36.69%\n","Precision: 0.35\n","Recall: 0.37\n","F1 Score: 0.33\n","Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n"]}]},{"cell_type":"code","source":["import librosa\n","import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import StandardScaler\n","import joblib\n","\n","# Function to extract audio features\n","def extract_features(file_path):\n","    y, sr = librosa.load(file_path)\n","    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n","    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n","    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n","    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n","    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr), axis=1)\n","    return np.concatenate((mfccs, chroma, mel, spectral_contrast, tonnetz))\n","\n","# Folder containing audio files\n","audio_folder = '/content/drive/MyDrive/work2/Validation_Data/Audios'\n","\n","# List to store audio file paths and sentiment labels\n","file_paths = []\n","sentiments = []\n","\n","# Iterate through files in the folder and extract sentiment labels\n","for file_name in os.listdir(audio_folder):\n","    if os.path.isfile(os.path.join(audio_folder, file_name)):\n","        file_paths.append(os.path.join(audio_folder, file_name))\n","\n","# Read sentiment labels from a CSV file\n","csv_path = '/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv'\n","df = pd.read_csv(csv_path)\n","sentiments = df['Senti'].tolist()\n","\n","# Create a dataset (X, y) with features and labels\n","X = [extract_features(path) for path in file_paths]\n","y = sentiments\n","\n","# Load the scaler\n","scaler_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest_Scaler.joblib'\n","scaler = joblib.load(scaler_path)\n","\n","# Standardize the features\n","X_scaled = scaler.transform(X)\n","\n","# Load the saved model\n","model_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest.joblib'\n","loaded_model = joblib.load(model_path)\n","\n","# Evaluate the loaded model\n","y_pred = loaded_model.predict(X_scaled)\n","accuracy = accuracy_score(y, y_pred)\n","precision = precision_score(y, y_pred, average='weighted')\n","recall = recall_score(y, y_pred, average='weighted')\n","f1 = f1_score(y, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f\"Accuracy: {accuracy*100:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['Audio Sentiment RF'],\n","    'Model Path': [model_path],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLAAycocS7go","executionInfo":{"status":"ok","timestamp":1718111194332,"user_tz":-300,"elapsed":181673,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"ea3451ac-cda2-45e5-a160-d8a9cf832ab4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 34.48%\n","Precision: 0.25\n","Recall: 0.34\n","F1 Score: 0.26\n","Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","import joblib\n","import os\n","import librosa\n","\n","# Function to extract features from audio files\n","def extract_features(file_path):\n","    y, sr = librosa.load(file_path, duration=3)\n","    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n","    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n","    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n","    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n","    features = np.mean(np.concatenate((mfccs, chroma, mel, contrast), axis=0), axis=1)\n","    return features\n","\n","# Folder containing audio files\n","audio_folder = '/content/drive/MyDrive/work2/Validation_Data/Audios'\n","\n","# List to store audio file paths and sentiment labels\n","file_names = []\n","senti_values = []\n","\n","# Iterate through files in the folder\n","for file_name in os.listdir(audio_folder):\n","    if os.path.isfile(os.path.join(audio_folder, file_name)):\n","        file_names.append(os.path.join(audio_folder, file_name))\n","\n","# Load sentiment labels from a CSV file\n","csv_path = '/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv'\n","df = pd.read_csv(csv_path)\n","senti_values = df['Senti'].tolist()\n","\n","# Create a dataset (X, y) with features and labels\n","X = np.array([extract_features(path) for path in file_names])\n","y = np.array(senti_values)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","\n","# Load the scaler\n","scaler_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_1_LSTM_Scaler.pkl'\n","scaler = joblib.load(scaler_path)\n","\n","# Standardize the features\n","X_scaled = scaler.transform(X)\n","\n","# Reshape for LSTM input\n","X_scaled = np.expand_dims(X_scaled, -1)\n","\n","# Load the saved best model\n","model_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_1_LSTM.h5'\n","best_model = tf.keras.models.load_model(model_path)\n","\n","# Evaluate the loaded model on the entire dataset\n","loss, accuracy = best_model.evaluate(X_scaled, y)\n","print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")\n","\n","# Make predictions\n","y_pred_prob = best_model.predict(X_scaled)\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y, y_pred)\n","precision = precision_score(y, y_pred, average='weighted')\n","recall = recall_score(y, y_pred, average='weighted')\n","f1 = f1_score(y, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f\"Accuracy: {accuracy*100:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['LSTM'],\n","    'Model Path': [model_path],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8Uj6wBtWh6B","executionInfo":{"status":"ok","timestamp":1718111199424,"user_tz":-300,"elapsed":5094,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"d84103ed-d148-4eb3-e93b-9a453365658b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 946ms/step - loss: 1.1071 - accuracy: 0.3103\n","Validation Loss: 1.107116460800171, Validation Accuracy: 0.3103448152542114\n","1/1 [==============================] - 1s 870ms/step\n","Accuracy: 31.03%\n","Precision: 0.25\n","Recall: 0.31\n","F1 Score: 0.26\n","Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file\n","results_df = pd.read_csv('/content/drive/MyDrive/work2/Final/updated_validation_results.csv')\n","\n","# Show the first 5 rows\n","results_df.head(10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"UmP3vEdiaixS","executionInfo":{"status":"ok","timestamp":1718111525531,"user_tz":-300,"elapsed":374,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"31e898a9-20d7-4bc9-86da-99481cdde85a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Model Name                                         Model Path  \\\n","0       Random Forest  /content/drive/MyDrive/work2/Final/Image_Model...   \n","1         MobileNetV2  /content/drive/MyDrive/work2/Final/Image_Model...   \n","2  Audio Sentiment RF  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","3                LSTM  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","\n","   Accuracy  Precision    Recall  F1 Score  \n","0  0.255528   0.783576  0.255528  0.350567  \n","1  0.366914   0.346832  0.366914  0.329704  \n","2  0.344828   0.247126  0.344828  0.257313  \n","3  0.310345   0.249390  0.310345  0.264791  "],"text/html":["\n","  <div id=\"df-b2dfc335-a01d-48ea-a440-c64ec2301808\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Model Path</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.255528</td>\n","      <td>0.783576</td>\n","      <td>0.255528</td>\n","      <td>0.350567</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MobileNetV2</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.366914</td>\n","      <td>0.346832</td>\n","      <td>0.366914</td>\n","      <td>0.329704</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Audio Sentiment RF</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.344828</td>\n","      <td>0.247126</td>\n","      <td>0.344828</td>\n","      <td>0.257313</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LSTM</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.310345</td>\n","      <td>0.249390</td>\n","      <td>0.310345</td>\n","      <td>0.264791</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2dfc335-a01d-48ea-a440-c64ec2301808')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b2dfc335-a01d-48ea-a440-c64ec2301808 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b2dfc335-a01d-48ea-a440-c64ec2301808');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cdf901bc-9b4b-492e-8dbd-e7a55c471f3a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdf901bc-9b4b-492e-8dbd-e7a55c471f3a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cdf901bc-9b4b-492e-8dbd-e7a55c471f3a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"MobileNetV2\",\n          \"LSTM\",\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5\",\n          \"/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_1_LSTM.h5\",\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04853074038426176,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.3669135802469135,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3669135802469135,\n          0.3103448275862069,\n          0.2555282555282555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2554927985154997,\n        \"min\": 0.2471264367816091,\n        \"max\": 0.7835760441018279,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3468322544366896,\n          0.2493904562870079,\n          0.7835760441018279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04853074038426176,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.3669135802469135,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3669135802469135,\n          0.3103448275862069,\n          0.2555282555282555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.046546946015813245,\n        \"min\": 0.2573127229488703,\n        \"max\": 0.3505674352223088,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3297035133944206,\n          0.2647906815822858,\n          0.3505674352223088\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import plotly.graph_objs as go\n","from plotly.subplots import make_subplots\n","\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv\", encoding='utf-8')\n","\n","\n","# Tokenize the reviews using BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model')\n","\n","# Tokenize and encode the reviews\n","input_ids = []\n","attention_masks = []\n","\n","for review in df['Sentence']:\n","    encoded_dict = tokenizer.encode_plus(\n","        review,\n","        add_special_tokens=True,\n","        max_length=64,\n","        truncation=True,  # Explicitly activate truncation\n","        padding='max_length',  # Pad to the max_length\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","# Do the same for df1\n","input_ids1 = []\n","attention_masks1 = []\n","\n","for review in df1['Sentence']:\n","    encoded_dict = tokenizer.encode_plus(\n","        review,\n","        add_special_tokens=True,\n","        max_length=64,\n","        truncation=True,  # Explicitly activate truncation\n","        padding='max_length',  # Pad to the max_length\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","    input_ids1.append(encoded_dict['input_ids'])\n","    attention_masks1.append(encoded_dict['attention_mask'])\n","\n","input_ids1 = torch.cat(input_ids1, dim=0)\n","attention_masks1 = torch.cat(attention_masks1, dim=0)\n","\n","# Load the labels\n","labels = torch.tensor(df['Label'])\n","labels1 = torch.tensor(df1['Label'])\n","\n","# Concatenate inputs and labels\n","input_ids = torch.cat((input_ids, input_ids1), dim=0)\n","attention_masks = torch.cat((attention_masks, attention_masks1), dim=0)\n","labels = torch.cat((labels, labels1), dim=0)\n","\n","# Split the dataset into training and validation sets\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# Create DataLoader\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# Load pre-trained BERT model for sentiment classification\n","model = BertForSequenceClassification.from_pretrained(\n","    '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model',\n","    num_labels=3,  # 3 classes: neutral, positive, negative\n","    output_attentions=False,\n","    output_hidden_states=False\n",")\n","\n","# Set up optimizer and learning rate scheduler\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","\n","# Evaluation loop\n","model.eval()\n","all_labels = []\n","all_preds = []\n","\n","for batch in val_dataloader:\n","    inputs = {\n","        'input_ids': batch[0],\n","        'attention_mask': batch[1],\n","        'labels': batch[2]\n","    }\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    logits = outputs.logits\n","    preds = np.argmax(logits.cpu().numpy(), axis=1)\n","\n","    all_labels.extend(inputs['labels'].cpu().numpy())\n","    all_preds.extend(preds)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(all_labels, all_preds)\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","\n","# Generate confusion matrix\n","conf_matrix = confusion_matrix(all_labels, all_preds)\n","print('Confusion Matrix:')\n","print(conf_matrix)\n","\n","# Print classification report\n","class_report = classification_report(all_labels, all_preds, target_names=['neutral', 'positive', 'negative'])\n","print('Classification Report:')\n","print(class_report)\n","\n","# Visualize the results\n","# Calculate precision, recall, and F1-score\n","class_report_dict = classification_report(all_labels, all_preds, target_names=['neutral', 'positive', 'negative'], output_dict=True)\n","precision = [class_report_dict[label]['precision'] for label in ['neutral', 'positive', 'negative']]\n","recall = [class_report_dict[label]['recall'] for label in ['neutral', 'positive', 'negative']]\n","f1_score = [class_report_dict[label]['f1-score'] for label in ['neutral', 'positive', 'negative']]\n","\n","# Create an interactive confusion matrix\n","fig = make_subplots(rows=2, cols=2, subplot_titles=['Confusion Matrix', 'Accuracy Bar Chart', 'Precision Bar Chart', 'Recall Bar Chart'])\n","\n","# Confusion Matrix\n","trace_heatmap = go.Heatmap(z=conf_matrix, x=['neutral', 'positive', 'negative'], y=['neutral', 'positive', 'negative'], colorscale='Viridis')\n","fig.add_trace(trace_heatmap, row=1, col=1)\n","\n","# Accuracy Bar Chart\n","trace_bar_accuracy = go.Bar(x=['Accuracy'], y=[accuracy * 100], marker=dict(color='blue'))\n","fig.add_trace(trace_bar_accuracy, row=1, col=2)\n","\n","# Precision Bar Chart\n","trace_bar_precision = go.Bar(x=['neutral', 'positive', 'negative'], y=np.round(precision, 2) * 100, marker=dict(color='green'))\n","fig.add_trace(trace_bar_precision, row=2, col=1)\n","\n","# Recall Bar Chart\n","trace_bar_recall = go.Bar(x=['neutral', 'positive', 'negative'], y=np.round(recall, 2) * 100, marker=dict(color='orange'))\n","fig.add_trace(trace_bar_recall, row=2, col=2)\n","\n","fig.update_layout(title_text='Confusion Matrix, Accuracy, Precision, and Recall', height=600, width=800)\n","fig.show()\n","\n","# Save the results to a CSV file\n","results_df = pd.DataFrame({\n","    'Model Name': ['BERT Multilingual'],\n","    'Model Path': ['/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model'],\n","    'Accuracy': [accuracy],\n","    'Precision': [np.mean(precision)],\n","    'Recall': [np.mean(recall)],\n","    'F1 Score': [np.mean(f1_score)]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"id":"Gk95B4gHcKkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import plotly.graph_objs as go\n","from plotly.subplots import make_subplots\n","\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv\", encoding='utf-8')\n","\n","# Print the column names to check for 'Sentence'\n","print(\"Columns in the DataFrame:\", df.columns)\n","\n","# Assuming the correct column names are 'Text' and 'Label' (you may need to adjust these based on the actual column names)\n","sentence_column = 'Transcription'\n","label_column = 'Senti'\n","\n","# Tokenize the reviews using BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model')\n","\n","# Tokenize and encode the reviews\n","input_ids = []\n","attention_masks = []\n","\n","for review in df[sentence_column]:\n","    encoded_dict = tokenizer.encode_plus(\n","        review,\n","        add_special_tokens=True,\n","        max_length=64,\n","        truncation=True,  # Explicitly activate truncation\n","        padding='max_length',  # Pad to the max_length\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","# Load the labels\n","labels = torch.tensor(df[label_column].values)\n","\n","# Create a dataset\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create DataLoader\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n","\n","# Load pre-trained BERT model for sentiment classification\n","model = BertForSequenceClassification.from_pretrained(\n","    '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model',\n","    num_labels=3,  # 3 classes: neutral, positive, negative\n","    output_attentions=False,\n","    output_hidden_states=False\n",")\n","\n","# Evaluation loop\n","model.eval()\n","all_labels = []\n","all_preds = []\n","\n","for batch in dataloader:\n","    inputs = {\n","        'input_ids': batch[0],\n","        'attention_mask': batch[1],\n","        'labels': batch[2]\n","    }\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    logits = outputs.logits\n","    preds = np.argmax(logits.cpu().numpy(), axis=1)\n","\n","    all_labels.extend(inputs['labels'].cpu().numpy())\n","    all_preds.extend(preds)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(all_labels, all_preds)\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","\n","# Generate confusion matrix\n","conf_matrix = confusion_matrix(all_labels, all_preds)\n","print('Confusion Matrix:')\n","print(conf_matrix)\n","\n","# Print classification report\n","class_report = classification_report(all_labels, all_preds, target_names=['neutral', 'positive', 'negative'])\n","print('Classification Report:')\n","print(class_report)\n","\n","# Visualize the results\n","# Calculate precision, recall, and F1-score\n","class_report_dict = classification_report(all_labels, all_preds, target_names=['neutral', 'positive', 'negative'], output_dict=True)\n","precision = [class_report_dict[label]['precision'] for label in ['neutral', 'positive', 'negative']]\n","recall = [class_report_dict[label]['recall'] for label in ['neutral', 'positive', 'negative']]\n","f1 = [class_report_dict[label]['f1-score'] for label in ['neutral', 'positive', 'negative']]\n","\n","# Create an interactive confusion matrix\n","fig = make_subplots(rows=2, cols=2, subplot_titles=['Confusion Matrix', 'Accuracy Bar Chart', 'Precision Bar Chart', 'Recall Bar Chart'])\n","\n","# Confusion Matrix\n","trace_heatmap = go.Heatmap(z=conf_matrix, x=['neutral', 'positive', 'negative'], y=['neutral', 'positive', 'negative'], colorscale='Viridis')\n","fig.add_trace(trace_heatmap, row=1, col=1)\n","\n","# Accuracy Bar Chart\n","trace_bar_accuracy = go.Bar(x=['Accuracy'], y=[accuracy * 100], marker=dict(color='blue'))\n","fig.add_trace(trace_bar_accuracy, row=1, col=2)\n","\n","# Precision Bar Chart\n","trace_bar_precision = go.Bar(x=['neutral', 'positive', 'negative'], y=np.round(precision, 2) * 100, marker=dict(color='green'))\n","fig.add_trace(trace_bar_precision, row=2, col=1)\n","\n","# Recall Bar Chart\n","trace_bar_recall = go.Bar(x=['neutral', 'positive', 'negative'], y=np.round(recall, 2) * 100, marker=dict(color='orange'))\n","fig.add_trace(trace_bar_recall, row=2, col=2)\n","\n","fig.update_layout(title_text='Confusion Matrix, Accuracy, Precision, and Recall', height=600, width=800)\n","fig.show()\n","\n","# Save the results to a CSV file\n","results_df = pd.DataFrame({\n","    'Model Name': ['BERT Multilingual'],\n","    'Model Path': ['/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model'],\n","    'Accuracy': [accuracy],\n","    'Precision': [np.mean(precision)],\n","    'Recall': [np.mean(recall)],\n","    'F1 Score': [np.mean(f1)]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":999},"id":"oimEu-X4c2Vj","executionInfo":{"status":"ok","timestamp":1718112141501,"user_tz":-300,"elapsed":21578,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"12d8ad36-b521-4bc4-d4fb-e9dfc2b7692e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in the DataFrame: Index(['File', 'Transcription', 'Status', 'Length', 'WordCount',\n","       'negative_count', 'positive_count', 'negative_positions',\n","       'positive_positions', 'Senti', 'Negative_Frame_Sentiments',\n","       'Positive_Frame_Sentiments'],\n","      dtype='object')\n","Accuracy: 41.38%\n","Confusion Matrix:\n","[[1 5 3]\n"," [0 4 4]\n"," [1 4 7]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","     neutral       0.50      0.11      0.18         9\n","    positive       0.31      0.50      0.38         8\n","    negative       0.50      0.58      0.54        12\n","\n","    accuracy                           0.41        29\n","   macro avg       0.44      0.40      0.37        29\n","weighted avg       0.45      0.41      0.38        29\n","\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"3a54b038-8cfe-421e-8964-cc0c493f1c76\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a54b038-8cfe-421e-8964-cc0c493f1c76\")) {                    Plotly.newPlot(                        \"3a54b038-8cfe-421e-8964-cc0c493f1c76\",                        [{\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"x\":[\"neutral\",\"positive\",\"negative\"],\"y\":[\"neutral\",\"positive\",\"negative\"],\"z\":[[1,5,3],[0,4,4],[1,4,7]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"blue\"},\"x\":[\"Accuracy\"],\"y\":[41.37931034482759],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"green\"},\"x\":[\"neutral\",\"positive\",\"negative\"],\"y\":[50.0,31.0,50.0],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"orange\"},\"x\":[\"neutral\",\"positive\",\"negative\"],\"y\":[11.0,50.0,57.99999999999999],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Confusion Matrix\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy Bar Chart\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Precision Bar Chart\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Recall Bar Chart\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Confusion Matrix, Accuracy, Precision, and Recall\"},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('3a54b038-8cfe-421e-8964-cc0c493f1c76');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file\n","results_df = pd.read_csv('/content/drive/MyDrive/work2/Final/validation_results.csv')\n","\n","# Show the first 5 rows\n","results_df.head(10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"h9x8P3K2fKn5","executionInfo":{"status":"ok","timestamp":1718112548330,"user_tz":-300,"elapsed":568,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"1773f099-e146-4ef4-8751-616a2991825f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Model Name                                         Model Path  \\\n","0       Random Forest  /content/drive/MyDrive/work2/Final/Image_Model...   \n","1         MobileNetV2  /content/drive/MyDrive/work2/Final/Image_Model...   \n","2  Audio Sentiment RF  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","3                LSTM  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","4   BERT Multilingual  /content/drive/MyDrive/work2/Final/Text_Work/T...   \n","\n","   Accuracy  Precision    Recall  F1 Score  \n","0  0.255528   0.783576  0.255528  0.350567  \n","1  0.366914   0.346832  0.366914  0.329704  \n","2  0.344828   0.247126  0.344828  0.257313  \n","3  0.310345   0.249390  0.310345  0.264791  \n","4  0.413793   0.435897  0.398148  0.367077  "],"text/html":["\n","  <div id=\"df-e6c44c7d-36f5-4ab0-bb39-d9802d535df7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Model Path</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.255528</td>\n","      <td>0.783576</td>\n","      <td>0.255528</td>\n","      <td>0.350567</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MobileNetV2</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.366914</td>\n","      <td>0.346832</td>\n","      <td>0.366914</td>\n","      <td>0.329704</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Audio Sentiment RF</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.344828</td>\n","      <td>0.247126</td>\n","      <td>0.344828</td>\n","      <td>0.257313</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LSTM</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.310345</td>\n","      <td>0.249390</td>\n","      <td>0.310345</td>\n","      <td>0.264791</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BERT Multilingual</td>\n","      <td>/content/drive/MyDrive/work2/Final/Text_Work/T...</td>\n","      <td>0.413793</td>\n","      <td>0.435897</td>\n","      <td>0.398148</td>\n","      <td>0.367077</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6c44c7d-36f5-4ab0-bb39-d9802d535df7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e6c44c7d-36f5-4ab0-bb39-d9802d535df7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e6c44c7d-36f5-4ab0-bb39-d9802d535df7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-90a5c198-9184-4e7d-af6e-d93057218eea\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90a5c198-9184-4e7d-af6e-d93057218eea')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-90a5c198-9184-4e7d-af6e-d93057218eea button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MobileNetV2\",\n          \"BERT Multilingual\",\n          \"Audio Sentiment RF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5\",\n          \"/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model\",\n          \"/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest.joblib\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.059567622613662906,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.4137931034482758,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3669135802469135,\n          0.4137931034482758,\n          0.3448275862068966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22164737826348763,\n        \"min\": 0.2471264367816091,\n        \"max\": 0.7835760441018279,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3468322544366896,\n          0.4358974358974359,\n          0.2471264367816091\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054832166917447196,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.3981481481481482,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3669135802469135,\n          0.3981481481481482,\n          0.3448275862068966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05008974152458094,\n        \"min\": 0.2573127229488703,\n        \"max\": 0.3670773670773671,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3297035133944206,\n          0.3670773670773671,\n          0.2573127229488703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import re\n","import nltk\n","import joblib\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from google.colab import drive\n","\n","# Function to remove unwanted characters\n","def removing_unwanted_data(text):\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\<a href', ' ', text)\n","    text = re.sub(r'&amp;', '', text)\n","    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n","    text = re.sub(r'<br />', ' ', text)\n","    text = re.sub(r'\\'', ' ', text)\n","    text = nltk.WordPunctTokenizer().tokenize(text)\n","    return text\n","\n","# Custom tokenizer function\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv\", encoding='utf-8')\n","\n","# Apply preprocessing\n","df['text_cleaned'] = df['Transcription'].map(removing_unwanted_data)\n","\n","# Load the saved vectorizer and model\n","vectorizer_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl'\n","model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl'\n","\n","vectorizer = joblib.load(vectorizer_path)\n","model = joblib.load(model_path)\n","\n","# Transform the data using the loaded vectorizer\n","X = vectorizer.transform(df['Transcription'])\n","y = df['Senti']\n","\n","# Evaluate the loaded model on the complete dataset\n","y_pred = model.predict(X)\n","accuracy = accuracy_score(y, y_pred)\n","precision = precision_score(y, y_pred, average='weighted')\n","recall = recall_score(y, y_pred, average='weighted')\n","f1 = f1_score(y, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['BOW Logistic Regression'],\n","    'Model Path': [model_path],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","\n","# Check if the results file exists and handle the append operation correctly\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    updated_df = pd.concat([existing_df, results_df], ignore_index=True)\n","    updated_df.to_csv(results_file, index=False)\n","else:\n","    results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQFOWOs4c4co","executionInfo":{"status":"ok","timestamp":1718112984229,"user_tz":-300,"elapsed":1299,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"43e8b917-c3d7-4c7a-fbb8-9df4db9f8965"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 41.38%\n","Precision: 0.17\n","Recall: 0.41\n","F1 Score: 0.24\n","Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file\n","results_df = pd.read_csv('/content/drive/MyDrive/work2/Final/validation_results.csv')\n","\n","# Show the first 5 rows\n","results_df.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"YUMPSmTZglcE","executionInfo":{"status":"ok","timestamp":1718112999244,"user_tz":-300,"elapsed":455,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"3e84dfd3-27cb-47a3-f13c-ae3d8bdaf36e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                Model Name                                         Model Path  \\\n","0            Random Forest  /content/drive/MyDrive/work2/Final/Image_Model...   \n","1              MobileNetV2  /content/drive/MyDrive/work2/Final/Image_Model...   \n","2       Audio Sentiment RF  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","3                     LSTM  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","4        BERT Multilingual  /content/drive/MyDrive/work2/Final/Text_Work/T...   \n","5  BOW Logistic Regression  /content/drive/MyDrive/work2/Final/Text_Work/T...   \n","\n","   Accuracy  Precision    Recall  F1 Score  \n","0  0.255528   0.783576  0.255528  0.350567  \n","1  0.366914   0.346832  0.366914  0.329704  \n","2  0.344828   0.247126  0.344828  0.257313  \n","3  0.310345   0.249390  0.310345  0.264791  \n","4  0.413793   0.435897  0.398148  0.367077  \n","5  0.413793   0.171225  0.413793  0.242220  "],"text/html":["\n","  <div id=\"df-9b6c36f2-5ab7-4e24-b716-edb1368d9c76\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Model Path</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.255528</td>\n","      <td>0.783576</td>\n","      <td>0.255528</td>\n","      <td>0.350567</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MobileNetV2</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.366914</td>\n","      <td>0.346832</td>\n","      <td>0.366914</td>\n","      <td>0.329704</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Audio Sentiment RF</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.344828</td>\n","      <td>0.247126</td>\n","      <td>0.344828</td>\n","      <td>0.257313</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LSTM</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.310345</td>\n","      <td>0.249390</td>\n","      <td>0.310345</td>\n","      <td>0.264791</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BERT Multilingual</td>\n","      <td>/content/drive/MyDrive/work2/Final/Text_Work/T...</td>\n","      <td>0.413793</td>\n","      <td>0.435897</td>\n","      <td>0.398148</td>\n","      <td>0.367077</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>BOW Logistic Regression</td>\n","      <td>/content/drive/MyDrive/work2/Final/Text_Work/T...</td>\n","      <td>0.413793</td>\n","      <td>0.171225</td>\n","      <td>0.413793</td>\n","      <td>0.242220</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b6c36f2-5ab7-4e24-b716-edb1368d9c76')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9b6c36f2-5ab7-4e24-b716-edb1368d9c76 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9b6c36f2-5ab7-4e24-b716-edb1368d9c76');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c8b87c00-1469-4638-b870-b39485d6285a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8b87c00-1469-4638-b870-b39485d6285a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c8b87c00-1469-4638-b870-b39485d6285a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Random Forest\",\n          \"MobileNetV2\",\n          \"BOW Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\",\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5\",\n          \"/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06155465685248495,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.4137931034482758,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3669135802469135,\n          0.4137931034482758,\n          0.3448275862068966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22138096316137532,\n        \"min\": 0.1712247324613555,\n        \"max\": 0.7835760441018279,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7835760441018279,\n          0.3468322544366896,\n          0.1712247324613555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.058617214574315034,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.4137931034482758,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.2555282555282555,\n          0.3669135802469135,\n          0.4137931034482758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053509659830534836,\n        \"min\": 0.2422203532380151,\n        \"max\": 0.3670773670773671,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.3505674352223088,\n          0.3297035133944206,\n          0.2422203532380151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import re\n","import nltk\n","import joblib\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import os\n","\n","# Function to remove unwanted characters\n","def removing_unwanted_data(text):\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\<a href', ' ', text)\n","    text = re.sub(r'&amp;', '', text)\n","    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n","    text = re.sub(r'<br />', ' ', text)\n","    text = re.sub(r'\\'', ' ', text)\n","    text = nltk.WordPunctTokenizer().tokenize(text)\n","    return text\n","\n","# Custom tokenizer function\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv\", encoding='utf-8')\n","\n","# Apply preprocessing\n","df['text_cleaned'] = df['Transcription'].map(removing_unwanted_data)\n","\n","# Load the saved vectorizer and model\n","vectorizer_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl'\n","model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl'\n","\n","vectorizer = joblib.load(vectorizer_path)\n","model = joblib.load(model_path)\n","\n","# Transform the data using the loaded vectorizer\n","X = vectorizer.transform(df['Transcription'])\n","y = df['Senti']\n","\n","# Evaluate the loaded model on the complete dataset\n","y_pred = model.predict(X)\n","accuracy = accuracy_score(y, y_pred)\n","precision = precision_score(y, y_pred, average='weighted')\n","recall = recall_score(y, y_pred, average='weighted')\n","f1 = f1_score(y, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['BOW Logistic Regression'],\n","    'Model Path': [model_path],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","max_accuracy_file = '/content/drive/MyDrive/work2/Final/max_accuracy.txt'\n","\n","# Check if the results file exists and handle the append operation correctly\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    updated_df = pd.concat([existing_df, results_df], ignore_index=True)\n","    updated_df.to_csv(results_file, index=False)\n","else:\n","    results_df.to_csv(results_file, index=False)\n","\n","# Update max accuracy if necessary\n","max_accuracy = accuracy\n","if os.path.exists(max_accuracy_file):\n","    with open(max_accuracy_file, 'r') as file:\n","        max_accuracy = max(max_accuracy, float(file.read()))\n","\n","with open(max_accuracy_file, 'w') as file:\n","    file.write(str(max_accuracy))\n","\n","print(f\"Results saved to {results_file}\")\n","print(f\"Maximum accuracy: {max_accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6E4X5meKg9G4","executionInfo":{"status":"ok","timestamp":1718113362819,"user_tz":-300,"elapsed":397,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"697e4e02-cf25-4855-ee79-a0dbec2ed1f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 41.38%\n","Precision: 0.17\n","Recall: 0.41\n","F1 Score: 0.24\n","Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n","Maximum accuracy: 41.38%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n","\n","Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import re\n","import nltk\n","import joblib\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import os\n","\n","# Function to remove unwanted characters\n","def removing_unwanted_data(text):\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\<a href', ' ', text)\n","    text = re.sub(r'&amp;', '', text)\n","    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n","    text = re.sub(r'<br />', ' ', text)\n","    text = re.sub(r'\\'', ' ', text)\n","    text = nltk.WordPunctTokenizer().tokenize(text)\n","    return text\n","\n","# Custom tokenizer function\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Load your dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv\", encoding='utf-8')\n","\n","# Apply preprocessing\n","df['text_cleaned'] = df['Transcription'].map(removing_unwanted_data)\n","\n","# Load the saved vectorizer and model\n","vectorizer_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl'\n","model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl'\n","\n","vectorizer = joblib.load(vectorizer_path)\n","model = joblib.load(model_path)\n","\n","# Transform the data using the loaded vectorizer\n","X = vectorizer.transform(df['Transcription'])\n","y = df['Senti']\n","\n","# Evaluate the loaded model on the complete dataset\n","y_pred = model.predict(X)\n","accuracy = accuracy_score(y, y_pred)\n","precision = precision_score(y, y_pred, average='weighted', zero_division=0)\n","recall = recall_score(y, y_pred, average='weighted', zero_division=0)\n","f1 = f1_score(y, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['BOW Logistic Regression'],\n","    'Model Path': [model_path],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Final/validation_results.csv'\n","max_accuracy_file = '/content/drive/MyDrive/work2/Final/max_accuracy.txt'\n","\n","# Check if the results file exists and handle the append operation correctly\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    updated_df = pd.concat([existing_df, results_df], ignore_index=True)\n","    updated_df.to_csv(results_file, index=False)\n","else:\n","    results_df.to_csv(results_file, index=False)\n","\n","# Update max accuracy if necessary\n","max_accuracy = accuracy\n","if os.path.exists(max_accuracy_file):\n","    with open(max_accuracy_file, 'r') as file:\n","        max_accuracy = max(max_accuracy, float(file.read()))\n","\n","with open(max_accuracy_file, 'w') as file:\n","    file.write(str(max_accuracy))\n","\n","print(f\"Results saved to {results_file}\")\n","print(f\"Maximum accuracy: {max_accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVrGFwg8iprL","executionInfo":{"status":"ok","timestamp":1718113446537,"user_tz":-300,"elapsed":394,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"bfd823e1-5cb6-4675-d15d-61690b2f0c04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 41.38%\n","Precision: 0.17\n","Recall: 0.41\n","F1 Score: 0.24\n","Results saved to /content/drive/MyDrive/work2/Final/validation_results.csv\n","Maximum accuracy: 41.38%\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file\n","results_df = pd.read_csv('/content/drive/MyDrive/work2/Final/validation_results.csv')\n","\n","# Show the first 5 rows\n","results_df.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"8Fg5vhWoiqU5","executionInfo":{"status":"ok","timestamp":1718113528598,"user_tz":-300,"elapsed":396,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"1313dde5-e896-4130-cd7f-a1d45975b1f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                Model Name                                         Model Path  \\\n","0            Random Forest  /content/drive/MyDrive/work2/Final/Image_Model...   \n","1              MobileNetV2  /content/drive/MyDrive/work2/Final/Image_Model...   \n","2       Audio Sentiment RF  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","3                     LSTM  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","4        BERT Multilingual  /content/drive/MyDrive/work2/Final/Text_Work/T...   \n","5  BOW Logistic Regression  /content/drive/MyDrive/work2/Final/Text_Work/T...   \n","\n","   Accuracy  Precision    Recall  F1 Score  \n","0  0.255528   0.783576  0.255528  0.350567  \n","1  0.366914   0.346832  0.366914  0.329704  \n","2  0.344828   0.247126  0.344828  0.257313  \n","3  0.310345   0.249390  0.310345  0.264791  \n","4  0.413793   0.435897  0.398148  0.367077  \n","5  0.413793   0.171225  0.413793  0.242220  "],"text/html":["\n","  <div id=\"df-73173bd1-92b4-48ec-bc47-4220e05c919f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Model Path</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.255528</td>\n","      <td>0.783576</td>\n","      <td>0.255528</td>\n","      <td>0.350567</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MobileNetV2</td>\n","      <td>/content/drive/MyDrive/work2/Final/Image_Model...</td>\n","      <td>0.366914</td>\n","      <td>0.346832</td>\n","      <td>0.366914</td>\n","      <td>0.329704</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Audio Sentiment RF</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.344828</td>\n","      <td>0.247126</td>\n","      <td>0.344828</td>\n","      <td>0.257313</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LSTM</td>\n","      <td>/content/drive/MyDrive/work2/Final/Audio_Model...</td>\n","      <td>0.310345</td>\n","      <td>0.249390</td>\n","      <td>0.310345</td>\n","      <td>0.264791</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BERT Multilingual</td>\n","      <td>/content/drive/MyDrive/work2/Final/Text_Work/T...</td>\n","      <td>0.413793</td>\n","      <td>0.435897</td>\n","      <td>0.398148</td>\n","      <td>0.367077</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>BOW Logistic Regression</td>\n","      <td>/content/drive/MyDrive/work2/Final/Text_Work/T...</td>\n","      <td>0.413793</td>\n","      <td>0.171225</td>\n","      <td>0.413793</td>\n","      <td>0.242220</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73173bd1-92b4-48ec-bc47-4220e05c919f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-73173bd1-92b4-48ec-bc47-4220e05c919f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-73173bd1-92b4-48ec-bc47-4220e05c919f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-15535a79-0045-4e19-bdd9-6c2d27f5b5c9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15535a79-0045-4e19-bdd9-6c2d27f5b5c9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-15535a79-0045-4e19-bdd9-6c2d27f5b5c9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Model Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Random Forest\",\n          \"MobileNetV2\",\n          \"BOW Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\",\n          \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5\",\n          \"/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06155465685248495,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.4137931034482758,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3669135802469135,\n          0.4137931034482758,\n          0.3448275862068966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22138096316137532,\n        \"min\": 0.1712247324613555,\n        \"max\": 0.7835760441018279,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7835760441018279,\n          0.3468322544366896,\n          0.1712247324613555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.058617214574315034,\n        \"min\": 0.2555282555282555,\n        \"max\": 0.4137931034482758,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.2555282555282555,\n          0.3669135802469135,\n          0.4137931034482758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053509659830534836,\n        \"min\": 0.2422203532380151,\n        \"max\": 0.3670773670773671,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.3505674352223088,\n          0.3297035133944206,\n          0.2422203532380151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# prompt: delete rows at index 6 and 7 . Then save results in same CSV file\n","\n","import pandas as pd\n","\n","# Load the CSV file\n","results_df = pd.read_csv('/content/drive/MyDrive/work2/Final/validation_results.csv')\n","\n","# Delete rows at index 6 and 7\n","results_df = results_df.drop([6, 7])\n","\n","# Save results in the same CSV file\n","results_df.to_csv('/content/drive/MyDrive/work2/Final/validation_results.csv', index=False)\n","\n","# Print the updated DataFrame\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8RtNtw0ivsZ","executionInfo":{"status":"ok","timestamp":1718113520836,"user_tz":-300,"elapsed":381,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"49042fe4-4b3c-45f5-81c2-07e6c2065020"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                Model Name                                         Model Path  \\\n","0            Random Forest  /content/drive/MyDrive/work2/Final/Image_Model...   \n","1              MobileNetV2  /content/drive/MyDrive/work2/Final/Image_Model...   \n","2       Audio Sentiment RF  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","3                     LSTM  /content/drive/MyDrive/work2/Final/Audio_Model...   \n","4        BERT Multilingual  /content/drive/MyDrive/work2/Final/Text_Work/T...   \n","5  BOW Logistic Regression  /content/drive/MyDrive/work2/Final/Text_Work/T...   \n","\n","   Accuracy  Precision    Recall  F1 Score  \n","0  0.255528   0.783576  0.255528  0.350567  \n","1  0.366914   0.346832  0.366914  0.329704  \n","2  0.344828   0.247126  0.344828  0.257313  \n","3  0.310345   0.249390  0.310345  0.264791  \n","4  0.413793   0.435897  0.398148  0.367077  \n","5  0.413793   0.171225  0.413793  0.242220  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import joblib\n","import librosa\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import os\n","\n","# Load the CSV files\n","audio_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv')\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","\n","# Select only the first record from Videos.csv\n","video_df = video_df.head(1)\n","\n","# Load the pre-trained Random Forest audio model\n","audio_rf_model_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest.joblib'\n","audio_rf_scaler_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest_Scaler.joblib'\n","\n","audio_rf_model = joblib.load(audio_rf_model_path)\n","audio_rf_scaler = joblib.load(audio_rf_scaler_path)\n","\n","# Folder containing audio files\n","audio_folder = '/content/drive/MyDrive/work2/Validation_Data/Audios'\n","\n","# Helper function for audio feature extraction\n","def preprocess_audio(file_path):\n","    try:\n","        y, sr = librosa.load(file_path)\n","        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n","        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n","        mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n","        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n","        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr), axis=1)\n","        return np.concatenate((mfccs, chroma, mel, spectral_contrast, tonnetz))\n","    except Exception as e:\n","        print(f\"Error processing {file_path}: {e}\")\n","        return None\n","\n","# Prediction function for Random Forest audio model\n","def predict_audio_rf(file_path):\n","    features = preprocess_audio(file_path)\n","    if features is not None:\n","        features_scaled = audio_rf_scaler.transform([features])\n","        return audio_rf_model.predict(features_scaled)[0]\n","    else:\n","        return None\n","\n","# Perform predictions and evaluate\n","predictions = []\n","for index, row in video_df.iterrows():\n","    try:\n","        # Correctly locate the audio file in the specified folder\n","        audio_path = os.path.join(audio_folder, row['File'])\n","        if not os.path.exists(audio_path):\n","            raise FileNotFoundError(f\"{audio_path} does not exist\")\n","\n","        print(f\"Audio File: {audio_path}\")\n","        prediction = predict_audio_rf(audio_path)\n","        predictions.append(prediction)\n","    except (IndexError, FileNotFoundError) as e:\n","        print(f\"Error: {e}\")\n","        predictions.append(None)\n","\n","video_df['Predicted_Senti'] = predictions\n","\n","# Drop rows where prediction is None\n","video_df = video_df.dropna(subset=['Predicted_Senti'])\n","\n","# Ensure sentiment values are integers\n","video_df['Predicted_Senti'] = video_df['Predicted_Senti'].astype(int)\n","video_df['Senti'] = video_df['Senti'].astype(int)\n","\n","# Evaluate the predictions\n","accuracy = accuracy_score(video_df['Senti'], video_df['Predicted_Senti'])\n","precision = precision_score(video_df['Senti'], video_df['Predicted_Senti'], average='weighted', zero_division=0)\n","recall = recall_score(video_df['Senti'], video_df['Predicted_Senti'], average='weighted', zero_division=0)\n","f1 = f1_score(video_df['Senti'], video_df['Predicted_Senti'], average='weighted')\n","\n","# Save results in a pandas DataFrame\n","results_df = pd.DataFrame({\n","    'Model Name': ['Audio Random Forest'],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","results_df.to_csv('/content/drive/MyDrive/work2/Validation_Data/results_audio_rf.csv', index=False)\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ui2HP6JDKBvD","executionInfo":{"status":"ok","timestamp":1718195588369,"user_tz":-300,"elapsed":3011,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"80f40d40-a534-4619-9fee-816637e224d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Audio File: /content/drive/MyDrive/work2/Validation_Data/Audios/1. Mobile_Neutral.wav\n","            Model Name  Accuracy  Precision  Recall  F1 Score\n","0  Audio Random Forest       0.0        0.0     0.0       0.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import joblib\n","import librosa\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import os\n","\n","# Load the CSV files\n","audio_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv')\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","\n","# Load the pre-trained Random Forest audio model\n","audio_rf_model_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest.joblib'\n","audio_rf_scaler_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest_Scaler.joblib'\n","\n","audio_rf_model = joblib.load(audio_rf_model_path)\n","audio_rf_scaler = joblib.load(audio_rf_scaler_path)\n","\n","# Folder containing audio files\n","audio_folder = '/content/drive/MyDrive/work2/Validation_Data/Audios'\n","\n","# Helper function for audio feature extraction\n","def preprocess_audio(file_path):\n","    try:\n","        y, sr = librosa.load(file_path)\n","        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n","        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n","        mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n","        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n","        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr), axis=1)\n","        return np.concatenate((mfccs, chroma, mel, spectral_contrast, tonnetz))\n","    except Exception as e:\n","        print(f\"Error processing {file_path}: {e}\")\n","        return None\n","\n","# Prediction and evaluation function for Random Forest audio model\n","results = []\n","for index, row in video_df.iterrows():\n","    audio_path = os.path.join(audio_folder, row['File'])\n","    if os.path.exists(audio_path):\n","        label = audio_df.loc[audio_df['File'] == row['File'], 'Senti'].values[0]\n","        prediction = predict_audio_rf(audio_path)\n","        results.append({\n","            'Audio File': row['File'],\n","            'Actual Label': label,\n","            'Predicted Label': prediction\n","        })\n","\n","# Convert results to DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Display final results including the video labels\n","#print(results_df)\n","\n","# Evaluate model performance\n","#actual_labels = results_df['Actual Label'].tolist()\n","#predicted_labels = results_df['Predicted Label'].tolist()\n","\n","accuracy = accuracy_score(actual_labels, predicted_labels)\n","precision = precision_score(actual_labels, predicted_labels, average='weighted')\n","recall = recall_score(actual_labels, predicted_labels, average='weighted')\n","f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n","\n","print(f\"Accuracy: {accuracy*100:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")"],"metadata":{"id":"CJzysAqWlyqp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#1. Audio Model Validation Random Forest"],"metadata":{"id":"vT_oYd2pFgOb"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import joblib\n","import librosa\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import os\n","\n","# Load the CSV files\n","audio_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv')\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","\n","# Load the pre-trained Random Forest audio model\n","audio_rf_model_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest.joblib'\n","audio_rf_scaler_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest_Scaler.joblib'\n","\n","audio_rf_model = joblib.load(audio_rf_model_path)\n","audio_rf_scaler = joblib.load(audio_rf_scaler_path)\n","\n","# Folder containing audio files\n","audio_folder = '/content/drive/MyDrive/work2/Validation_Data/Audios'\n","\n","# Helper function for audio feature extraction\n","def preprocess_audio(file_path):\n","    try:\n","        y, sr = librosa.load(file_path)\n","        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n","        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n","        mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n","        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n","        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr), axis=1)\n","        return np.concatenate((mfccs, chroma, mel, spectral_contrast, tonnetz))\n","    except Exception as e:\n","        print(f\"Error processing {file_path}: {e}\")\n","        return None\n","# Prediction function for Random Forest audio model\n","def predict_audio_rf(file_path):\n","    features = preprocess_audio(file_path)\n","    if features is not None:\n","        features_scaled = audio_rf_scaler.transform([features])\n","        return audio_rf_model.predict(features_scaled)[0]\n","    else:\n","        return None\n","\n","# Prediction and evaluation function for Random Forest audio model\n","results = []\n","for index, row in video_df.iterrows():\n","    audio_path = os.path.join(audio_folder, row['File'])\n","    if os.path.exists(audio_path):\n","        label = audio_df.loc[audio_df['File'] == row['File'], 'Senti'].values[0]\n","        prediction = predict_audio_rf(audio_path)\n","        results.append({\n","            'Audio File': row['File'],\n","            'Actual Label': label,\n","            'Predicted Label': prediction\n","        })\n","\n","# Convert results to DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Display final results including the video labels\n","print(results_df)\n","\n","# Evaluate model performance\n","actual_labels = results_df['Actual Label'].tolist()\n","predicted_labels = results_df['Predicted Label'].tolist()\n","\n","accuracy = accuracy_score(actual_labels, predicted_labels)\n","precision = precision_score(actual_labels, predicted_labels, average='weighted')\n","recall = recall_score(actual_labels, predicted_labels, average='weighted')\n","f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n","\n","print(f\"Accuracy: {accuracy*100:.2f}%\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1 Score: {f1:.2f}\")\n","\n","# Metrics dictionary\n","metrics = {\n","    'Model': 'Random Forest',\n","    'Accuracy': accuracy,\n","    'Precision': precision,\n","    'Recall': recall,\n","    'F1 Score': f1\n","}\n","\n","# Convert dictionary to DataFrame\n","metrics_df = pd.DataFrame([metrics])\n","\n","# Save to CSV\n","metrics_df.to_csv('/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv', index=False)\n","\n","print(\"Model evaluation metrics saved successfully.\")"],"metadata":{"id":"mNqkzSawOuMo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718274376504,"user_tz":-300,"elapsed":198330,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"85f71b83-ccb1-43b6-cd57-38efecbaa0fc"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["                                           Audio File  Actual Label  \\\n","0                               1. Mobile_Neutral.wav             0   \n","1              1. Mobile__Positive_Product_Review.wav             0   \n","2                  1. Tea_Negative_Product_Review.wav             2   \n","3      10. Blasphemy_Negative_Perception_Building.wav             1   \n","4   10. Political Extremisim_Negative_Perception_B...             2   \n","5      11. Blasphemy_Negative_Perception_Building.wav             2   \n","6   11. Political Extremisim_Negative_Perception_B...             2   \n","7    2. Communication_Neutral_Perception Building.wav             0   \n","8               2. Mobile_Positive_Product_Review.wav             1   \n","9                  2. Tea_Negative_Product_Review.wav             0   \n","10   3. Communication_Neutral_Perception Building.wav             0   \n","11                 3. ICE_Negative_Product_Review.wav             2   \n","12              3. Mobile_Positive_Product_Review.wav             1   \n","13                 4. ICE_Negative_Product_Review.wav             2   \n","14                  4. ICE_Neutral_Product_Review.wav             1   \n","15           4. Olive Oil_Positive_Product_Review.wav             1   \n","16       5. Blasphemy_Neutral_Perception_Building.wav             0   \n","17  5. Honor Killing_Negative_Perception_Building.wav             2   \n","18                 5. ICE_Positive_Product_Review.wav             1   \n","19                  5.ICE_Negative_Product_Review.wav             1   \n","20  6. Honor_Killing_Negative_Perception_Building.wav             2   \n","21                 6. ICE_Positive_Product_Review.wav             1   \n","22    6. Social Media_Neutral_Perception_Building.wav             2   \n","23      7. Blasphemy_Negative_Perception_Building.wav             2   \n","24  7. Political Extremisim_Neutral_Perception_Bui...             0   \n","25      8. Blasphemy_Negative_Perception_Building.wav             1   \n","26  8. Communication_Positive_Perception_Building.wav             1   \n","27  8. Blasphemy_Neutral_Perception_Building_by_Im...             1   \n","\n","    Predicted Label  \n","0                 2  \n","1                 1  \n","2                 1  \n","3                 1  \n","4                 2  \n","5                 1  \n","6                 2  \n","7                 1  \n","8                 2  \n","9                 1  \n","10                2  \n","11                1  \n","12                1  \n","13                1  \n","14                1  \n","15                1  \n","16                1  \n","17                1  \n","18                1  \n","19                1  \n","20                2  \n","21                1  \n","22                2  \n","23                1  \n","24                2  \n","25                1  \n","26                1  \n","27                1  \n","Accuracy: 50.00%\n","Precision: 0.38\n","Recall: 0.50\n","F1 Score: 0.41\n","Model evaluation metrics saved successfully.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["metrics_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"PCrvuN8KDklb","executionInfo":{"status":"ok","timestamp":1718268521787,"user_tz":-300,"elapsed":5,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"a2478ab1-5fee-4c0c-dce7-24765b0f9797"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Model  Accuracy  Precision  Recall  F1 Score\n","0  Random Forest       0.5      0.375     0.5  0.412186"],"text/html":["\n","  <div id=\"df-385c6dfa-9ca6-40cf-b811-b905b1c8046a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>0.5</td>\n","      <td>0.375</td>\n","      <td>0.5</td>\n","      <td>0.412186</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-385c6dfa-9ca6-40cf-b811-b905b1c8046a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-385c6dfa-9ca6-40cf-b811-b905b1c8046a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-385c6dfa-9ca6-40cf-b811-b905b1c8046a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df","summary":"{\n  \"name\": \"metrics_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.375,\n        \"max\": 0.375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.41218637992831536,\n        \"max\": 0.41218637992831536,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.41218637992831536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["# prompt: results_df save this csv\n","\n","results_df.to_csv('/content/drive/MyDrive/work2/Validation_Data/results_audio_rf_temp.csv')\n"],"metadata":{"id":"MG_6ttmifC8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_df.head(30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":927},"id":"KWlQFk7fHnbT","executionInfo":{"status":"ok","timestamp":1718223907763,"user_tz":-300,"elapsed":408,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"7baeb059-13ac-431f-ba35-cb7d8c7b3fc6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           Audio File  Actual Label  \\\n","0                               1. Mobile_Neutral.wav             0   \n","1              1. Mobile__Positive_Product_Review.wav             0   \n","2                  1. Tea_Negative_Product_Review.wav             2   \n","3      10. Blasphemy_Negative_Perception_Building.wav             1   \n","4   10. Political Extremisim_Negative_Perception_B...             2   \n","5      11. Blasphemy_Negative_Perception_Building.wav             2   \n","6   11. Political Extremisim_Negative_Perception_B...             2   \n","7    2. Communication_Neutral_Perception Building.wav             0   \n","8               2. Mobile_Positive_Product_Review.wav             1   \n","9                  2. Tea_Negative_Product_Review.wav             0   \n","10   3. Communication_Neutral_Perception Building.wav             0   \n","11                 3. ICE_Negative_Product_Review.wav             2   \n","12              3. Mobile_Positive_Product_Review.wav             1   \n","13                 4. ICE_Negative_Product_Review.wav             2   \n","14                  4. ICE_Neutral_Product_Review.wav             1   \n","15           4. Olive Oil_Positive_Product_Review.wav             1   \n","16       5. Blasphemy_Neutral_Perception_Building.wav             0   \n","17  5. Honor Killing_Negative_Perception_Building.wav             2   \n","18                 5. ICE_Positive_Product_Review.wav             1   \n","19                  5.ICE_Negative_Product_Review.wav             1   \n","20  6. Honor_Killing_Negative_Perception_Building.wav             2   \n","21                 6. ICE_Positive_Product_Review.wav             1   \n","22    6. Social Media_Neutral_Perception_Building.wav             2   \n","23      7. Blasphemy_Negative_Perception_Building.wav             2   \n","24  7. Political Extremisim_Neutral_Perception_Bui...             0   \n","25      8. Blasphemy_Negative_Perception_Building.wav             1   \n","26  8. Communication_Positive_Perception_Building.wav             1   \n","27  8. Blasphemy_Neutral_Perception_Building_by_Im...             1   \n","\n","    Predicted Label  \n","0                 2  \n","1                 1  \n","2                 1  \n","3                 1  \n","4                 2  \n","5                 1  \n","6                 2  \n","7                 1  \n","8                 2  \n","9                 1  \n","10                2  \n","11                1  \n","12                1  \n","13                1  \n","14                1  \n","15                1  \n","16                1  \n","17                1  \n","18                1  \n","19                1  \n","20                2  \n","21                1  \n","22                2  \n","23                1  \n","24                2  \n","25                1  \n","26                1  \n","27                1  "],"text/html":["\n","  <div id=\"df-1f5208c3-c990-4b4e-9cfa-4fb644b37511\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Audio File</th>\n","      <th>Actual Label</th>\n","      <th>Predicted Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1. Mobile_Neutral.wav</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1. Mobile__Positive_Product_Review.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1. Tea_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10. Political Extremisim_Negative_Perception_B...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>11. Political Extremisim_Negative_Perception_B...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2. Communication_Neutral_Perception Building.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2. Mobile_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2. Tea_Negative_Product_Review.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>3. Communication_Neutral_Perception Building.wav</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>3. ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3. Mobile_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>4. ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>4. ICE_Neutral_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>4. Olive Oil_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>5. Blasphemy_Neutral_Perception_Building.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>5. Honor Killing_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>5. ICE_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>5.ICE_Negative_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>6. Honor_Killing_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>6. ICE_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>6. Social Media_Neutral_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>7. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>7. Political Extremisim_Neutral_Perception_Bui...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>8. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>8. Communication_Positive_Perception_Building.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>8. Blasphemy_Neutral_Perception_Building_by_Im...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f5208c3-c990-4b4e-9cfa-4fb644b37511')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1f5208c3-c990-4b4e-9cfa-4fb644b37511 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1f5208c3-c990-4b4e-9cfa-4fb644b37511');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f3c2c816-b0f8-4ae2-bb06-91fce51e8e09\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3c2c816-b0f8-4ae2-bb06-91fce51e8e09')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f3c2c816-b0f8-4ae2-bb06-91fce51e8e09 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 28,\n  \"fields\": [\n    {\n      \"column\": \"Audio File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"2. Tea_Negative_Product_Review.wav\",\n          \"8. Blasphemy_Negative_Perception_Building.wav\",\n          \"2. Mobile_Positive_Product_Review.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["#2. Audio Model Validatation LSTM"],"metadata":{"id":"gjEAnUL2FmYU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import joblib\n","import librosa\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import os\n","import tensorflow as tf\n","\n","# Load the CSV files\n","audio_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv')\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","\n","# Load the pre-trained LSTM audio model and scaler\n","lstm_model_path = '/content/drive/MyDrive/work2/Final/Old_audio_models/Audio_Model_1_LSTM.h5'\n","lstm_scaler_path = '/content/drive/MyDrive/work2/Final/Old_audio_models/scaler_lstm.pkl'\n","\n","lstm_model = tf.keras.models.load_model(lstm_model_path)\n","lstm_scaler = joblib.load(lstm_scaler_path)\n","\n","# Folder containing audio files\n","audio_folder = '/content/drive/MyDrive/work2/Validation_Data/Audios'\n","\n","# Helper function for audio feature extraction\n","def preprocess_audio_lstm(file_path):\n","    try:\n","        y, sr = librosa.load(file_path, duration=3)\n","        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n","        mel = librosa.feature.melspectrogram(y=y, sr=sr)\n","        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n","        bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n","        energy_contour = librosa.feature.rms(y=y)\n","        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n","\n","        features = np.concatenate((\n","            np.mean(mfccs, axis=1),\n","            np.mean(mel, axis=1),\n","            np.mean(contrast, axis=1),\n","            np.mean(bandwidth, axis=1),\n","            np.mean(energy_contour, axis=1),\n","            np.mean(spectral_rolloff, axis=1)\n","        ))\n","        return features\n","    except Exception as e:\n","        print(f\"Error processing {file_path}: {e}\")\n","        return None\n","\n","def predict_audio_lstm(file_path):\n","    features = preprocess_audio_lstm(file_path)\n","    if features is not None:\n","        features_scaled = lstm_scaler.transform([features])\n","        features_scaled = np.expand_dims(features_scaled, -1)\n","        prediction = lstm_model.predict(features_scaled)\n","        return np.argmax(prediction, axis=1)[0]\n","    else:\n","        return None\n","\n","# Prediction and evaluation function for the LSTM model\n","results_lstm = []\n","for index, row in video_df.iterrows():\n","    audio_path = os.path.join(audio_folder, row['File'])\n","    if os.path.exists(audio_path):\n","        label = audio_df.loc[audio_df['File'] == row['File'], 'Senti'].values[0]\n","        prediction_lstm = predict_audio_lstm(audio_path)\n","        results_lstm.append({\n","            'Audio File': row['File'],\n","            'Actual Label': label,\n","            'Predicted Label': prediction_lstm\n","        })\n","\n","# Convert results to DataFrame\n","results_lstm_df = pd.DataFrame(results_lstm)\n","\n","# Display final results including the video labels\n","print(\"LSTM Results:\\n\", results_lstm_df)\n","\n","# Evaluate model performance for LSTM\n","actual_labels_lstm = results_lstm_df['Actual Label'].tolist()\n","predicted_labels_lstm = results_lstm_df['Predicted Label'].tolist()\n","\n","accuracy_lstm = accuracy_score(actual_labels_lstm, predicted_labels_lstm)\n","precision_lstm = precision_score(actual_labels_lstm, predicted_labels_lstm, average='weighted', zero_division=1)\n","recall_lstm = recall_score(actual_labels_lstm, predicted_labels_lstm, average='weighted')\n","f1_lstm = f1_score(actual_labels_lstm, predicted_labels_lstm, average='weighted')\n","\n","print(f\"LSTM - Accuracy: {accuracy_lstm*100:.2f}%\")\n","print(f\"LSTM - Precision: {precision_lstm:.2f}\")\n","print(f\"LSTM - Recall: {recall_lstm:.2f}\")\n","print(f\"LSTM - F1 Score: {f1_lstm:.2f}\")\n","\n","# Metrics dictionary for LSTM model\n","metrics_lstm = {\n","    'Model': 'LSTM',\n","    'Accuracy': accuracy_lstm,\n","    'Precision': precision_lstm,\n","    'Recall': recall_lstm,\n","    'F1 Score': f1_lstm\n","}\n","\n","# Convert dictionary to DataFrame\n","metrics_df_lstm = pd.DataFrame([metrics_lstm])\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    metrics_df_lstm = pd.concat([existing_df, metrics_df_lstm], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","metrics_df_lstm.to_csv(results_file, index=False)\n","\n","print(\"Model evaluation metrics saved successfully.\")\n"],"metadata":{"id":"Az-L7TSBfzeR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718274385474,"user_tz":-300,"elapsed":9006,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"beec9d57-0cbc-4d65-86b0-3ec764a94991"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 60ms/step\n","LSTM Results:\n","                                            Audio File  Actual Label  \\\n","0                               1. Mobile_Neutral.wav             0   \n","1              1. Mobile__Positive_Product_Review.wav             0   \n","2                  1. Tea_Negative_Product_Review.wav             2   \n","3      10. Blasphemy_Negative_Perception_Building.wav             1   \n","4   10. Political Extremisim_Negative_Perception_B...             2   \n","5      11. Blasphemy_Negative_Perception_Building.wav             2   \n","6   11. Political Extremisim_Negative_Perception_B...             2   \n","7    2. Communication_Neutral_Perception Building.wav             0   \n","8               2. Mobile_Positive_Product_Review.wav             1   \n","9                  2. Tea_Negative_Product_Review.wav             0   \n","10   3. Communication_Neutral_Perception Building.wav             0   \n","11                 3. ICE_Negative_Product_Review.wav             2   \n","12              3. Mobile_Positive_Product_Review.wav             1   \n","13                 4. ICE_Negative_Product_Review.wav             2   \n","14                  4. ICE_Neutral_Product_Review.wav             1   \n","15           4. Olive Oil_Positive_Product_Review.wav             1   \n","16       5. Blasphemy_Neutral_Perception_Building.wav             0   \n","17  5. Honor Killing_Negative_Perception_Building.wav             2   \n","18                 5. ICE_Positive_Product_Review.wav             1   \n","19                  5.ICE_Negative_Product_Review.wav             1   \n","20  6. Honor_Killing_Negative_Perception_Building.wav             2   \n","21                 6. ICE_Positive_Product_Review.wav             1   \n","22    6. Social Media_Neutral_Perception_Building.wav             2   \n","23      7. Blasphemy_Negative_Perception_Building.wav             2   \n","24  7. Political Extremisim_Neutral_Perception_Bui...             0   \n","25      8. Blasphemy_Negative_Perception_Building.wav             1   \n","26  8. Communication_Positive_Perception_Building.wav             1   \n","27  8. Blasphemy_Neutral_Perception_Building_by_Im...             1   \n","\n","    Predicted Label  \n","0                 1  \n","1                 1  \n","2                 2  \n","3                 1  \n","4                 1  \n","5                 1  \n","6                 1  \n","7                 1  \n","8                 2  \n","9                 2  \n","10                1  \n","11                2  \n","12                2  \n","13                1  \n","14                1  \n","15                2  \n","16                2  \n","17                2  \n","18                1  \n","19                1  \n","20                1  \n","21                1  \n","22                1  \n","23                2  \n","24                1  \n","25                2  \n","26                1  \n","27                1  \n","LSTM - Accuracy: 39.29%\n","LSTM - Precision: 0.55\n","LSTM - Recall: 0.39\n","LSTM - F1 Score: 0.33\n","Model evaluation metrics saved successfully.\n"]}]},{"cell_type":"code","source":["metrics_df_lstm.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"80KE1WHRGyOF","executionInfo":{"status":"ok","timestamp":1718268553389,"user_tz":-300,"elapsed":405,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"7a1f3518-5844-4521-976f-2e6a7e39e793"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Model  Accuracy  Precision    Recall  F1 Score\n","0  Random Forest  0.500000   0.375000  0.500000  0.412186\n","1           LSTM  0.392857   0.545635  0.392857  0.332512"],"text/html":["\n","  <div id=\"df-96a0b322-e4c2-4c11-afda-81e104cbe1c5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>0.500000</td>\n","      <td>0.375000</td>\n","      <td>0.500000</td>\n","      <td>0.412186</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LSTM</td>\n","      <td>0.392857</td>\n","      <td>0.545635</td>\n","      <td>0.392857</td>\n","      <td>0.332512</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96a0b322-e4c2-4c11-afda-81e104cbe1c5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-96a0b322-e4c2-4c11-afda-81e104cbe1c5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-96a0b322-e4c2-4c11-afda-81e104cbe1c5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d4b3adbb-c025-45d8-91f3-05568835605e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4b3adbb-c025-45d8-91f3-05568835605e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d4b3adbb-c025-45d8-91f3-05568835605e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"metrics_df_lstm","summary":"{\n  \"name\": \"metrics_df_lstm\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"LSTM\",\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07576144084141581,\n        \"min\": 0.39285714285714285,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.39285714285714285,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12065710948818077,\n        \"min\": 0.375,\n        \"max\": 0.5456349206349207,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5456349206349207,\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07576144084141581,\n        \"min\": 0.39285714285714285,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.39285714285714285,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056338071403928346,\n        \"min\": 0.332512315270936,\n        \"max\": 0.4121863799283153,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.332512315270936,\n          0.4121863799283153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["#3. Frame Model Validatation Random Forest"],"metadata":{"id":"XH5QliqLNOdx"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import cv2\n","from skimage.feature import hog\n","import joblib\n","import os\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Load the CSV files\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","frames_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    if not os.path.exists(filepath):\n","        print(f\"File not found: {filepath}\")\n","        return None\n","    img = cv2.imread(filepath)\n","    if img is None:\n","        print(f\"Failed to read image: {filepath}\")\n","        return None\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = cv2.resize(img, (128, 128))\n","    img = cv2.equalizeHist(img)\n","    return img\n","\n","# Load the saved model\n","joblib_file = \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\"\n","loaded_rf_model = joblib.load(joblib_file)\n","\n","# Initialize lists to store true labels and predictions\n","all_true_labels = []\n","all_pred_labels = []\n","\n","# Process each video\n","for video_name in video_df['File']:\n","    video_base_name = video_name.replace('.wav', '')\n","\n","    # Filter frames related to the current video and are key frames\n","    video_frames = frames_df[(frames_df['Video Name'].str.replace('.wav', '') == video_base_name) & (frames_df['Key_Frame'] == 'Y')]\n","\n","    # Check if there are any key frames for this video\n","    if video_frames.empty:\n","        print(f\"No key frames found for video: {video_name}\")\n","        continue\n","\n","    # Apply preprocessing to each image and prepare features\n","    for frame_path, true_label in zip(video_frames['Frame Path'], video_frames['Senti']):\n","        processed_img = preprocess_image(frame_path)\n","        if processed_img is not None:\n","            hog_features = hog(processed_img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys').reshape(1, -1)\n","            video_pred = loaded_rf_model.predict(hog_features)[0]\n","            all_true_labels.append(true_label)\n","            all_pred_labels.append(video_pred)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(all_true_labels, all_pred_labels)\n","precision = precision_score(all_true_labels, all_pred_labels, average='weighted')\n","recall = recall_score(all_true_labels, all_pred_labels, average='weighted')\n","f1 = f1_score(all_true_labels, all_pred_labels, average='weighted')\n","\n","# Print evaluation metrics\n","print(f\"Overall Accuracy: {accuracy*100:.2f}%\")\n","print(f\"Overall Precision: {precision:.2f}\")\n","print(f\"Overall Recall: {recall:.2f}\")\n","print(f\"Overall F1 Score: {f1:.2f}\")\n","\n","# Prepare results for saving\n","results_df = pd.DataFrame({\n","    'Model': ['Random Forest (Video)'],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Overall evaluation metrics saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKq61-XNHJ3e","executionInfo":{"status":"ok","timestamp":1718274410115,"user_tz":-300,"elapsed":24673,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"93deafc4-41c2-43b2-c83e-561a00de8c23"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["No key frames found for video: 9. Blasphemy_Negative_Perception_Building.wav\n","Overall Accuracy: 56.10%\n","Overall Precision: 0.57\n","Overall Recall: 0.56\n","Overall F1 Score: 0.53\n","Overall evaluation metrics saved to /content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","# Read the CSV file\n","df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv')\n","\n","# Display the first 5 rows\n","df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"uUbrVkG2QA_p","executionInfo":{"status":"ok","timestamp":1718268603448,"user_tz":-300,"elapsed":423,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"d216b95d-b201-4f1e-9a0c-6af6915872ed"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Model  Accuracy  Precision    Recall  F1 Score       Modality  \\\n","0  Random Forest  0.500000   0.375000  0.500000  0.412186            NaN   \n","1           LSTM  0.392857   0.545635  0.392857  0.332512            NaN   \n","2            NaN       NaN        NaN       NaN       NaN  Video Model 2   \n","3            NaN       NaN        NaN       NaN       NaN  Video Model 2   \n","4            NaN       NaN        NaN       NaN       NaN  Video Model 2   \n","\n","                               Video Name Sentiment  Percentage  \n","0                                     NaN       NaN         NaN  \n","1                                     NaN       NaN         NaN  \n","2                   1. Mobile_Neutral.wav  negative    0.365104  \n","3  1. Mobile__Positive_Product_Review.wav  negative    0.354444  \n","4      1. Tea_Negative_Product_Review.wav  negative    0.359145  "],"text/html":["\n","  <div id=\"df-e9b57439-e917-4a27-b823-b0dc62644ed3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","      <th>Modality</th>\n","      <th>Video Name</th>\n","      <th>Sentiment</th>\n","      <th>Percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>0.500000</td>\n","      <td>0.375000</td>\n","      <td>0.500000</td>\n","      <td>0.412186</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LSTM</td>\n","      <td>0.392857</td>\n","      <td>0.545635</td>\n","      <td>0.392857</td>\n","      <td>0.332512</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Video Model 2</td>\n","      <td>1. Mobile_Neutral.wav</td>\n","      <td>negative</td>\n","      <td>0.365104</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Video Model 2</td>\n","      <td>1. Mobile__Positive_Product_Review.wav</td>\n","      <td>negative</td>\n","      <td>0.354444</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Video Model 2</td>\n","      <td>1. Tea_Negative_Product_Review.wav</td>\n","      <td>negative</td>\n","      <td>0.359145</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9b57439-e917-4a27-b823-b0dc62644ed3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e9b57439-e917-4a27-b823-b0dc62644ed3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e9b57439-e917-4a27-b823-b0dc62644ed3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3b3c4f33-1f22-470d-ab47-2bf70e5ed453\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b3c4f33-1f22-470d-ab47-2bf70e5ed453')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3b3c4f33-1f22-470d-ab47-2bf70e5ed453 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"LSTM\",\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07576144084141585,\n        \"min\": 0.3928571428571428,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3928571428571428,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12065710948818077,\n        \"min\": 0.375,\n        \"max\": 0.5456349206349207,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5456349206349207,\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07576144084141585,\n        \"min\": 0.3928571428571428,\n        \"max\": 0.5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3928571428571428,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056338071403928346,\n        \"min\": 0.332512315270936,\n        \"max\": 0.4121863799283153,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.332512315270936,\n          0.4121863799283153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Modality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Video Model 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Video Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"2. Tea_Negative_Product_Review.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01926299029688394,\n        \"min\": 0.3339878787878787,\n        \"max\": 0.4071583333333333,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          0.3356746031746032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["#4. Frame Model Validatation CNN"],"metadata":{"id":"J75ObMNcRXhB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","import os\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Load the CSV files\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","frames_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    if not os.path.exists(filepath):\n","        print(f\"File not found: {filepath}\")\n","        return None\n","    img = cv2.imread(filepath)\n","    if img is None:\n","        print(f\"Failed to read image: {filepath}\")\n","        return None\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img, (224, 224))  # Resize to match MobileNetV2 input\n","    img = preprocess_input(img)  # Preprocess as per MobileNetV2 requirements\n","    return img\n","\n","# Load the saved TensorFlow model\n","model_path = '/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5'\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# Initialize lists to store true labels and predictions\n","all_true_labels = []\n","all_pred_labels = []\n","\n","# Process each video\n","for video_name in video_df['File']:\n","    video_base_name = video_name.replace('.wav', '')\n","\n","    # Filter frames related to the current video and are key frames\n","    video_frames = frames_df[(frames_df['Video Name'].str.replace('.wav', '') == video_base_name) & (frames_df['Key_Frame'] == 'Y')]\n","\n","    # Check if there are any key frames for this video\n","    if video_frames.empty:\n","        print(f\"No key frames found for video: {video_name}\")\n","        continue\n","\n","    # Apply preprocessing to each image and prepare features\n","    for frame_path, true_label in zip(video_frames['Frame Path'], video_frames['Senti']):\n","        processed_img = preprocess_image(frame_path)\n","        if processed_img is not None:\n","            video_image = np.expand_dims(processed_img, axis=0)\n","            video_pred = loaded_model.predict(video_image)[0]\n","            all_true_labels.append(true_label)\n","            all_pred_labels.append(np.argmax(video_pred))\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(all_true_labels, all_pred_labels)\n","precision = precision_score(all_true_labels, all_pred_labels, average='weighted')\n","recall = recall_score(all_true_labels, all_pred_labels, average='weighted')\n","f1 = f1_score(all_true_labels, all_pred_labels, average='weighted')\n","\n","# Print evaluation metrics\n","print(f\"Overall Accuracy: {accuracy*100:.2f}%\")\n","print(f\"Overall Precision: {precision:.2f}\")\n","print(f\"Overall Recall: {recall:.2f}\")\n","print(f\"Overall F1 Score: {f1:.2f}\")\n","\n","# Prepare results for saving\n","results_df = pd.DataFrame({\n","    'Model': ['MobileNetV2 (Video)'],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Overall evaluation metrics saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQrYI57MRSRG","executionInfo":{"status":"ok","timestamp":1718274483003,"user_tz":-300,"elapsed":72926,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"865b7a8b-82d5-4651-e0d9-236783bf0a3a"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 96ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 115ms/step\n","1/1 [==============================] - 0s 133ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 104ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 96ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 73ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 106ms/step\n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 96ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 104ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 103ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 80ms/step\n","1/1 [==============================] - 0s 101ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 114ms/step\n","1/1 [==============================] - 0s 103ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 131ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 70ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 101ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 96ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 71ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 144ms/step\n","1/1 [==============================] - 0s 186ms/step\n","1/1 [==============================] - 0s 163ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 104ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 100ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 109ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 54ms/step\n","No key frames found for video: 9. Blasphemy_Negative_Perception_Building.wav\n","Overall Accuracy: 52.21%\n","Overall Precision: 0.64\n","Overall Recall: 0.52\n","Overall F1 Score: 0.50\n","Overall evaluation metrics saved to /content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","# Read the CSV file\n","df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv')\n","\n","# Display the first 5 rows\n","df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"3xTvQ9EhRdZ2","executionInfo":{"status":"ok","timestamp":1718229241495,"user_tz":-300,"elapsed":434,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"df0e1199-4ddd-4675-8d75-0bbb7ef80e6c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   Model  Accuracy  Precision    Recall  F1 Score\n","0          Random Forest  0.500000   0.375000  0.500000  0.412186\n","1                   LSTM  0.392857   0.545635  0.392857  0.332512\n","2  Random Forest (Video)  0.324013   0.364749  0.324013  0.289487\n","3    MobileNetV2 (Video)  0.358025   0.344199  0.358025  0.319684"],"text/html":["\n","  <div id=\"df-f4ae1930-20cf-4ebc-ba61-4ee6fcfeefb1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>0.500000</td>\n","      <td>0.375000</td>\n","      <td>0.500000</td>\n","      <td>0.412186</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LSTM</td>\n","      <td>0.392857</td>\n","      <td>0.545635</td>\n","      <td>0.392857</td>\n","      <td>0.332512</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Random Forest (Video)</td>\n","      <td>0.324013</td>\n","      <td>0.364749</td>\n","      <td>0.324013</td>\n","      <td>0.289487</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MobileNetV2 (Video)</td>\n","      <td>0.358025</td>\n","      <td>0.344199</td>\n","      <td>0.358025</td>\n","      <td>0.319684</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4ae1930-20cf-4ebc-ba61-4ee6fcfeefb1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f4ae1930-20cf-4ebc-ba61-4ee6fcfeefb1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f4ae1930-20cf-4ebc-ba61-4ee6fcfeefb1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7d4b3d7e-5d3e-4eb6-b193-b2af4e2d9120\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d4b3d7e-5d3e-4eb6-b193-b2af4e2d9120')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7d4b3d7e-5d3e-4eb6-b193-b2af4e2d9120 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"LSTM\",\n          \"MobileNetV2 (Video)\",\n          \"Random Forest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07622200417550504,\n        \"min\": 0.3240131578947368,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3928571428571428,\n          0.3580246913580246,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09304510727150136,\n        \"min\": 0.3441989141335547,\n        \"max\": 0.5456349206349207,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5456349206349207,\n          0.3441989141335547,\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07622200417550504,\n        \"min\": 0.3240131578947368,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3928571428571428,\n          0.3580246913580246,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05235075976155893,\n        \"min\": 0.289487499418307,\n        \"max\": 0.4121863799283153,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.332512315270936,\n          0.3196837782491791,\n          0.4121863799283153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["#5. Text Model Validation BERT"],"metadata":{"id":"LITOJ6ABSmZp"}},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","# Load your dataset\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","text_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv')\n","\n","# Tokenize the reviews using BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model')\n","\n","# Tokenize and encode the reviews\n","input_ids = []\n","attention_masks = []\n","\n","for review in text_df['Transcription']:\n","    encoded_dict = tokenizer.encode_plus(\n","        review,\n","        add_special_tokens=True,\n","        max_length=64,\n","        truncation=True,  # Explicitly activate truncation\n","        padding='max_length',  # Pad to the max_length\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n","# Load the labels\n","labels = torch.tensor(text_df['Senti'])\n","\n","# Create the dataset\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Split the dataset into training and validation sets\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# Create DataLoader\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# Load pre-trained BERT model for sentiment classification\n","model = BertForSequenceClassification.from_pretrained(\n","    '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model',\n","    num_labels=3,  # 3 classes: neutral, positive, negative\n","    output_attentions=False,\n","    output_hidden_states=False\n",")\n","\n","# Set up optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","\n","# Evaluation loop\n","model.eval()\n","all_labels = []\n","all_preds = []\n","\n","for batch in val_dataloader:\n","    inputs = {\n","        'input_ids': batch[0],\n","        'attention_mask': batch[1],\n","        'labels': batch[2]\n","    }\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    logits = outputs.logits\n","    preds = np.argmax(logits.cpu().numpy(), axis=1)\n","\n","    all_labels.extend(inputs['labels'].cpu().numpy())\n","    all_preds.extend(preds)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(all_labels, all_preds)\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","\n","# Generate confusion matrix\n","conf_matrix = confusion_matrix(all_labels, all_preds)\n","print('Confusion Matrix:')\n","print(conf_matrix)\n","\n","# Print classification report\n","class_report = classification_report(all_labels, all_preds, target_names=['neutral', 'positive', 'negative'])\n","print('Classification Report:')\n","print(class_report)\n","\n","# Prepare results for saving\n","class_report_dict = classification_report(all_labels, all_preds, target_names=['neutral', 'positive', 'negative'], output_dict=True)\n","precision = [class_report_dict[label]['precision'] for label in ['neutral', 'positive', 'negative']]\n","recall = [class_report_dict[label]['recall'] for label in ['neutral', 'positive', 'negative']]\n","f1_score = [class_report_dict[label]['f1-score'] for label in ['neutral', 'positive', 'negative']]\n","\n","# Save the results to a CSV file\n","results_df = pd.DataFrame({\n","    'Model': ['BERT (Text)'],\n","    'Accuracy': [accuracy],\n","    'Precision': [np.mean(precision)],\n","    'Recall': [np.mean(recall)],\n","    'F1 Score': [np.mean(f1_score)]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPGaK9ZGR9tn","executionInfo":{"status":"ok","timestamp":1718274487754,"user_tz":-300,"elapsed":4765,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"8570c01f-b367-470c-89e2-52b3aeb459e8"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 66.67%\n","Confusion Matrix:\n","[[1 0 0]\n"," [0 2 2]\n"," [0 0 1]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","     neutral       1.00      1.00      1.00         1\n","    positive       1.00      0.50      0.67         4\n","    negative       0.33      1.00      0.50         1\n","\n","    accuracy                           0.67         6\n","   macro avg       0.78      0.83      0.72         6\n","weighted avg       0.89      0.67      0.69         6\n","\n","Results saved to /content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","# Read the CSV file\n","df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv')\n","\n","# Display the first 5 rows\n","df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"u6NOPENwTU4k","executionInfo":{"status":"ok","timestamp":1718229280718,"user_tz":-300,"elapsed":484,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"13eeef45-0244-46f2-f6de-5ee7977fb6c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   Model  Accuracy  Precision    Recall  F1 Score\n","0          Random Forest  0.500000   0.375000  0.500000  0.412186\n","1                   LSTM  0.392857   0.545635  0.392857  0.332512\n","2  Random Forest (Video)  0.324013   0.364749  0.324013  0.289487\n","3    MobileNetV2 (Video)  0.358025   0.344199  0.358025  0.319684\n","4            BERT (Text)  0.666667   0.833333  0.666667  0.666667"],"text/html":["\n","  <div id=\"df-7a2c810c-ce18-4f6e-89e7-25c76f8e5275\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>0.500000</td>\n","      <td>0.375000</td>\n","      <td>0.500000</td>\n","      <td>0.412186</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LSTM</td>\n","      <td>0.392857</td>\n","      <td>0.545635</td>\n","      <td>0.392857</td>\n","      <td>0.332512</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Random Forest (Video)</td>\n","      <td>0.324013</td>\n","      <td>0.364749</td>\n","      <td>0.324013</td>\n","      <td>0.289487</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MobileNetV2 (Video)</td>\n","      <td>0.358025</td>\n","      <td>0.344199</td>\n","      <td>0.358025</td>\n","      <td>0.319684</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BERT (Text)</td>\n","      <td>0.666667</td>\n","      <td>0.833333</td>\n","      <td>0.666667</td>\n","      <td>0.666667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a2c810c-ce18-4f6e-89e7-25c76f8e5275')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7a2c810c-ce18-4f6e-89e7-25c76f8e5275 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7a2c810c-ce18-4f6e-89e7-25c76f8e5275');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e5be89d0-89f7-4167-b4fd-67e36c7df4d9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5be89d0-89f7-4167-b4fd-67e36c7df4d9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e5be89d0-89f7-4167-b4fd-67e36c7df4d9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"LSTM\",\n          \"BERT (Text)\",\n          \"Random Forest (Video)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13876927904782813,\n        \"min\": 0.3240131578947368,\n        \"max\": 0.6666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3928571428571428,\n          0.6666666666666666,\n          0.3240131578947368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2068275485329773,\n        \"min\": 0.3441989141335547,\n        \"max\": 0.8333333333333334,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5456349206349207,\n          0.8333333333333334,\n          0.3647485580389329\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13876927904782813,\n        \"min\": 0.3240131578947368,\n        \"max\": 0.6666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3928571428571428,\n          0.6666666666666666,\n          0.3240131578947368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15361767810496177,\n        \"min\": 0.289487499418307,\n        \"max\": 0.6666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.332512315270936,\n          0.6666666666666666,\n          0.289487499418307\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["#6. Text Model Validation BOW"],"metadata":{"id":"sso2ZPZuTMub"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import re\n","import nltk\n","import joblib\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.feature_extraction.text import CountVectorizer\n","import os\n","\n","# Load your dataset\n","text_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv')\n","\n","# Function to remove unwanted characters\n","def removing_unwanted_data(text):\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\<a href', ' ', text)\n","    text = re.sub(r'&amp;', '', text)\n","    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n","    text = re.sub(r'<br />', ' ', text)\n","    text = re.sub(r'\\'', ' ', text)\n","    text = nltk.WordPunctTokenizer().tokenize(text)\n","    return text\n","\n","# Apply preprocessing\n","text_df['text_cleaned'] = text_df['Transcription'].map(removing_unwanted_data)\n","\n","# Custom tokenizer function\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Load the saved vectorizer and model\n","vectorizer_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl'\n","model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl'\n","\n","vectorizer = joblib.load(vectorizer_path)\n","model = joblib.load(model_path)\n","\n","# Transform the data using the loaded vectorizer\n","X = vectorizer.transform(text_df['text_cleaned'])\n","y = text_df['Senti']\n","\n","# Evaluate the loaded model\n","y_pred = model.predict(X)\n","accuracy = accuracy_score(y, y_pred)\n","precision = precision_score(y, y_pred, average='weighted')\n","recall = recall_score(y, y_pred, average='weighted')\n","f1 = f1_score(y, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","# Generate confusion matrix\n","conf_matrix = confusion_matrix(y, y_pred)\n","print('Confusion Matrix:')\n","print(conf_matrix)\n","\n","# Prepare results for saving\n","results_df = pd.DataFrame({\n","    'Model': ['BOW Logistic Regression (Text)'],\n","    'Accuracy': [accuracy],\n","    'Precision': [precision],\n","    'Recall': [recall],\n","    'F1 Score': [f1]\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNUysxKbSs5q","executionInfo":{"status":"ok","timestamp":1718274487755,"user_tz":-300,"elapsed":54,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"a8eff4c2-dddf-463f-b903-3a10ae9481b7"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 58.62%\n","Precision: 0.60\n","Recall: 0.59\n","F1 Score: 0.58\n","Confusion Matrix:\n","[[0 1 1]\n"," [1 8 2]\n"," [0 7 9]]\n","Results saved to /content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","# Read the CSV file\n","df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation.csv')\n","\n","# Display the first 5 rows\n","df.head(10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"tk2FbyPUTHHz","executionInfo":{"status":"ok","timestamp":1718274487755,"user_tz":-300,"elapsed":46,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"e9bbb449-bf34-4025-8677-36c86d326e84"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            Model  Accuracy  Precision    Recall  F1 Score\n","0                   Random Forest  0.500000   0.375000  0.500000  0.412186\n","1                            LSTM  0.392857   0.545635  0.392857  0.332512\n","2           Random Forest (Video)  0.561039   0.571987  0.561039  0.530425\n","3             MobileNetV2 (Video)  0.522078   0.635805  0.522078  0.503028\n","4                     BERT (Text)  0.666667   0.777778  0.833333  0.722222\n","5  BOW Logistic Regression (Text)  0.586207   0.603448  0.586207  0.579456"],"text/html":["\n","  <div id=\"df-2af9a95a-4821-4f83-ad6d-6f4450e21840\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>0.500000</td>\n","      <td>0.375000</td>\n","      <td>0.500000</td>\n","      <td>0.412186</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LSTM</td>\n","      <td>0.392857</td>\n","      <td>0.545635</td>\n","      <td>0.392857</td>\n","      <td>0.332512</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Random Forest (Video)</td>\n","      <td>0.561039</td>\n","      <td>0.571987</td>\n","      <td>0.561039</td>\n","      <td>0.530425</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MobileNetV2 (Video)</td>\n","      <td>0.522078</td>\n","      <td>0.635805</td>\n","      <td>0.522078</td>\n","      <td>0.503028</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BERT (Text)</td>\n","      <td>0.666667</td>\n","      <td>0.777778</td>\n","      <td>0.833333</td>\n","      <td>0.722222</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>BOW Logistic Regression (Text)</td>\n","      <td>0.586207</td>\n","      <td>0.603448</td>\n","      <td>0.586207</td>\n","      <td>0.579456</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2af9a95a-4821-4f83-ad6d-6f4450e21840')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2af9a95a-4821-4f83-ad6d-6f4450e21840 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2af9a95a-4821-4f83-ad6d-6f4450e21840');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d99ee8fe-871b-4864-8e92-8bd21fb6d020\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d99ee8fe-871b-4864-8e92-8bd21fb6d020')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d99ee8fe-871b-4864-8e92-8bd21fb6d020 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Random Forest\",\n          \"LSTM\",\n          \"BOW Logistic Regression (Text)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09184078780410138,\n        \"min\": 0.3928571428571428,\n        \"max\": 0.6666666666666666,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5,\n          0.3928571428571428,\n          0.5862068965517241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1310753308146861,\n        \"min\": 0.375,\n        \"max\": 0.7777777777777778,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.375,\n          0.5456349206349207,\n          0.603448275862069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1470806583279796,\n        \"min\": 0.3928571428571428,\n        \"max\": 0.8333333333333334,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5,\n          0.3928571428571428,\n          0.5862068965517241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1351533041986757,\n        \"min\": 0.332512315270936,\n        \"max\": 0.7222222222222222,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4121863799283153,\n          0.332512315270936,\n          0.5794563035942346\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":75}]},{"cell_type":"markdown","source":["#Prediction labels by BOW"],"metadata":{"id":"b1AH_QPRT8Qn"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import re\n","import nltk\n","import joblib\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.feature_extraction.text import CountVectorizer\n","import os\n","\n","# Load your dataset\n","text_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv')\n","\n","# Function to remove unwanted characters\n","def removing_unwanted_data(text):\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\<a href', ' ', text)\n","    text = re.sub(r'&amp;', '', text)\n","    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n","    text = re.sub(r'<br />', ' ', text)\n","    text = re.sub(r'\\'', ' ', text)\n","    text = nltk.WordPunctTokenizer().tokenize(text)\n","    return text\n","\n","# Apply preprocessing\n","text_df['text_cleaned'] = text_df['Transcription'].map(removing_unwanted_data)\n","\n","# Load the saved vectorizer and model\n","vectorizer_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl'\n","model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl'\n","\n","vectorizer = joblib.load(vectorizer_path)\n","model = joblib.load(model_path)\n","\n","# Transform the data using the loaded vectorizer\n","X = vectorizer.transform(text_df['text_cleaned'])\n","y = text_df['Senti']\n","\n","# Evaluate the loaded model using the entire dataset for testing\n","y_pred = model.predict(X)\n","accuracy = accuracy_score(y, y_pred)\n","precision = precision_score(y, y_pred, average='weighted', zero_division=1)\n","recall = recall_score(y, y_pred, average='weighted', zero_division=1)\n","f1 = f1_score(y, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","# Create a DataFrame to hold file names, actual labels, and predicted labels\n","results_df = pd.DataFrame({\n","    'Text File': text_df['File'],  # Assuming 'File' column has the audio file names\n","    'Actual Label': y,\n","    'Predicted Label': y_pred\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/prediction_label_by_bow.csv'\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(\"Model evaluation metrics and results saved successfully.\")\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W162HEVOT7Sw","executionInfo":{"status":"ok","timestamp":1718262041229,"user_tz":-300,"elapsed":369,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"80bfd4df-1ee5-4e21-f679-59a7ee821bef"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 41.38%\n","Precision: 0.33\n","Recall: 0.41\n","F1 Score: 0.36\n","Model evaluation metrics and results saved successfully.\n","                                            Text File  Actual Label  \\\n","0                               1. Mobile_Neutral.wav             0   \n","1              1. Mobile__Positive_Product_Review.wav             0   \n","2                  1. Tea_Negative_Product_Review.wav             2   \n","3      10. Blasphemy_Negative_Perception_Building.wav             2   \n","4   10. Political Extremisim_Negative_Perception_B...             2   \n","5      11. Blasphemy_Negative_Perception_Building.wav             2   \n","6   11. Political Extremisim_Negative_Perception_B...             2   \n","7    2. Communication_Neutral_Perception Building.wav             0   \n","8               2. Mobile_Positive_Product_Review.wav             1   \n","9                  2. Tea_Negative_Product_Review.wav             0   \n","10   3. Communication_Neutral_Perception Building.wav             0   \n","11                 3. ICE_Negative_Product_Review.wav             2   \n","12              3. Mobile_Positive_Product_Review.wav             1   \n","13                 4. ICE_Negative_Product_Review.wav             2   \n","14                  4. ICE_Neutral_Product_Review.wav             1   \n","15           4. Olive Oil_Positive_Product_Review.wav             1   \n","16       5. Blasphemy_Neutral_Perception_Building.wav             0   \n","17  5. Honor Killing_Negative_Perception_Building.wav             2   \n","18                 5. ICE_Positive_Product_Review.wav             1   \n","19                  5.ICE_Negative_Product_Review.wav             2   \n","20  6. Honor_Killing_Negative_Perception_Building.wav             2   \n","21                 6. ICE_Positive_Product_Review.wav             1   \n","22    6. Social Media_Neutral_Perception_Building.wav             0   \n","23      7. Blasphemy_Negative_Perception_Building.wav             2   \n","24  7. Political Extremisim_Neutral_Perception_Bui...             0   \n","25      8. Blasphemy_Negative_Perception_Building.wav             2   \n","26  8. Blasphemy_Neutral_Perception_Building_by_Im...             1   \n","27  8. Communication_Positive_Perception_Building.wav             0   \n","28  9. Blasphemy_Negative_Perception_Building (1).wav             1   \n","\n","    Predicted Label  \n","0                 1  \n","1                 1  \n","2                 2  \n","3                 2  \n","4                 2  \n","5                 1  \n","6                 2  \n","7                 1  \n","8                 1  \n","9                 1  \n","10                2  \n","11                1  \n","12                1  \n","13                1  \n","14                0  \n","15                1  \n","16                1  \n","17                2  \n","18                1  \n","19                1  \n","20                2  \n","21                1  \n","22                2  \n","23                2  \n","24                1  \n","25                1  \n","26                2  \n","27                2  \n","28                2  \n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":959},"id":"xT9kIYQ3VdTQ","executionInfo":{"status":"ok","timestamp":1718262061888,"user_tz":-300,"elapsed":386,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"a59f1c89-837d-4b23-a9c7-43018b440cdb"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            Text File  Actual Label  \\\n","0                               1. Mobile_Neutral.wav             0   \n","1              1. Mobile__Positive_Product_Review.wav             0   \n","2                  1. Tea_Negative_Product_Review.wav             2   \n","3      10. Blasphemy_Negative_Perception_Building.wav             2   \n","4   10. Political Extremisim_Negative_Perception_B...             2   \n","5      11. Blasphemy_Negative_Perception_Building.wav             2   \n","6   11. Political Extremisim_Negative_Perception_B...             2   \n","7    2. Communication_Neutral_Perception Building.wav             0   \n","8               2. Mobile_Positive_Product_Review.wav             1   \n","9                  2. Tea_Negative_Product_Review.wav             0   \n","10   3. Communication_Neutral_Perception Building.wav             0   \n","11                 3. ICE_Negative_Product_Review.wav             2   \n","12              3. Mobile_Positive_Product_Review.wav             1   \n","13                 4. ICE_Negative_Product_Review.wav             2   \n","14                  4. ICE_Neutral_Product_Review.wav             1   \n","15           4. Olive Oil_Positive_Product_Review.wav             1   \n","16       5. Blasphemy_Neutral_Perception_Building.wav             0   \n","17  5. Honor Killing_Negative_Perception_Building.wav             2   \n","18                 5. ICE_Positive_Product_Review.wav             1   \n","19                  5.ICE_Negative_Product_Review.wav             2   \n","20  6. Honor_Killing_Negative_Perception_Building.wav             2   \n","21                 6. ICE_Positive_Product_Review.wav             1   \n","22    6. Social Media_Neutral_Perception_Building.wav             0   \n","23      7. Blasphemy_Negative_Perception_Building.wav             2   \n","24  7. Political Extremisim_Neutral_Perception_Bui...             0   \n","25      8. Blasphemy_Negative_Perception_Building.wav             2   \n","26  8. Blasphemy_Neutral_Perception_Building_by_Im...             1   \n","27  8. Communication_Positive_Perception_Building.wav             0   \n","28  9. Blasphemy_Negative_Perception_Building (1).wav             1   \n","\n","    Predicted Label  \n","0                 1  \n","1                 1  \n","2                 2  \n","3                 2  \n","4                 2  \n","5                 1  \n","6                 2  \n","7                 1  \n","8                 1  \n","9                 1  \n","10                2  \n","11                1  \n","12                1  \n","13                1  \n","14                0  \n","15                1  \n","16                1  \n","17                2  \n","18                1  \n","19                1  \n","20                2  \n","21                1  \n","22                2  \n","23                2  \n","24                1  \n","25                1  \n","26                2  \n","27                2  \n","28                2  "],"text/html":["\n","  <div id=\"df-423fa67b-4b3d-424e-b996-9ae60f8eb035\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text File</th>\n","      <th>Actual Label</th>\n","      <th>Predicted Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1. Mobile_Neutral.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1. Mobile__Positive_Product_Review.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1. Tea_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10. Political Extremisim_Negative_Perception_B...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>11. Political Extremisim_Negative_Perception_B...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2. Communication_Neutral_Perception Building.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2. Mobile_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2. Tea_Negative_Product_Review.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>3. Communication_Neutral_Perception Building.wav</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>3. ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3. Mobile_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>4. ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>4. ICE_Neutral_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>4. Olive Oil_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>5. Blasphemy_Neutral_Perception_Building.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>5. Honor Killing_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>5. ICE_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>5.ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>6. Honor_Killing_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>6. ICE_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>6. Social Media_Neutral_Perception_Building.wav</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>7. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>7. Political Extremisim_Neutral_Perception_Bui...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>8. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>8. Blasphemy_Neutral_Perception_Building_by_Im...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>8. Communication_Positive_Perception_Building.wav</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>9. Blasphemy_Negative_Perception_Building (1).wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-423fa67b-4b3d-424e-b996-9ae60f8eb035')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-423fa67b-4b3d-424e-b996-9ae60f8eb035 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-423fa67b-4b3d-424e-b996-9ae60f8eb035');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5908f01e-06f4-42b3-aa17-919b06905a54\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5908f01e-06f4-42b3-aa17-919b06905a54')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5908f01e-06f4-42b3-aa17-919b06905a54 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 29,\n  \"fields\": [\n    {\n      \"column\": \"Text File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"8. Communication_Positive_Perception_Building.wav\",\n          \"5. Blasphemy_Neutral_Perception_Building.wav\",\n          \"3. Mobile_Positive_Product_Review.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["results_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"3F6hF2pUUI7g","executionInfo":{"status":"ok","timestamp":1718260638204,"user_tz":-300,"elapsed":406,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"9d0e7639-c743-42e2-e854-045cca3bba29"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            Model  Accuracy  Precision    Recall  F1 Score  \\\n","0  BOW Logistic Regression (Text)  0.333333   0.166667  0.333333  0.222222   \n","\n","        Actual Labels    Predicted Labels  \n","0  [0, 0, 1, 0, 1, 0]  [2, 1, 1, 2, 1, 1]  "],"text/html":["\n","  <div id=\"df-706e5673-8d45-4006-a03a-a4cfdf1788bc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","      <th>Actual Labels</th>\n","      <th>Predicted Labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BOW Logistic Regression (Text)</td>\n","      <td>0.333333</td>\n","      <td>0.166667</td>\n","      <td>0.333333</td>\n","      <td>0.222222</td>\n","      <td>[0, 0, 1, 0, 1, 0]</td>\n","      <td>[2, 1, 1, 2, 1, 1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-706e5673-8d45-4006-a03a-a4cfdf1788bc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-706e5673-8d45-4006-a03a-a4cfdf1788bc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-706e5673-8d45-4006-a03a-a4cfdf1788bc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"BOW Logistic Regression (Text)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3333333333333333,\n        \"max\": 0.3333333333333333,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.16666666666666666,\n        \"max\": 0.16666666666666666,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.16666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3333333333333333,\n        \"max\": 0.3333333333333333,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2222222222222222,\n        \"max\": 0.2222222222222222,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2222222222222222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","# Load your dataset\n","text_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv')\n","\n","# Initialize BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model')\n","\n","# Prepare input data\n","input_ids = []\n","attention_masks = []\n","\n","for sentence in text_df['Transcription']:\n","    encoded_dict = tokenizer.encode_plus(\n","        sentence,                      # Sentence to encode.\n","        add_special_tokens = True,     # Add '[CLS]' and '[SEP]'\n","        max_length = 64,               # Pad & truncate all sentences.\n","        pad_to_max_length = True,\n","        return_attention_mask = True,  # Construct attention masks.\n","        return_tensors = 'pt',         # Return pytorch tensors.\n","    )\n","\n","    # Add the encoded sentence to the list.\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(text_df['Senti'].values)\n","\n","# Create the TensorDataset\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create DataLoader\n","data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n","\n","# Load BERT model for sequence classification.\n","model = BertForSequenceClassification.from_pretrained(\n","    '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model',\n","    num_labels = 3,  # The number of output labels.\n","    output_attentions = False,  # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Prediction on the dataset\n","model.eval()  # Evaluation mode\n","all_labels = []\n","all_preds = []\n","\n","for batch in data_loader:\n","    batch = tuple(t.to('cuda') if torch.cuda.is_available() else t.to('cpu') for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    with torch.no_grad():\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    logits = outputs.logits\n","    preds = torch.argmax(logits, dim=1).cpu().numpy()\n","    labels = b_labels.cpu().numpy()\n","\n","    all_labels.extend(labels)\n","    all_preds.extend(preds)\n","\n","# Prepare DataFrame to save results\n","results_df = pd.DataFrame({\n","    'Text File': text_df['File'],  # Assuming 'File' column contains the names of the text files\n","    'Actual Label': all_labels,\n","    'Predicted Label': all_preds\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/prediction_label_by_BERT.csv'\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(\"Model evaluation metrics and results saved successfully.\")\n","print(results_df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AH7WNkp6F-7M","executionInfo":{"status":"ok","timestamp":1718273732238,"user_tz":-300,"elapsed":23453,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"89dcba07-de4d-4d00-fa8b-0e2629e8883a"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model evaluation metrics and results saved successfully.\n","                                           Text File  Actual Label  \\\n","0                              1. Mobile_Neutral.wav             1   \n","1             1. Mobile__Positive_Product_Review.wav             1   \n","2                 1. Tea_Negative_Product_Review.wav             2   \n","3     10. Blasphemy_Negative_Perception_Building.wav             2   \n","4  10. Political Extremisim_Negative_Perception_B...             2   \n","\n","   Predicted Label  \n","0                2  \n","1                1  \n","2                2  \n","3                0  \n","4                1  \n"]}]},{"cell_type":"code","source":["results_df.head(30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":959},"id":"ogGITYbUGLB6","executionInfo":{"status":"ok","timestamp":1718273754575,"user_tz":-300,"elapsed":623,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"e8c90c40-fac0-4478-968d-ac04d487c1f9"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            Text File  Actual Label  \\\n","0                               1. Mobile_Neutral.wav             1   \n","1              1. Mobile__Positive_Product_Review.wav             1   \n","2                  1. Tea_Negative_Product_Review.wav             2   \n","3      10. Blasphemy_Negative_Perception_Building.wav             2   \n","4   10. Political Extremisim_Negative_Perception_B...             2   \n","5      11. Blasphemy_Negative_Perception_Building.wav             1   \n","6   11. Political Extremisim_Negative_Perception_B...             2   \n","7    2. Communication_Neutral_Perception Building.wav             1   \n","8               2. Mobile_Positive_Product_Review.wav             1   \n","9                  2. Tea_Negative_Product_Review.wav             0   \n","10   3. Communication_Neutral_Perception Building.wav             0   \n","11                 3. ICE_Negative_Product_Review.wav             2   \n","12              3. Mobile_Positive_Product_Review.wav             1   \n","13                 4. ICE_Negative_Product_Review.wav             2   \n","14                  4. ICE_Neutral_Product_Review.wav             0   \n","15           4. Olive Oil_Positive_Product_Review.wav             1   \n","16       5. Blasphemy_Neutral_Perception_Building.wav             0   \n","17  5. Honor Killing_Negative_Perception_Building.wav             2   \n","18                 5. ICE_Positive_Product_Review.wav             1   \n","19                  5.ICE_Negative_Product_Review.wav             2   \n","20  6. Honor_Killing_Negative_Perception_Building.wav             2   \n","21                 6. ICE_Positive_Product_Review.wav             1   \n","22    6. Social Media_Neutral_Perception_Building.wav             0   \n","23      7. Blasphemy_Negative_Perception_Building.wav             1   \n","24  7. Political Extremisim_Neutral_Perception_Bui...             1   \n","25      8. Blasphemy_Negative_Perception_Building.wav             2   \n","26  8. Blasphemy_Neutral_Perception_Building_by_Im...             2   \n","27  8. Communication_Positive_Perception_Building.wav             2   \n","28  9. Blasphemy_Negative_Perception_Building (1).wav             2   \n","\n","    Predicted Label  \n","0                 2  \n","1                 1  \n","2                 2  \n","3                 0  \n","4                 1  \n","5                 2  \n","6                 2  \n","7                 2  \n","8                 2  \n","9                 1  \n","10                0  \n","11                2  \n","12                2  \n","13                2  \n","14                1  \n","15                2  \n","16                2  \n","17                2  \n","18                1  \n","19                1  \n","20                2  \n","21                1  \n","22                1  \n","23                1  \n","24                1  \n","25                1  \n","26                2  \n","27                1  \n","28                1  "],"text/html":["\n","  <div id=\"df-196d3632-9f03-45da-834b-5e130cfabeab\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text File</th>\n","      <th>Actual Label</th>\n","      <th>Predicted Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1. Mobile_Neutral.wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1. Mobile__Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1. Tea_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10. Political Extremisim_Negative_Perception_B...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>11. Political Extremisim_Negative_Perception_B...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2. Communication_Neutral_Perception Building.wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2. Mobile_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2. Tea_Negative_Product_Review.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>3. Communication_Neutral_Perception Building.wav</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>3. ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3. Mobile_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>4. ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>4. ICE_Neutral_Product_Review.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>4. Olive Oil_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>5. Blasphemy_Neutral_Perception_Building.wav</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>5. Honor Killing_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>5. ICE_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>5.ICE_Negative_Product_Review.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>6. Honor_Killing_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>6. ICE_Positive_Product_Review.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>6. Social Media_Neutral_Perception_Building.wav</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>7. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>7. Political Extremisim_Neutral_Perception_Bui...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>8. Blasphemy_Negative_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>8. Blasphemy_Neutral_Perception_Building_by_Im...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>8. Communication_Positive_Perception_Building.wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>9. Blasphemy_Negative_Perception_Building (1).wav</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-196d3632-9f03-45da-834b-5e130cfabeab')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-196d3632-9f03-45da-834b-5e130cfabeab button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-196d3632-9f03-45da-834b-5e130cfabeab');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3c0419f2-8670-49c4-a919-a9d69c6ac6e7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c0419f2-8670-49c4-a919-a9d69c6ac6e7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3c0419f2-8670-49c4-a919-a9d69c6ac6e7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 29,\n  \"fields\": [\n    {\n      \"column\": \"Text File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"8. Communication_Positive_Perception_Building.wav\",\n          \"5. Blasphemy_Neutral_Perception_Building.wav\",\n          \"3. Mobile_Positive_Product_Review.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from skimage.feature import hog\n","import joblib\n","import os\n","\n","# Load the CSV files\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","frames_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Filter frames_df to only include key frames\n","frames_df = frames_df[frames_df['Key_Frame'] == 'Y']\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    if not os.path.exists(filepath):\n","        print(f\"File not found: {filepath}\")\n","        return None\n","    img = cv2.imread(filepath)\n","    if img is None:\n","        print(f\"Failed to read image: {filepath}\")\n","        return None\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = cv2.resize(img, (128, 128))\n","    img = cv2.equalizeHist(img)\n","    return img\n","\n","# Apply preprocessing to each image and prepare labels\n","images = []\n","labels = []\n","frame_paths = []  # List to keep track of frame paths for results\n","video_names = []  # List to store corresponding video names\n","\n","for idx, row in frames_df.iterrows():\n","    video_name = row['Video Name'].replace('.wav', '')\n","    frame_path = row['Frame Path']\n","    # Check if the frame path contains the video name\n","    if video_name in frame_path:\n","        processed_img = preprocess_image(frame_path)\n","        if processed_img is not None:\n","            images.append(processed_img)\n","            labels.append(row['Senti'])\n","            frame_paths.append(frame_path)  # Store the frame path\n","            video_names.append(video_name)  # Store the video name without .wav extension\n","\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","# Extract HOG features from the images\n","hog_features = [hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys') for image in images]\n","\n","# Load the saved model\n","joblib_file = \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\"\n","loaded_rf_model = joblib.load(joblib_file)\n","\n","# Evaluate the model\n","y_pred = loaded_rf_model.predict(hog_features)\n","\n","# Prepare results for saving\n","results_df = pd.DataFrame({\n","    'Video Name': video_names,\n","    'Frame Path': frame_paths,\n","    'Actual Sentiment': labels,\n","    'Predicted Sentiment': y_pred\n","})\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/frame_pediction_video.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    results_df = pd.concat([existing_df, results_df], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2A51Dzv5bY1p","executionInfo":{"status":"ok","timestamp":1718263854567,"user_tz":-300,"elapsed":15537,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"2bb71ea5-1712-4511-a909-b1458426f6b1"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Results saved to /content/drive/MyDrive/work2/Validation_Data/frame_pediction_video.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file\n","df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/frame_pediction_video.csv')\n","\n","# Display the first 5 rows\n","df.head(1000)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"V7IJbjpee62h","executionInfo":{"status":"ok","timestamp":1718264648110,"user_tz":-300,"elapsed":400,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"7f2a7379-ba2f-4811-cb8d-0ef4d0846379"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        Video Name  \\\n","0                                1. Mobile_Neutral   \n","1                                1. Mobile_Neutral   \n","2                                1. Mobile_Neutral   \n","3                                1. Mobile_Neutral   \n","4                                1. Mobile_Neutral   \n","..                                             ...   \n","402  9. Blasphemy_Negative_Perception_Building (1)   \n","403  9. Blasphemy_Negative_Perception_Building (1)   \n","404  9. Blasphemy_Negative_Perception_Building (1)   \n","405  9. Blasphemy_Negative_Perception_Building (1)   \n","406  9. Blasphemy_Negative_Perception_Building (1)   \n","\n","                                            Frame Path  Actual Sentiment  \\\n","0    /content/drive/MyDrive/work2/Validation_Data/V...                 0   \n","1    /content/drive/MyDrive/work2/Validation_Data/V...                 0   \n","2    /content/drive/MyDrive/work2/Validation_Data/V...                 0   \n","3    /content/drive/MyDrive/work2/Validation_Data/V...                 0   \n","4    /content/drive/MyDrive/work2/Validation_Data/V...                 0   \n","..                                                 ...               ...   \n","402  /content/drive/MyDrive/work2/Validation_Data/V...                 0   \n","403  /content/drive/MyDrive/work2/Validation_Data/V...                 2   \n","404  /content/drive/MyDrive/work2/Validation_Data/V...                 2   \n","405  /content/drive/MyDrive/work2/Validation_Data/V...                 1   \n","406  /content/drive/MyDrive/work2/Validation_Data/V...                 2   \n","\n","     Predicted Sentiment  \n","0                      2  \n","1                      2  \n","2                      2  \n","3                      2  \n","4                      2  \n","..                   ...  \n","402                    0  \n","403                    0  \n","404                    0  \n","405                    2  \n","406                    2  \n","\n","[407 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-8f2038de-4876-4bd0-82ae-40ccc908ef62\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video Name</th>\n","      <th>Frame Path</th>\n","      <th>Actual Sentiment</th>\n","      <th>Predicted Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1. Mobile_Neutral</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1. Mobile_Neutral</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1. Mobile_Neutral</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1. Mobile_Neutral</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1. Mobile_Neutral</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>9. Blasphemy_Negative_Perception_Building (1)</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>403</th>\n","      <td>9. Blasphemy_Negative_Perception_Building (1)</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>404</th>\n","      <td>9. Blasphemy_Negative_Perception_Building (1)</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>9. Blasphemy_Negative_Perception_Building (1)</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>406</th>\n","      <td>9. Blasphemy_Negative_Perception_Building (1)</td>\n","      <td>/content/drive/MyDrive/work2/Validation_Data/V...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>407 rows  4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f2038de-4876-4bd0-82ae-40ccc908ef62')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8f2038de-4876-4bd0-82ae-40ccc908ef62 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8f2038de-4876-4bd0-82ae-40ccc908ef62');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-78dc299b-a5b0-475f-b2d6-5dc95419b514\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78dc299b-a5b0-475f-b2d6-5dc95419b514')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-78dc299b-a5b0-475f-b2d6-5dc95419b514 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 407,\n  \"fields\": [\n    {\n      \"column\": \"Video Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"8. Communication_Positive_Perception_Building\",\n          \"5. Blasphemy_Neutral_Perception_Building\",\n          \"3. Mobile_Positive_Product_Review\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frame Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 407,\n        \"samples\": [\n          \"/content/drive/MyDrive/work2/Validation_Data/Validation_All_Frames/10. Political Extremisim_Negative_Perception_Building/10_frame_86.jpg\",\n          \"/content/drive/MyDrive/work2/Validation_Data/Validation_All_Frames/4. ICE_Neutral_Product_Review/4_frame_83.jpg\",\n          \"/content/drive/MyDrive/work2/Validation_Data/Validation_All_Frames/5.ICE_Negative_Product_Review/5_frame_19.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","import os\n","\n","# Load the CSV files\n","video_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","frames_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    if not os.path.exists(filepath):\n","        print(f\"File not found: {filepath}\")\n","        return None\n","    img = cv2.imread(filepath)\n","    if img is None:\n","        print(f\"Failed to read image: {filepath}\")\n","        return None\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img, (224, 224))  # Resize to match MobileNetV2 input\n","    img = preprocess_input(img)  # Preprocess as per MobileNetV2 requirements\n","    return img\n","\n","# Load the saved TensorFlow model\n","model_path = '/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5'\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# List to store results\n","results = []\n","\n","# Process each video\n","for video_name in video_df['File']:\n","    video_base_name = video_name.replace('.wav', '')\n","\n","    # Filter frames related to the current video and are key frames\n","    video_frames = frames_df[(frames_df['Video Name'].str.replace('.wav', '') == video_base_name) & (frames_df['Key_Frame'] == 'Y')]\n","\n","    # Check if there are any key frames for this video\n","    if video_frames.empty:\n","        print(f\"No key frames found for video: {video_name}\")\n","        continue\n","\n","    # Apply preprocessing to each image and prepare features\n","    for frame_path, true_label in zip(video_frames['Frame Path'], video_frames['Senti']):\n","        processed_img = preprocess_image(frame_path)\n","        if processed_img is not None:\n","            video_image = np.expand_dims(processed_img, axis=0)\n","            video_pred = loaded_model.predict(video_image)[0]\n","            predicted_label = np.argmax(video_pred)\n","            results.append({\n","                'Text File': frame_path,\n","                'Actual Label': true_label,\n","                'Predicted Label': predicted_label\n","            })\n","\n","# Convert results to DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Path to the results file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/Frame_Prediction_Results_CNN.csv'\n","\n","# Save the DataFrame to the CSV file\n","results_df.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESKCLDQw5F7x","executionInfo":{"status":"ok","timestamp":1718270431401,"user_tz":-300,"elapsed":80133,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"8a5993ba-7828-49d0-9909-a194e5fc0e3c"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 2s 2s/step\n","1/1 [==============================] - 0s 105ms/step\n","1/1 [==============================] - 0s 94ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 126ms/step\n","1/1 [==============================] - 0s 137ms/step\n","1/1 [==============================] - 0s 115ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 121ms/step\n","1/1 [==============================] - 0s 151ms/step\n","1/1 [==============================] - 0s 163ms/step\n","1/1 [==============================] - 0s 196ms/step\n","1/1 [==============================] - 0s 145ms/step\n","1/1 [==============================] - 0s 169ms/step\n","1/1 [==============================] - 0s 101ms/step\n","1/1 [==============================] - 0s 165ms/step\n","1/1 [==============================] - 0s 117ms/step\n","1/1 [==============================] - 0s 163ms/step\n","1/1 [==============================] - 0s 175ms/step\n","1/1 [==============================] - 0s 222ms/step\n","1/1 [==============================] - 0s 168ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 69ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 79ms/step\n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 94ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 112ms/step\n","1/1 [==============================] - 0s 96ms/step\n","1/1 [==============================] - 0s 104ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 82ms/step\n","1/1 [==============================] - 0s 121ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 78ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 104ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 96ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 100ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 102ms/step\n","1/1 [==============================] - 0s 107ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 118ms/step\n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 81ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 91ms/step\n","1/1 [==============================] - 0s 126ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 94ms/step\n","1/1 [==============================] - 0s 103ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 100ms/step\n","1/1 [==============================] - 0s 92ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 113ms/step\n","1/1 [==============================] - 0s 89ms/step\n","1/1 [==============================] - 0s 100ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 61ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 83ms/step\n","1/1 [==============================] - 0s 101ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 96ms/step\n","1/1 [==============================] - 0s 90ms/step\n","1/1 [==============================] - 0s 78ms/step\n","1/1 [==============================] - 0s 97ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 88ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 93ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 84ms/step\n","1/1 [==============================] - 0s 87ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 95ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 99ms/step\n","1/1 [==============================] - 0s 108ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 67ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 60ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 72ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 51ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 62ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 54ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 55ms/step\n","No key frames found for video: 9. Blasphemy_Negative_Perception_Building.wav\n","Results saved to /content/drive/MyDrive/work2/Validation_Data/Frame_Prediction_Results_CNN.csv\n"]}]},{"cell_type":"markdown","source":["# **Table Creation for Sentiment Classfication based on 1 Video & its corresponding modalities (Audio,Text, Frame)**"],"metadata":{"id":"FeDYHPAcV2zR"}},{"cell_type":"markdown","source":["##Snippet 1: Audio Model 1 (LSTM)"],"metadata":{"id":"Sp7DCIMbWI0-"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import librosa\n","import tensorflow as tf\n","import joblib\n","\n","# Load your datasets\n","audio_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv')\n","\n","# Get the first audio file\n","first_audio_file = audio_df.iloc[0]['File']\n","\n","# Load the pre-trained model and scaler\n","audio_model_path = '/content/drive/MyDrive/work2/Final/Old_audio_models/Audio_Model_1_LSTM.h5'\n","audio_scaler_path = '/content/drive/MyDrive/work2/Final/Old_audio_models/scaler_lstm.pkl'\n","audio_model = tf.keras.models.load_model(audio_model_path)\n","audio_scaler = joblib.load(audio_scaler_path)\n","\n","# Helper function for audio feature extraction\n","def preprocess_audio(file_path):\n","    y, sr = librosa.load(file_path, duration=3)\n","    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n","    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n","    contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n","    bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr), axis=1)\n","    energy_contour = np.mean(librosa.feature.rms(y=y), axis=1)\n","    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr), axis=1)\n","    return np.concatenate((mfccs, mel, contrast, bandwidth, energy_contour, spectral_rolloff))\n","\n","# Predict audio sentiment\n","audio_path = '/content/drive/MyDrive/work2/Validation_Data/Audios/' + first_audio_file\n","audio_features = preprocess_audio(audio_path)\n","audio_features_scaled = audio_scaler.transform([audio_features])\n","audio_features_scaled = np.expand_dims(audio_features_scaled, -1)\n","audio_pred = audio_model.predict(audio_features_scaled)[0]\n","audio_sentiment = np.argmax(audio_pred)\n","audio_percentage = audio_pred[audio_sentiment]\n","\n","# Save results to a DataFrame\n","results_df_audio1 = pd.DataFrame({\n","    'Modality': ['Audio Model 1'],\n","    'Sentiment': ['neutral' if audio_sentiment == 0 else 'positive' if audio_sentiment == 1 else 'negative'],\n","    'Percentage': [audio_percentage]\n","})\n","\n","# Save to CSV for combining later\n","results_df_audio1.to_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_audio1.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQrLuePFV9pC","executionInfo":{"status":"ok","timestamp":1718259862351,"user_tz":-300,"elapsed":37628,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"07f1b179-6047-4d13-ec34-f04a76661728"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 846ms/step\n"]}]},{"cell_type":"markdown","source":["##Snippet 2: Audio Model 2 (Random Forest)"],"metadata":{"id":"YXSiB4yXYJqG"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import librosa\n","import joblib\n","\n","# Load your datasets\n","audio_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Audio.csv')\n","\n","# Get the first audio file\n","first_audio_file = audio_df.iloc[0]['File']\n","\n","# Load the pre-trained model and scaler\n","audio_model_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest.joblib'\n","audio_scaler_path = '/content/drive/MyDrive/work2/Final/Audio_Models/Audio_Model_2_RandomForest_Scaler.joblib'\n","audio_model = joblib.load(audio_model_path)\n","audio_scaler = joblib.load(audio_scaler_path)\n","\n","# Helper function for audio feature extraction\n","def preprocess_audio(file_path):\n","    y, sr = librosa.load(file_path, duration=3)\n","    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)\n","    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)\n","    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)\n","    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n","    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr), axis=1)\n","    return np.concatenate((mfccs, chroma, mel, spectral_contrast, tonnetz))\n","\n","# Predict audio sentiment\n","audio_path = '/content/drive/MyDrive/work2/Validation_Data/Audios/' + first_audio_file\n","audio_features = preprocess_audio(audio_path)\n","\n","# Ensure the feature vector has the correct shape\n","if audio_features.shape[0] == 151:\n","    audio_features = np.pad(audio_features, (0, 15), 'constant')  # Assuming 15 features are missing\n","elif audio_features.shape[0] == 166:\n","    audio_features = audio_features[:166]  # Assuming extra features need to be trimmed\n","else:\n","    raise ValueError(f\"Unexpected number of features: {audio_features.shape[0]}\")\n","\n","audio_features_scaled = audio_scaler.transform([audio_features])\n","audio_pred = audio_model.predict_proba(audio_features_scaled)[0]\n","audio_sentiment = np.argmax(audio_pred)\n","audio_percentage = audio_pred[audio_sentiment]\n","\n","# Save results to a DataFrame\n","results_df_audio2 = pd.DataFrame({\n","    'Modality': ['Audio Model 2'],\n","    'Sentiment': ['neutral' if audio_sentiment == 0 else 'positive' if audio_sentiment == 1 else 'negative'],\n","    'Percentage': [audio_percentage]\n","})\n","\n","# Save to CSV for combining later\n","results_df_audio2.to_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_audio2.csv', index=False)\n","\n","print(results_df_audio2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGyLCmtMWLlC","executionInfo":{"status":"ok","timestamp":1718259889840,"user_tz":-300,"elapsed":2402,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"d8948dc7-b933-49f3-ebbd-1a5414676ec2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["        Modality Sentiment  Percentage\n","0  Audio Model 2  negative        0.44\n"]}]},{"cell_type":"markdown","source":["##Snippet 3: Text Model 1 (BERT)"],"metadata":{"id":"tfmGRNtvYpQ9"}},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","import numpy as np\n","import pandas as pd\n","\n","# Load your datasets\n","text_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv')\n","\n","# Get the first text transcription\n","first_text = text_df.iloc[0]['Transcription']\n","\n","# Load the pre-trained model and tokenizer\n","text_model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model'\n","text_tokenizer = BertTokenizer.from_pretrained(text_model_path)\n","text_model = BertForSequenceClassification.from_pretrained(text_model_path)\n","\n","# Tokenize and encode the text\n","encoded_dict = text_tokenizer.encode_plus(\n","    first_text,\n","    add_special_tokens=True,\n","    max_length=64,\n","    truncation=True,\n","    padding='max_length',\n","    return_attention_mask=True,\n","    return_tensors='pt'\n",")\n","input_ids = encoded_dict['input_ids']\n","attention_mask = encoded_dict['attention_mask']\n","\n","# Predict text sentiment\n","text_model.eval()\n","with torch.no_grad():\n","    outputs = text_model(input_ids, attention_mask=attention_mask)\n","    logits = outputs.logits\n","    probs = torch.nn.functional.softmax(logits, dim=1).detach().cpu().numpy()[0]\n","\n","text_sentiment = np.argmax(probs)\n","text_percentage = probs[text_sentiment]\n","\n","# Save results to a DataFrame\n","results_df_text1 = pd.DataFrame({\n","    'Modality': ['Text Model 1'],\n","    'Sentiment': ['neutral' if text_sentiment == 0 else 'positive' if text_sentiment == 1 else 'negative'],\n","    'Percentage': [text_percentage]\n","})\n","\n","# Save to CSV for combining later\n","results_df_text1.to_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_text1.csv', index=False)\n"],"metadata":{"id":"EbauoOOXXqgY","executionInfo":{"status":"ok","timestamp":1718259923805,"user_tz":-300,"elapsed":30459,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["##Snippet 4: Text Model 2 (Logistic Regression with BOW)"],"metadata":{"id":"pdoBVqYQYuKN"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import re\n","import nltk\n","import joblib\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Load your datasets\n","text_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Text.csv')\n","\n","# Get the first text transcription\n","first_text = text_df.iloc[0]['Transcription']\n","\n","# Function to remove unwanted characters\n","def removing_unwanted_data(text):\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","    text = re.sub(r'\\<a href', ' ', text)\n","    text = re.sub(r'&amp;', '', text)\n","    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n","    text = re.sub(r'<br />', ' ', text)\n","    text = re.sub(r'\\'', ' ', text)\n","    text = nltk.WordPunctTokenizer().tokenize(text)\n","    return text\n","\n","# Custom tokenizer function (as it was used when creating the vectorizer)\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Apply preprocessing\n","cleaned_text = removing_unwanted_data(first_text)\n","\n","# Load the saved vectorizer and model\n","vectorizer_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl'\n","model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl'\n","\n","# Ensure the custom tokenizer is available when loading the vectorizer\n","vectorizer = joblib.load(vectorizer_path)\n","model = joblib.load(model_path)\n","\n","# Transform the data using the loaded vectorizer\n","X = vectorizer.transform([' '.join(cleaned_text)])\n","\n","# Predict text sentiment\n","text_pred = model.predict_proba(X)[0]\n","text_sentiment = np.argmax(text_pred)\n","text_percentage = text_pred[text_sentiment]\n","\n","# Save results to a DataFrame\n","results_df_text2 = pd.DataFrame({\n","    'Modality': ['Text Model 2'],\n","    'Sentiment': ['neutral' if text_sentiment == 0 else 'positive' if text_sentiment == 1 else 'negative'],\n","    'Percentage': [text_percentage]\n","})\n","\n","# Save to CSV for combining later\n","results_df_text2.to_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_text2.csv', index=False)\n","\n","print(\"Results saved successfully for Text Model 2.\")\n"],"metadata":{"id":"Nz8ELO2SYv8k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718260153749,"user_tz":-300,"elapsed":1023,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"db334557-5bf8-4c94-9416-694d67b63fce"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Results saved successfully for Text Model 2.\n"]}]},{"cell_type":"markdown","source":["##Snippet 5: Video Model 1 (CNN with MobileNetV2)"],"metadata":{"id":"IIypQZyLYy7V"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","\n","# Load your datasets\n","frames_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Get the first video name without the .wav extension\n","first_video_name = frames_df.iloc[0]['Video Name'].replace('.wav', '')\n","\n","# Load the pre-trained model\n","video_model_path = '/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5'\n","video_model = tf.keras.models.load_model(video_model_path)\n","\n","# Helper function for video feature extraction\n","def preprocess_image(filepath):\n","    img = cv2.imread(filepath)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img, (224, 224))\n","    img = preprocess_input(img)\n","    return img\n","\n","# Filter frames related to the first video and are key frames\n","video_frames = frames_df[(frames_df['Video Name'].str.replace('.wav', '') == first_video_name) & (frames_df['Key_Frame'] == 'Y')]\n","\n","# Predict video sentiment for all key frames\n","predictions = []\n","\n","for frame_path in video_frames['Frame Path']:\n","    video_image = preprocess_image(frame_path)\n","    video_image = np.expand_dims(video_image, axis=0)\n","    video_pred = video_model.predict(video_image)[0]\n","    predictions.append(video_pred)\n","\n","# Aggregate predictions\n","if predictions:\n","    average_prediction = np.mean(predictions, axis=0)\n","    video_sentiment = np.argmax(average_prediction)\n","    video_percentage = average_prediction[video_sentiment]\n","\n","    # Save results to a DataFrame\n","    results_df_video1 = pd.DataFrame({\n","        'Modality': ['Video Model 1'],\n","        'Sentiment': ['neutral' if video_sentiment == 0 else 'positive' if video_sentiment == 1 else 'negative'],\n","        'Percentage': [video_percentage]\n","    })\n","\n","    # Save to CSV for combining later\n","    results_df_video1.to_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_video1.csv', index=False)\n","\n","    print(\"Results saved successfully for Video Model 1.\")\n","else:\n","    print(\"No key frames found for the first video.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_s7dJ2XBYzpT","executionInfo":{"status":"ok","timestamp":1718260219481,"user_tz":-300,"elapsed":15515,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"fd815126-5ced-448b-f45b-fe1fa1d22f3f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 0s 203ms/step\n","1/1 [==============================] - 0s 258ms/step\n","1/1 [==============================] - 0s 137ms/step\n","1/1 [==============================] - 0s 135ms/step\n","1/1 [==============================] - 0s 111ms/step\n","1/1 [==============================] - 0s 86ms/step\n","1/1 [==============================] - 0s 156ms/step\n","Results saved successfully for Video Model 1.\n"]}]},{"cell_type":"markdown","source":["##Snippet 6: Video Model 2 (Random Forest)"],"metadata":{"id":"nD53ocmSY3Vl"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import joblib\n","from skimage.feature import hog\n","\n","# Load your datasets\n","frames_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Frames_Meta_Data.csv')\n","\n","# Get the first video name without the .wav extension\n","first_video_name = frames_df.iloc[0]['Video Name'].replace('.wav', '')\n","\n","# Load the pre-trained model\n","video_model_path = '/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl'\n","video_model = joblib.load(video_model_path)\n","\n","# Helper function for video feature extraction\n","def preprocess_image(filepath):\n","    img = cv2.imread(filepath)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = cv2.resize(img, (128, 128))\n","    img = cv2.equalizeHist(img)\n","    hog_features = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys')\n","    return hog_features\n","\n","# Filter frames related to the first video and are key frames\n","video_frames = frames_df[(frames_df['Video Name'].str.replace('.wav', '') == first_video_name) & (frames_df['Key_Frame'] == 'Y')]\n","\n","# Predict video sentiment for all key frames\n","predictions = []\n","\n","for frame_path in video_frames['Frame Path']:\n","    video_features = preprocess_image(frame_path).reshape(1, -1)\n","    video_pred = video_model.predict_proba(video_features)[0]\n","    predictions.append(video_pred)\n","\n","# Aggregate predictions\n","if predictions:\n","    average_prediction = np.mean(predictions, axis=0)\n","    video_sentiment = np.argmax(average_prediction)\n","    video_percentage = average_prediction[video_sentiment]\n","\n","    # Save results to a DataFrame\n","    results_df_video2 = pd.DataFrame({\n","        'Modality': ['Video Model 2'],\n","        'Sentiment': ['neutral' if video_sentiment == 0 else 'positive' if video_sentiment == 1 else 'negative'],\n","        'Percentage': [video_percentage]\n","    })\n","\n","    # Save to CSV for combining later\n","    results_df_video2.to_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_video2.csv', index=False)\n","\n","    print(\"Results saved successfully for Video Model 2.\")\n","else:\n","    print(\"No key frames found for the first video.\")\n"],"metadata":{"id":"1lkLY92cY35R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718260222038,"user_tz":-300,"elapsed":2569,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"2c92c0b0-d43b-4fd5-eaa8-931c770ba8b0"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Results saved successfully for Video Model 2.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"2GFNTbko7JTD"}},{"cell_type":"markdown","source":["## Saving Results"],"metadata":{"id":"w0uBJnZw7KH6"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","# Load the temporary results from each model\n","results_audio1 = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_audio1.csv')\n","results_audio2 = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_audio2.csv')\n","results_text1 = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_text1.csv')\n","results_text2 = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_text2.csv')\n","results_video1 = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_video1.csv')\n","results_video2 = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Temp_results_video2.csv')\n","\n","# Combine all results into one DataFrame\n","all_results = pd.concat([results_audio1, results_audio2, results_text1, results_text2, results_video1, results_video2])\n","\n","# Determine the modality with the greatest percentage\n","max_percentage_idx = all_results['Percentage'].idxmax()\n","max_percentage_modality = all_results.loc[max_percentage_idx, 'Modality']\n","max_percentage_sentiment = all_results.loc[max_percentage_idx, 'Sentiment']\n","\n","# Add considered sentiment to the results DataFrame\n","all_results['Considered Sentiment'] = None\n","all_results.at[max_percentage_idx, 'Considered Sentiment'] = max_percentage_sentiment\n","\n","# Display the results table\n","print(all_results)\n","\n","# Save the final results to the validation CSV file\n","results_file = '/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation_modelity.csv'\n","\n","# Check if the results file exists\n","if os.path.exists(results_file):\n","    # If it exists, read the existing data\n","    existing_df = pd.read_csv(results_file)\n","    # Append the new results\n","    all_results = pd.concat([existing_df, all_results], ignore_index=True)\n","\n","# Save the DataFrame to the CSV file\n","all_results.to_csv(results_file, index=False)\n","\n","print(f\"Results saved to {results_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I28IXotEZVqz","executionInfo":{"status":"ok","timestamp":1718260236323,"user_tz":-300,"elapsed":383,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"4f219ebc-90f4-41b3-b9d9-4f7693fec288"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["        Modality Sentiment  Percentage Considered Sentiment\n","0  Audio Model 1  positive    0.428967             positive\n","0  Audio Model 2  negative    0.440000             negative\n","0   Text Model 1  negative    0.955447             negative\n","0   Text Model 2  negative    0.999999             negative\n","0  Video Model 1  positive    0.470676             positive\n","0  Video Model 2  negative    0.365104             negative\n","Results saved to /content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation_modelity.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/work2/Validation_Data/Final_Model_Validation_modelity.csv\")\n","\n","# Display the first 10 rows of the DataFrame\n","display(df.head(10))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"UA9mNTzZZecc","executionInfo":{"status":"ok","timestamp":1718264660266,"user_tz":-300,"elapsed":389,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"aac24b14-da0c-466f-f2af-cf586e0924f2"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":["        Modality Sentiment  Percentage Considered Sentiment\n","0  Audio Model 1  positive    0.428967             positive\n","1  Audio Model 2  negative    0.440000             negative\n","2   Text Model 1  negative    0.955447             negative\n","3   Text Model 2  negative    0.999999             negative\n","4  Video Model 1  positive    0.470676             positive\n","5  Video Model 2  negative    0.365104             negative"],"text/html":["\n","  <div id=\"df-a8ca5336-2482-4bc1-903d-5b7ce085ca96\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Modality</th>\n","      <th>Sentiment</th>\n","      <th>Percentage</th>\n","      <th>Considered Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Audio Model 1</td>\n","      <td>positive</td>\n","      <td>0.428967</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Audio Model 2</td>\n","      <td>negative</td>\n","      <td>0.440000</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Text Model 1</td>\n","      <td>negative</td>\n","      <td>0.955447</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Text Model 2</td>\n","      <td>negative</td>\n","      <td>0.999999</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Video Model 1</td>\n","      <td>positive</td>\n","      <td>0.470676</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Video Model 2</td>\n","      <td>negative</td>\n","      <td>0.365104</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8ca5336-2482-4bc1-903d-5b7ce085ca96')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a8ca5336-2482-4bc1-903d-5b7ce085ca96 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a8ca5336-2482-4bc1-903d-5b7ce085ca96');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-49243ca0-3fbc-4dd9-b8fd-9b6a31484667\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49243ca0-3fbc-4dd9-b8fd-9b6a31484667')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-49243ca0-3fbc-4dd9-b8fd-9b6a31484667 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Audio Model 1\",\n          \"Audio Model 2\",\n          \"Video Model 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2872249402032386,\n        \"min\": 0.3651041666666667,\n        \"max\": 0.999998725931368,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.42896712,\n          0.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Considered Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["#Modelity Work"],"metadata":{"id":"G4vhOI437N1y"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Specific predictions data\n","data = {\n","    'Modality': [\n","        'Audio Model 1', 'Audio Model 2', 'Text Model 1', 'Text Model 2', 'Video Model 1', 'Video Model 2'\n","    ],\n","    'Sentiment': [\n","        'positive', 'negative', 'negative', 'negative', 'positive', 'negative'\n","    ],\n","    'Percentage': [\n","        0.428967, 0.440000, 0.955447, 0.999999, 0.470676, 0.365104\n","    ],\n","    'Considered Sentiment': [\n","        'positive', 'negative', 'negative', 'negative', 'positive', 'negative'\n","    ]\n","}\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","\n","# Weights for each modality (adjust these weights as needed)\n","modality_weights = {\n","    'Audio Model 1': 1.0,\n","    'Audio Model 2': 1.0,\n","    'Text Model 1': 1.0,\n","    'Text Model 2': 1.0,\n","    'Video Model 1': 1.0,\n","    'Video Model 2': 1.0\n","}\n","\n","# Apply weights to each prediction percentage\n","df['Weighted Percentage'] = df.apply(lambda row: row['Percentage'] * modality_weights[row['Modality']], axis=1)\n","\n","# Aggregate the sentiments with their weighted percentages\n","sentiment_scores = df.groupby('Sentiment')['Weighted Percentage'].sum()\n","\n","# Determine the final sentiment\n","final_sentiment = sentiment_scores.idxmax()\n","final_percentage = sentiment_scores.max()\n","\n","# Print the DataFrame\n","print(df)\n","\n","# Load the Videos.csv file to get video names and labels\n","videos_df = pd.read_csv('/content/drive/MyDrive/work2/Validation_Data/Meta_Data/Videos.csv')\n","\n","# Assume we are working with the first video\n","video_name = videos_df.iloc[0]['File']\n","video_label = videos_df.iloc[0]['Senti']\n","\n","# Print and save the final classification\n","final_classification = {\n","    'Video Name': [video_name],\n","    'True Label': [video_label],\n","    'Predicted Sentiment': [final_sentiment],\n","    'Final Percentage': [final_percentage]\n","}\n","\n","final_classification_df = pd.DataFrame(final_classification)\n","\n","# Save the final classification to a CSV file\n","final_classification_output_path = '/content/drive/MyDrive/work2/Validation_Data/Final_Classification_Results.csv'\n","final_classification_df.to_csv(final_classification_output_path, index=False)\n","\n","print(\"Final classification results saved successfully.\")\n","print(final_classification_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmqI0DWfMl9B","executionInfo":{"status":"ok","timestamp":1718264713842,"user_tz":-300,"elapsed":593,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"c55365de-9aa7-4233-b6b0-7b696837e695"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["        Modality Sentiment  Percentage Considered Sentiment  \\\n","0  Audio Model 1  positive    0.428967             positive   \n","1  Audio Model 2  negative    0.440000             negative   \n","2   Text Model 1  negative    0.955447             negative   \n","3   Text Model 2  negative    0.999999             negative   \n","4  Video Model 1  positive    0.470676             positive   \n","5  Video Model 2  negative    0.365104             negative   \n","\n","   Weighted Percentage  \n","0             0.428967  \n","1             0.440000  \n","2             0.955447  \n","3             0.999999  \n","4             0.470676  \n","5             0.365104  \n","Final classification results saved successfully.\n","              Video Name  True Label Predicted Sentiment  Final Percentage\n","0  1. Mobile_Neutral.wav           0            negative           2.76055\n"]}]},{"cell_type":"code","source":["final_classification_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"xk8UZ45tjysb","executionInfo":{"status":"ok","timestamp":1718264754050,"user_tz":-300,"elapsed":387,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"0db95649-619f-4548-d46e-6e39f487a40f"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Video Name  True Label Predicted Sentiment  Final Percentage\n","0  1. Mobile_Neutral.wav           0            negative           2.76055"],"text/html":["\n","  <div id=\"df-a39aad7b-466b-4034-a3e7-e8655c41fe3d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video Name</th>\n","      <th>True Label</th>\n","      <th>Predicted Sentiment</th>\n","      <th>Final Percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1. Mobile_Neutral.wav</td>\n","      <td>0</td>\n","      <td>negative</td>\n","      <td>2.76055</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a39aad7b-466b-4034-a3e7-e8655c41fe3d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a39aad7b-466b-4034-a3e7-e8655c41fe3d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a39aad7b-466b-4034-a3e7-e8655c41fe3d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"final_classification_df","summary":"{\n  \"name\": \"final_classification_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Video Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1. Mobile_Neutral.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"True Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Final Percentage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2.76055,\n        \"max\": 2.76055,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.76055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":[],"metadata":{"id":"aQ-xhFiwj2uX"},"execution_count":null,"outputs":[]}]}