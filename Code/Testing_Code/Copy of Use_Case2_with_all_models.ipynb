{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IARYY3jIPCHa","outputId":"a59b0f4c-abf3-469f-d37f-1943d8ad09e6","executionInfo":{"status":"ok","timestamp":1717507406204,"user_tz":-300,"elapsed":25184,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# !pip install SpeechRecognition\n","# !pip install google-cloud-speech pandas\n","!pip install pydub\n","# !apt install ffmpeg\n","\n","# !pip install FER"],"metadata":{"id":"E7UuIGfXPpOb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716799783356,"user_tz":-300,"elapsed":17402,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"a154cc37-545a-42fa-f3c9-b49745be69a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"BefKwEffQwq6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Insert Video to convert into Audio**"],"metadata":{"id":"o3XX-Cg-TB9V"}},{"cell_type":"code","source":["import moviepy.editor as mp\n","import speech_recognition as sr\n","from pydub import AudioSegment\n","import os\n","import pandas as pd\n","\n","def video_to_audio(video_path, audio_path):\n","    \"\"\"Convert video file to audio file.\"\"\"\n","    video = mp.VideoFileClip(video_path)\n","    video.audio.write_audiofile(audio_path)\n","\n","def get_audio_length(file_path):\n","    \"\"\"Return the length of the audio file in seconds.\"\"\"\n","    audio = AudioSegment.from_file(file_path)\n","    return len(audio) / 1000.0  # Convert milliseconds to seconds\n","\n","def transcribe_audio_speech_recognition(audio_file_path):\n","    \"\"\"Transcribe the given local audio file using the speech_recognition library.\"\"\"\n","    recognizer = sr.Recognizer()\n","    with sr.AudioFile(audio_file_path) as source:\n","        audio_data = recognizer.record(source)\n","        try:\n","            transcript = recognizer.recognize_google(audio_data, language=\"ur-PK\")\n","            return transcript\n","        except sr.UnknownValueError:\n","            print(\"Google Speech Recognition could not understand the audio\")\n","            return None\n","        except sr.RequestError as e:\n","            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n","            return None\n","\n","def read_words_from_file(file_path):\n","    \"\"\"Read words from a file and return them as a list.\"\"\"\n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            return [line.strip().lower() for line in file.readlines()]\n","    except FileNotFoundError:\n","        print(f\"File not found: {file_path}\")\n","        return []\n","    except Exception as e:\n","        print(f\"Error reading file {file_path}: {e}\")\n","        return []\n","\n","# Convert video to audio\n","video_file_path = '/content/drive/MyDrive/Use_Case/test_video/Test.mp4'\n","audio_file_path = '/content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav'\n","video_to_audio(video_file_path, audio_file_path)\n","\n","# Get audio length\n","length_in_seconds = get_audio_length(audio_file_path)\n","print(f\"The length of the audio file is {length_in_seconds} seconds.\")\n","\n","# Transcribe audio\n","transcript = transcribe_audio_speech_recognition(audio_file_path)\n","if transcript:\n","    print(\"Transcript:\", transcript)\n","    words_in_transcript = transcript.split()\n","    transcript_length = len(words_in_transcript)\n","    print(f\"Transcript Length (in words): {transcript_length}\")\n","\n","    # Read positive and negative words from files\n","    negative_words = read_words_from_file('/content/drive/MyDrive/work2/dictionary/urdu_negative_words.txt')\n","    positive_words = read_words_from_file('/content/drive/MyDrive/work2/dictionary/urdu_positive_words.txt')\n","\n","    results = []\n","    negative_count, positive_count = 0, 0\n","    for index, word in enumerate(words_in_transcript):\n","        position = (index + 1) / transcript_length * length_in_seconds\n","        if word.lower() in negative_words:\n","            negative_count += 1\n","            results.append({'Word': word, 'Type': 'Negative', 'Position': index + 1, 'Time': round(position)})\n","        elif word.lower() in positive_words:\n","            positive_count += 1\n","            results.append({'Word': word, 'Type': 'Positive', 'Position': index + 1, 'Time': round(position)})\n","\n","    # Create DataFrame and display results\n","    df = pd.DataFrame(results)\n","    print(df)\n","    print(f\"Total Negative Words: {negative_count}\")\n","    print(f\"Total Positive Words: {positive_count}\")\n","else:\n","    print(\"No transcript available.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgRt2unzR1vt","outputId":"2d8bb5c3-875f-4c70-89f8-19e34e387389"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MoviePy - Writing audio in /content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","The length of the audio file is 121.24 seconds.\n","Transcript: سب سے پہلے ہم بات کریں گے اس کی پیکیجنگ کی پیکیجنگ کچھ اس طرح سے ہے روز گولڈ از مائی کمزوری لائک دس کلر ائی لو دس کلر گلاس پیکیجنگ ہے اس کی اس میں اپ کو ملے گی ٹوٹل 32 ایم ایل فاؤنڈیشن اس میں کوئی پمپ اویلیبل نہیں ہے اتا ہے یہ کچھ اس طرح سے دو فٹ ایپلیکیشن میں وچ از ہیوج لائک ہم کہہ سکتے ہیں کہ یہ ٹارچ فاؤنڈیشن کی جو ہے ڈیو ہے اس کا جو کنسیلر ہے وہ اس کا منی ورژن ہے ریڈ می شو یو سو یہ ہے کنسیلر اور یہ ہے فاؤنڈیشن دونوں کی پیکیجنگ سیمس ہے میں کنسیلر کا نام بھی کنسیلر ڈیفائن کنسلر ہے اور اس کا کینسل اینڈ ڈیفائن فاؤنڈیشن اس میں بھی ہے ایپلیکیشن کا کلر ڈارک ہے کیونکہ یہ میں نے کنٹورنگ کے لیے لیا تھا اس میں بھی ایپلیکیشن موجود ہے دو فٹ ایپلیکیشن جس سے بہت ایزیلی سے اپلائی ہو جاتی ہے فاؤنڈیشن بھی اور کنسیلر بھی فاؤنڈیشن تو یہ ہے ٹھیک ہے تو اس کی جو پرائز ہے 950 سمتھنگ یہ بہت سستا تھا پہلے 850 ورڈ عمران خان سلام اپ کو لائک پرائزز سو اس کی جو پرائز ہے یہ 12 ہے یو ایس میں بڑی یہاں پے یہ اپ کو ملے گا 2000 رز میں سو جو ایف ٹو شیڈ ہے وہ ہے فیرس اسکین ٹون کے لئے ود لائٹ ییلو انڈر ٹون لیکن ایف تھری جو ہے وہ بھی فیٹس کینٹون کے لئے ہے لیکن تھوڑا سا زیادہ یلو انڈر ٹون ہے دونوں میں دونوں کو مکس کرکے میں اپنے فیس پر اپلائی کرتی ہوں اس کا ٹیکسچر جو ہے وہ سوپر سوپر سوپر کریمی ہے اینڈ یہ کلیم کرتا ہے کہ یہ اپ کو فل کوریج دیتا ہے جو ابھی دیکھیں گے ہم اپلیکیشن کے دوران تو دونوں کس واچز میں ابھی اپ کو دکھا دیتی ہوں تو یہ والا شعر جو ہے اس میں اپ کو ملیں گے ٹوٹل 24 شیرز لائک لائٹ سے لے کر ڈاکٹر شیڈز اپ کو ملیں گے اس میں اویلیبل ہے\n","Transcript Length (in words): 340\n","       Word      Type  Position  Time\n","0        ہم  Negative         4     1\n","1    کمزوری  Negative        22     8\n","2   اویلیبل  Positive        50    18\n","3      نہیں  Negative        51    18\n","4        ہم  Negative        68    24\n","5       منی  Positive        89    32\n","6    ایزیلی  Positive       155    55\n","7      ٹھیک  Positive       170    61\n","8      سستا  Positive       182    65\n","9      سلام  Positive       189    67\n","10     لیکن  Negative       235    84\n","11     لیکن  Negative       247    88\n","12    زیادہ  Negative       250    89\n","13       ہم  Negative       296   106\n","14  اویلیبل  Positive       339   121\n","Total Negative Words: 8\n","Total Positive Words: 7\n"]}]},{"cell_type":"code","source":["import speech_recognition as sr\n","from pydub import AudioSegment\n","import os\n","import pandas as pd\n","\n","def get_audio_length(file_path):\n","    \"\"\"Return the length of the audio file in seconds.\"\"\"\n","    audio = AudioSegment.from_file(file_path)\n","    return len(audio) / 1000.0  # Convert milliseconds to seconds\n","\n","def transcribe_audio_speech_recognition(audio_file_path):\n","    \"\"\"Transcribe the given local audio file using the speech_recognition library.\"\"\"\n","    recognizer = sr.Recognizer()\n","    with sr.AudioFile(audio_file_path) as source:\n","        audio_data = recognizer.record(source)\n","        try:\n","            transcript = recognizer.recognize_google(audio_data, language=\"ur-PK\")\n","            return transcript\n","        except sr.UnknownValueError:\n","            print(\"Google Speech Recognition could not understand the audio\")\n","            return None\n","        except sr.RequestError as e:\n","            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n","            return None\n","\n","def read_words_from_file(file_path):\n","    \"\"\"Read words from a file and return them as a list.\"\"\"\n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            return [line.strip().lower() for line in file.readlines()]\n","    except FileNotFoundError:\n","        print(f\"File not found: {file_path}\")\n","        return []\n","    except Exception as e:\n","        print(f\"Error reading file {file_path}: {e}\")\n","        return []\n","\n","audio_file_path = '/content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav'\n","length_in_seconds = get_audio_length(audio_file_path)\n","print(f\"The length of the audio file is {length_in_seconds} seconds.\")\n","\n","transcript = transcribe_audio_speech_recognition(audio_file_path)\n","if transcript:\n","    print(\"Transcript:\", transcript)\n","    words_in_transcript = transcript.split()\n","    transcript_length = len(words_in_transcript)\n","    print(f\"Transcript Length (in words): {transcript_length}\")\n","\n","    negative_words = read_words_from_file('/content/drive/MyDrive/work2/dictionary/urdu_negative_words.txt')\n","    positive_words = read_words_from_file('/content/drive/MyDrive/work2/dictionary/urdu_positive_words.txt')\n","\n","    results37 = []\n","    negative_count, positive_count = 0, 0\n","    negative_positions, positive_positions = [], []  # Lists to store positions\n","\n","    for index, word in enumerate(words_in_transcript):\n","        position = (index+1) / transcript_length * length_in_seconds\n","        if word.lower() in negative_words:\n","            negative_count += 1\n","            negative_positions.append(round(position))  # Append to negative_positions list\n","            # results.append({'Word': word, 'Type': 'Negative', 'Position': index+1, 'Time': round(position)})\n","        elif word.lower() in positive_words:\n","            positive_count += 1\n","            positive_positions.append(round(position))  # Append to positive_positions list\n","            # results.append({'Word': word, 'Type': 'Positive', 'Position': index+1, 'Time': round(position)})\n","\n","    print(f\"Total Negative Words: {negative_count}\")\n","    print(f\"Total Positive Words: {positive_count}\")\n","    print(\"Negative Word Positions:\", negative_positions)\n","    print(\"Positive Word Positions:\", positive_positions)\n","\n","    results37.append({'Length': length_in_seconds, 'audio_name': os.path.basename(audio_file_path),'Transcript' : transcript , 'negative_count': negative_count, 'positive_count': positive_count, 'negative_positions' : negative_positions, 'positive_positions': positive_positions})\n","    # Create DataFrame\n","    df = pd.DataFrame(results37)\n","\n","    # Save results to a CSV file\n","    csv_file_path = '/content/drive/MyDrive/Use_Case/transcription/Test.csv'\n","    df.to_csv(csv_file_path, index=False)\n","    print(f\"Results saved to {csv_file_path}\")\n","\n","\n","\n","else:\n","    print(\"No transcript available.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8etdIANjUCB6","outputId":"221ad1d6-a6bd-45f7-dce4-13ba96e47947","executionInfo":{"status":"ok","timestamp":1716800019790,"user_tz":-300,"elapsed":33138,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The length of the audio file is 121.24 seconds.\n","Transcript: سب سے پہلے ہم بات کریں گے اس کی پیکیجنگ کی پیکیجنگ کچھ اس طرح سے ہے روز گولڈ از مائی کمزوری لائک دس کلر ائی لو دس کلر گلاس پیکیجنگ ہے اس کی اس میں اپ کو ملے گی ٹوٹل 32 ایم ایل فاؤنڈیشن اس میں کوئی پمپ اویلیبل نہیں ہے اتا ہے یہ کچھ اس طرح سے دو فٹ ایپلیکیشن میں وچ از ہیوج لائک ہم کہہ سکتے ہیں کہ یہ ٹارچ فاؤنڈیشن کی جو ہے ڈیو ہے اس کا جو کنسیلر ہے وہ اس کا منی ورژن ہے ریڈ می شو یو سو یہ ہے کنسیلر اور یہ ہے فاؤنڈیشن دونوں کی پیکیجنگ سیم سیم ہے اور اس کا کینسل اینڈ ڈیفائن فاؤنڈیشن اس میں بھی ہے ایپلیکیشن کا کلر ڈارک ہے کیونکہ یہ میں نے کنٹورنگ کے لیے لیا تھا اس میں بھی ایپلیکیشن موجود ہے دو فٹ ایپلیکیشن جس سے بہت ایزیلی سے اپلائی ہو جاتی ہے فاؤنڈیشن بھی اور کنسیلر بھی فاؤنڈیشن تو یہ ہے ٹھیک ہے تو اس کی جو پرائز ہے 950 سمتھنگ یہ بہت سستا تھا پہلے 850 ورڈ عمران خان سلام اپ کو لائک پرائزز سو اس کی جو پرائز ہے یہ 12 ہے یو ایس میں بڑی یہاں پے یہ اپ کو ملے گا 2000 رز میں سو جو ایف ٹو شیڈ ہے وہ ہے فیرس اسکین ٹون کے لئے ود لائٹ ییلو انڈر ٹون لیکن ایف تھری جو ہے وہ بھی فیئر سکن ٹون کے لئے ہے لیکن تھوڑا سا زیادہ یلو انڈر ٹون ہے دونوں میں دونوں کو مکس کرکے میں اپنے فیس پر اپلائی کرتی ہوں اس کا ٹیکسچر جو ہے وہ سوپر سوپر سوپر کریمی ہے اینڈ یہ کلیم کرتا ہے کہ یہ اپ کو فل کوریج دیتا ہے جو ابھی دیکھیں گے ہم اپلیکیشن کے دوران تو دونوں کس واچز میں ابھی اپ کو دکھا دیتی ہوں تو یہ والا شعر جو ہے اس میں اپ کو ملیں گے ٹوٹل 24 شیرز لائک لائٹ سے لے کر ڈاکٹر شیڈز اپ کو ملیں گے اس میں اویلیبل ہے\n","Transcript Length (in words): 333\n","Total Negative Words: 8\n","Total Positive Words: 7\n","Negative Word Positions: [1, 8, 19, 25, 83, 87, 88, 105]\n","Positive Word Positions: [18, 32, 54, 59, 63, 66, 121]\n","Results saved to /content/drive/MyDrive/Use_Case/transcription/Test.csv\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/transcription/Test.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"ONR9DggnUhnq","outputId":"fa0a1bfe-a8aa-4b7d-94ab-d551731b2416","executionInfo":{"status":"ok","timestamp":1716789612500,"user_tz":-300,"elapsed":388,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Length audio_name                                         Transcript  \\\n","0  121.24   Test.wav  سب سے پہلے ہم بات کریں گے اس کی پیکیجنگ کی پیک...   \n","\n","   negative_count  positive_count               negative_positions  \\\n","0               8               7  [1, 8, 18, 24, 84, 88, 89, 106]   \n","\n","              positive_positions  \n","0  [18, 32, 55, 61, 65, 67, 121]  "],"text/html":["\n","  <div id=\"df-cfe6fe02-4f84-4684-931d-680bb47fe0d8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Length</th>\n","      <th>audio_name</th>\n","      <th>Transcript</th>\n","      <th>negative_count</th>\n","      <th>positive_count</th>\n","      <th>negative_positions</th>\n","      <th>positive_positions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>121.24</td>\n","      <td>Test.wav</td>\n","      <td>سب سے پہلے ہم بات کریں گے اس کی پیکیجنگ کی پیک...</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>[1, 8, 18, 24, 84, 88, 89, 106]</td>\n","      <td>[18, 32, 55, 61, 65, 67, 121]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfe6fe02-4f84-4684-931d-680bb47fe0d8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cfe6fe02-4f84-4684-931d-680bb47fe0d8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cfe6fe02-4f84-4684-931d-680bb47fe0d8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 121.24,\n        \"max\": 121.24,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          121.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0633\\u0628 \\u0633\\u06d2 \\u067e\\u06c1\\u0644\\u06d2 \\u06c1\\u0645 \\u0628\\u0627\\u062a \\u06a9\\u0631\\u06cc\\u06ba \\u06af\\u06d2 \\u0627\\u0633 \\u06a9\\u06cc \\u067e\\u06cc\\u06a9\\u06cc\\u062c\\u0646\\u06af \\u06a9\\u06cc \\u067e\\u06cc\\u06a9\\u06cc\\u062c\\u0646\\u06af \\u06a9\\u0686\\u06be \\u0627\\u0633 \\u0637\\u0631\\u062d \\u0633\\u06d2 \\u06c1\\u06d2 \\u0631\\u0648\\u0632 \\u06af\\u0648\\u0644\\u0688 \\u0627\\u0632 \\u0645\\u0627\\u0626\\u06cc \\u06a9\\u0645\\u0632\\u0648\\u0631\\u06cc \\u0644\\u0627\\u0626\\u06a9 \\u062f\\u0633 \\u06a9\\u0644\\u0631 \\u0627\\u0626\\u06cc \\u0644\\u0648 \\u062f\\u0633 \\u06a9\\u0644\\u0631 \\u06af\\u0644\\u0627\\u0633 \\u067e\\u06cc\\u06a9\\u06cc\\u062c\\u0646\\u06af \\u06c1\\u06d2 \\u0627\\u0633 \\u06a9\\u06cc \\u0627\\u0633 \\u0645\\u06cc\\u06ba \\u0627\\u067e \\u06a9\\u0648 \\u0645\\u0644\\u06d2 \\u06af\\u06cc \\u0679\\u0648\\u0679\\u0644 32 \\u0627\\u06cc\\u0645 \\u0627\\u06cc\\u0644 \\u0641\\u0627\\u0624\\u0646\\u0688\\u06cc\\u0634\\u0646 \\u0627\\u0633 \\u0645\\u06cc\\u06ba \\u06a9\\u0648\\u0626\\u06cc \\u067e\\u0645\\u067e \\u0627\\u0648\\u06cc\\u0644\\u06cc\\u0628\\u0644 \\u0646\\u06c1\\u06cc\\u06ba \\u06c1\\u06d2 \\u0627\\u062a\\u0627 \\u06c1\\u06d2 \\u06cc\\u06c1 \\u06a9\\u0686\\u06be \\u0627\\u0633 \\u0637\\u0631\\u062d \\u0633\\u06d2 \\u062f\\u0648 \\u0641\\u0679 \\u0627\\u06cc\\u067e\\u0644\\u06cc\\u06a9\\u06cc\\u0634\\u0646 \\u0645\\u06cc\\u06ba \\u0648\\u0686 \\u0627\\u0632 \\u06c1\\u06cc\\u0648\\u062c \\u0644\\u0627\\u0626\\u06a9 \\u06c1\\u0645 \\u06a9\\u06c1\\u06c1 \\u0633\\u06a9\\u062a\\u06d2 \\u06c1\\u06cc\\u06ba \\u06a9\\u06c1 \\u06cc\\u06c1 \\u0679\\u0627\\u0631\\u0686 \\u0641\\u0627\\u0624\\u0646\\u0688\\u06cc\\u0634\\u0646 \\u06a9\\u06cc \\u062c\\u0648 \\u06c1\\u06d2 \\u0688\\u06cc\\u0648 \\u06c1\\u06d2 \\u0627\\u0633 \\u06a9\\u0627 \\u062c\\u0648 \\u06a9\\u0646\\u0633\\u06cc\\u0644\\u0631 \\u06c1\\u06d2 \\u0648\\u06c1 \\u0627\\u0633 \\u06a9\\u0627 \\u0645\\u0646\\u06cc \\u0648\\u0631\\u0698\\u0646 \\u06c1\\u06d2 \\u0631\\u06cc\\u0688 \\u0645\\u06cc \\u0634\\u0648 \\u06cc\\u0648 \\u0633\\u0648 \\u06cc\\u06c1 \\u06c1\\u06d2 \\u06a9\\u0646\\u0633\\u06cc\\u0644\\u0631 \\u0627\\u0648\\u0631 \\u06cc\\u06c1 \\u06c1\\u06d2 \\u0641\\u0627\\u0624\\u0646\\u0688\\u06cc\\u0634\\u0646 \\u062f\\u0648\\u0646\\u0648\\u06ba \\u06a9\\u06cc \\u067e\\u06cc\\u06a9\\u06cc\\u062c\\u0646\\u06af \\u0633\\u06cc\\u0645\\u0633 \\u06c1\\u06d2 \\u0645\\u06cc\\u06ba \\u06a9\\u0646\\u0633\\u06cc\\u0644\\u0631 \\u06a9\\u0627 \\u0646\\u0627\\u0645 \\u0628\\u06be\\u06cc \\u06a9\\u0646\\u0633\\u06cc\\u0644\\u0631 \\u0688\\u06cc\\u0641\\u0627\\u0626\\u0646 \\u06a9\\u0646\\u0633\\u0644\\u0631 \\u06c1\\u06d2 \\u0627\\u0648\\u0631 \\u0627\\u0633 \\u06a9\\u0627 \\u06a9\\u06cc\\u0646\\u0633\\u0644 \\u0627\\u06cc\\u0646\\u0688 \\u0688\\u06cc\\u0641\\u0627\\u0626\\u0646 \\u0641\\u0627\\u0624\\u0646\\u0688\\u06cc\\u0634\\u0646 \\u0627\\u0633 \\u0645\\u06cc\\u06ba \\u0628\\u06be\\u06cc \\u06c1\\u06d2 \\u0627\\u06cc\\u067e\\u0644\\u06cc\\u06a9\\u06cc\\u0634\\u0646 \\u06a9\\u0627 \\u06a9\\u0644\\u0631 \\u0688\\u0627\\u0631\\u06a9 \\u06c1\\u06d2 \\u06a9\\u06cc\\u0648\\u0646\\u06a9\\u06c1 \\u06cc\\u06c1 \\u0645\\u06cc\\u06ba \\u0646\\u06d2 \\u06a9\\u0646\\u0679\\u0648\\u0631\\u0646\\u06af \\u06a9\\u06d2 \\u0644\\u06cc\\u06d2 \\u0644\\u06cc\\u0627 \\u062a\\u06be\\u0627 \\u0627\\u0633 \\u0645\\u06cc\\u06ba \\u0628\\u06be\\u06cc \\u0627\\u06cc\\u067e\\u0644\\u06cc\\u06a9\\u06cc\\u0634\\u0646 \\u0645\\u0648\\u062c\\u0648\\u062f \\u06c1\\u06d2 \\u062f\\u0648 \\u0641\\u0679 \\u0627\\u06cc\\u067e\\u0644\\u06cc\\u06a9\\u06cc\\u0634\\u0646 \\u062c\\u0633 \\u0633\\u06d2 \\u0628\\u06c1\\u062a \\u0627\\u06cc\\u0632\\u06cc\\u0644\\u06cc \\u0633\\u06d2 \\u0627\\u067e\\u0644\\u0627\\u0626\\u06cc \\u06c1\\u0648 \\u062c\\u0627\\u062a\\u06cc \\u06c1\\u06d2 \\u0641\\u0627\\u0624\\u0646\\u0688\\u06cc\\u0634\\u0646 \\u0628\\u06be\\u06cc \\u0627\\u0648\\u0631 \\u06a9\\u0646\\u0633\\u06cc\\u0644\\u0631 \\u0628\\u06be\\u06cc \\u0641\\u0627\\u0624\\u0646\\u0688\\u06cc\\u0634\\u0646 \\u062a\\u0648 \\u06cc\\u06c1 \\u06c1\\u06d2 \\u0679\\u06be\\u06cc\\u06a9 \\u06c1\\u06d2 \\u062a\\u0648 \\u0627\\u0633 \\u06a9\\u06cc \\u062c\\u0648 \\u067e\\u0631\\u0627\\u0626\\u0632 \\u06c1\\u06d2 950 \\u0633\\u0645\\u062a\\u06be\\u0646\\u06af \\u06cc\\u06c1 \\u0628\\u06c1\\u062a \\u0633\\u0633\\u062a\\u0627 \\u062a\\u06be\\u0627 \\u067e\\u06c1\\u0644\\u06d2 850 \\u0648\\u0631\\u0688 \\u0639\\u0645\\u0631\\u0627\\u0646 \\u062e\\u0627\\u0646 \\u0633\\u0644\\u0627\\u0645 \\u0627\\u067e \\u06a9\\u0648 \\u0644\\u0627\\u0626\\u06a9 \\u067e\\u0631\\u0627\\u0626\\u0632\\u0632 \\u0633\\u0648 \\u0627\\u0633 \\u06a9\\u06cc \\u062c\\u0648 \\u067e\\u0631\\u0627\\u0626\\u0632 \\u06c1\\u06d2 \\u06cc\\u06c1 12 \\u06c1\\u06d2 \\u06cc\\u0648 \\u0627\\u06cc\\u0633 \\u0645\\u06cc\\u06ba \\u0628\\u0691\\u06cc \\u06cc\\u06c1\\u0627\\u06ba \\u067e\\u06d2 \\u06cc\\u06c1 \\u0627\\u067e \\u06a9\\u0648 \\u0645\\u0644\\u06d2 \\u06af\\u0627 2000 \\u0631\\u0632 \\u0645\\u06cc\\u06ba \\u0633\\u0648 \\u062c\\u0648 \\u0627\\u06cc\\u0641 \\u0679\\u0648 \\u0634\\u06cc\\u0688 \\u06c1\\u06d2 \\u0648\\u06c1 \\u06c1\\u06d2 \\u0641\\u06cc\\u0631\\u0633 \\u0627\\u0633\\u06a9\\u06cc\\u0646 \\u0679\\u0648\\u0646 \\u06a9\\u06d2 \\u0644\\u0626\\u06d2 \\u0648\\u062f \\u0644\\u0627\\u0626\\u0679 \\u06cc\\u06cc\\u0644\\u0648 \\u0627\\u0646\\u0688\\u0631 \\u0679\\u0648\\u0646 \\u0644\\u06cc\\u06a9\\u0646 \\u0627\\u06cc\\u0641 \\u062a\\u06be\\u0631\\u06cc \\u062c\\u0648 \\u06c1\\u06d2 \\u0648\\u06c1 \\u0628\\u06be\\u06cc \\u0641\\u06cc\\u0679\\u0633 \\u06a9\\u06cc\\u0646\\u0679\\u0648\\u0646 \\u06a9\\u06d2 \\u0644\\u0626\\u06d2 \\u06c1\\u06d2 \\u0644\\u06cc\\u06a9\\u0646 \\u062a\\u06be\\u0648\\u0691\\u0627 \\u0633\\u0627 \\u0632\\u06cc\\u0627\\u062f\\u06c1 \\u06cc\\u0644\\u0648 \\u0627\\u0646\\u0688\\u0631 \\u0679\\u0648\\u0646 \\u06c1\\u06d2 \\u062f\\u0648\\u0646\\u0648\\u06ba \\u0645\\u06cc\\u06ba \\u062f\\u0648\\u0646\\u0648\\u06ba \\u06a9\\u0648 \\u0645\\u06a9\\u0633 \\u06a9\\u0631\\u06a9\\u06d2 \\u0645\\u06cc\\u06ba \\u0627\\u067e\\u0646\\u06d2 \\u0641\\u06cc\\u0633 \\u067e\\u0631 \\u0627\\u067e\\u0644\\u0627\\u0626\\u06cc \\u06a9\\u0631\\u062a\\u06cc \\u06c1\\u0648\\u06ba \\u0627\\u0633 \\u06a9\\u0627 \\u0679\\u06cc\\u06a9\\u0633\\u0686\\u0631 \\u062c\\u0648 \\u06c1\\u06d2 \\u0648\\u06c1 \\u0633\\u0648\\u067e\\u0631 \\u0633\\u0648\\u067e\\u0631 \\u0633\\u0648\\u067e\\u0631 \\u06a9\\u0631\\u06cc\\u0645\\u06cc \\u06c1\\u06d2 \\u0627\\u06cc\\u0646\\u0688 \\u06cc\\u06c1 \\u06a9\\u0644\\u06cc\\u0645 \\u06a9\\u0631\\u062a\\u0627 \\u06c1\\u06d2 \\u06a9\\u06c1 \\u06cc\\u06c1 \\u0627\\u067e \\u06a9\\u0648 \\u0641\\u0644 \\u06a9\\u0648\\u0631\\u06cc\\u062c \\u062f\\u06cc\\u062a\\u0627 \\u06c1\\u06d2 \\u062c\\u0648 \\u0627\\u0628\\u06be\\u06cc \\u062f\\u06cc\\u06a9\\u06be\\u06cc\\u06ba \\u06af\\u06d2 \\u06c1\\u0645 \\u0627\\u067e\\u0644\\u06cc\\u06a9\\u06cc\\u0634\\u0646 \\u06a9\\u06d2 \\u062f\\u0648\\u0631\\u0627\\u0646 \\u062a\\u0648 \\u062f\\u0648\\u0646\\u0648\\u06ba \\u06a9\\u0633 \\u0648\\u0627\\u0686\\u0632 \\u0645\\u06cc\\u06ba \\u0627\\u0628\\u06be\\u06cc \\u0627\\u067e \\u06a9\\u0648 \\u062f\\u06a9\\u06be\\u0627 \\u062f\\u06cc\\u062a\\u06cc \\u06c1\\u0648\\u06ba \\u062a\\u0648 \\u06cc\\u06c1 \\u0648\\u0627\\u0644\\u0627 \\u0634\\u0639\\u0631 \\u062c\\u0648 \\u06c1\\u06d2 \\u0627\\u0633 \\u0645\\u06cc\\u06ba \\u0627\\u067e \\u06a9\\u0648 \\u0645\\u0644\\u06cc\\u06ba \\u06af\\u06d2 \\u0679\\u0648\\u0679\\u0644 24 \\u0634\\u06cc\\u0631\\u0632 \\u0644\\u0627\\u0626\\u06a9 \\u0644\\u0627\\u0626\\u0679 \\u0633\\u06d2 \\u0644\\u06d2 \\u06a9\\u0631 \\u0688\\u0627\\u06a9\\u0679\\u0631 \\u0634\\u06cc\\u0688\\u0632 \\u0627\\u067e \\u06a9\\u0648 \\u0645\\u0644\\u06cc\\u06ba \\u06af\\u06d2 \\u0627\\u0633 \\u0645\\u06cc\\u06ba \\u0627\\u0648\\u06cc\\u0644\\u06cc\\u0628\\u0644 \\u06c1\\u06d2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_positions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[1, 8, 18, 24, 84, 88, 89, 106]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_positions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[18, 32, 55, 61, 65, 67, 121]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**Extracting Frames from Video**"],"metadata":{"id":"Bp44lnLtUwK0"}},{"cell_type":"code","source":["import cv2\n","import pandas as pd\n","import os\n","\n","# Video file path\n","video_file_path = '/content/drive/MyDrive/Use_Case/test_video/Test.mp4'\n","video_name = os.path.basename(video_file_path).split('.')[0]  # Extract name without extension\n","\n","# Create a folder to store frames if it doesn't exist\n","output_folder = f'/content/drive/MyDrive/Use_Case/Frames/{video_name}'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Load positions from the CSV file\n","csv_file_path = '/content/drive/MyDrive/Use_Case/transcription/Test.csv'\n","df = pd.read_csv(csv_file_path)\n","\n","# Convert positions to lists of integers\n","negative_positions = eval(df['negative_positions'][0])\n","positive_positions = eval(df['positive_positions'][0])\n","\n","# Initialize video capture\n","cap = cv2.VideoCapture(video_file_path)\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","duration = frame_count / fps\n","\n","frame_info = []  # List to store frame information\n","\n","# Extract frames\n","for sec in range(int(duration) + 1):\n","    cap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    frame_filename = os.path.join(output_folder, f'{video_name}_frame_{sec}.jpg')\n","    cv2.imwrite(frame_filename, frame)\n","\n","    # Determine if the frame is negative or positive\n","    is_in_Dictionary = 'Y' if sec in negative_positions else 'N'\n","    is_in_Dictionary = 'Y' if sec in positive_positions else 'N'\n","\n","    frame_info.append({\n","        'Video Name': video_name,\n","        'Frame Path': frame_filename,\n","        'Time in Seconds': sec,\n","        'Key_Frame': is_in_Dictionary\n","    })\n","\n","# Release video capture object\n","cap.release()\n","\n","# Save frame information to a new CSV file\n","frame_info_df = pd.DataFrame(frame_info)\n","frames_csv_path = f'/content/drive/MyDrive/Use_Case/frames_path/{video_name}_frames_info.csv'\n","frame_info_df.to_csv(frames_csv_path, index=False)\n","\n","print(\"Frames extracted and saved in\", output_folder)\n","print(f\"Frame information saved to {frames_csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZVrCo2dUy_N","outputId":"bbe78e49-aa8e-4f5e-d723-bf589a03e616"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Frames extracted and saved in /content/drive/MyDrive/Use_Case/Frames/Test\n","Frame information saved to /content/drive/MyDrive/Use_Case/frames_path/Test_frames_info.csv\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/frames_path/Test_frames_info.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"0ClngzXDWVIv","outputId":"715cc2e7-eab5-4161-926e-5f9ec2b3cfbc","executionInfo":{"status":"ok","timestamp":1716789619366,"user_tz":-300,"elapsed":1011,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Video Name                                         Frame Path  \\\n","0       Test  /content/drive/MyDrive/Use_Case/Frames/Test/Te...   \n","1       Test  /content/drive/MyDrive/Use_Case/Frames/Test/Te...   \n","2       Test  /content/drive/MyDrive/Use_Case/Frames/Test/Te...   \n","3       Test  /content/drive/MyDrive/Use_Case/Frames/Test/Te...   \n","4       Test  /content/drive/MyDrive/Use_Case/Frames/Test/Te...   \n","\n","   Time in Seconds Key_Frame  \n","0                0         N  \n","1                1         N  \n","2                2         N  \n","3                3         N  \n","4                4         N  "],"text/html":["\n","  <div id=\"df-06a80a87-c7c7-44bb-a6bd-7a1cd0c6cb4b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video Name</th>\n","      <th>Frame Path</th>\n","      <th>Time in Seconds</th>\n","      <th>Key_Frame</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test</td>\n","      <td>/content/drive/MyDrive/Use_Case/Frames/Test/Te...</td>\n","      <td>0</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test</td>\n","      <td>/content/drive/MyDrive/Use_Case/Frames/Test/Te...</td>\n","      <td>1</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test</td>\n","      <td>/content/drive/MyDrive/Use_Case/Frames/Test/Te...</td>\n","      <td>2</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Test</td>\n","      <td>/content/drive/MyDrive/Use_Case/Frames/Test/Te...</td>\n","      <td>3</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Test</td>\n","      <td>/content/drive/MyDrive/Use_Case/Frames/Test/Te...</td>\n","      <td>4</td>\n","      <td>N</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06a80a87-c7c7-44bb-a6bd-7a1cd0c6cb4b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-06a80a87-c7c7-44bb-a6bd-7a1cd0c6cb4b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-06a80a87-c7c7-44bb-a6bd-7a1cd0c6cb4b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cf81ee15-a22e-4b1f-ace7-bf394e41af04\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf81ee15-a22e-4b1f-ace7-bf394e41af04')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cf81ee15-a22e-4b1f-ace7-bf394e41af04 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 122,\n  \"fields\": [\n    {\n      \"column\": \"Video Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frame Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 122,\n        \"samples\": [\n          \"/content/drive/MyDrive/Use_Case/Frames/Test/Test_frame_18.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time in Seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 0,\n        \"max\": 121,\n        \"num_unique_values\": 122,\n        \"samples\": [\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Key_Frame\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["**Text Model 1**"],"metadata":{"id":"dNJ0tZYwW4_a"}},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n","import numpy as np\n","import speech_recognition as sr\n","from sklearn.preprocessing import LabelEncoder\n","import os\n","import pandas as pd\n","\n","# Function to transcribe audio to text using Google Speech Recognition\n","def transcribe_audio(audio_path, language=\"ur-PK\"):\n","    recognizer = sr.Recognizer()\n","    audio_file = sr.AudioFile(audio_path)\n","    with audio_file as source:\n","        audio_data = recognizer.record(source)\n","    try:\n","        transcript = recognizer.recognize_google(audio_data, language=language)\n","        return transcript\n","    except sr.UnknownValueError:\n","        return \"Google Speech Recognition could not understand the audio\"\n","    except sr.RequestError as e:\n","        return f\"Could not request results from Google Speech Recognition service; {e}\"\n","\n","# Path to the new audio file\n","new_audio_path = '/content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav'\n","\n","# Transcribe the audio file\n","transcribed_text = transcribe_audio(new_audio_path)\n","\n","# Print the transcribed text\n","print(\"Transcribed Text:\", transcribed_text)\n","\n","# Load the saved BERT model and tokenizer\n","model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model'\n","tokenizer = BertTokenizer.from_pretrained(model_path)\n","model = BertForSequenceClassification.from_pretrained(model_path)\n","\n","# Tokenize the transcribed text\n","encoded_dict = tokenizer.encode_plus(\n","    transcribed_text,\n","    add_special_tokens=True,\n","    max_length=64,\n","    truncation=True,\n","    padding='max_length',\n","    return_attention_mask=True,\n","    return_tensors='pt'\n",")\n","\n","input_ids = encoded_dict['input_ids']\n","attention_masks = encoded_dict['attention_mask']\n","\n","# Create DataLoader for the transcribed text\n","dataset = TensorDataset(input_ids, attention_masks)\n","dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=1)\n","\n","# Prediction function\n","def predict(model, dataloader):\n","    model.eval()\n","    predictions = []\n","\n","    for batch in dataloader:\n","        batch = tuple(t.to('cpu') for t in batch)\n","        inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            logits = outputs[0]\n","        logits = logits.detach().cpu().numpy()\n","        predictions.append(logits)\n","\n","    return predictions\n","\n","# Get predictions for the transcribed text\n","predictions = predict(model, dataloader)\n","\n","# Get the predicted sentiment label\n","predicted_label = np.argmax(predictions, axis=2).flatten()\n","\n","# Map the label back to the sentiment\n","label_encoder = LabelEncoder()\n","label_encoder.fit(['Neutral', 'Positive', 'Negative'])  # Use the same labels used during training\n","predicted_sentiment = label_encoder.inverse_transform(predicted_label)\n","\n","print(f\"Predicted Sentiment: {predicted_sentiment[0]}\")\n","\n","# Save the prediction into a CSV file with the required columns\n","output_data = {\n","    'file': [os.path.basename(new_audio_path)],\n","    'modality': ['T'],\n","    'senti': [predicted_sentiment[0]],\n","    'Model1': [predicted_sentiment[0]],\n","    'Model2': [''],\n","    'Model3': ['']\n","}\n","\n","output_df = pd.DataFrame(output_data)\n","\n","# Define the output CSV file path\n","output_csv_path = '/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv'\n","output_df.to_csv(output_csv_path, index=False)\n","\n","print(f\"Prediction saved to {output_csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzFkqBDCRTWu","outputId":"f23e9673-1ce0-4f06-993f-dd2ad9138811","executionInfo":{"status":"ok","timestamp":1716790935078,"user_tz":-300,"elapsed":44777,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transcribed Text: سب سے پہلے ہم بات کریں گے اس کی پیکیجنگ کی پیکیجنگ کچھ اس طرح سے ہے روز گولڈ از مائی کمزوری لائک دس کلر ائی لو دس کلر گلاس پیکیجنگ ہے اس کی اس میں اپ کو ملے گی ٹوٹل 32 ایم ایل فاؤنڈیشن اس میں کوئی پمپ اویلیبل نہیں ہے اتا ہے یہ کچھ اس طرح سے دو فٹ ایپلیکیشن میں وچ از ہیوج لائک ہم کہہ سکتے ہیں کہ یہ ٹارچ فاؤنڈیشن کی جو ہے ڈیو ہے اس کا جو کنسیلر ہے وہ اس کا منی ورژن ہے ریڈ می شو یو سو یہ ہے کنسیلر اور یہ ہے فاؤنڈیشن دونوں کی پیکیجنگ سیم سیم ہے اور اس کا کینسل اینڈ ڈیفائن فاؤنڈیشن اس میں بھی ہے ایپلیکیشن کا کلر ڈارک ہے کیونکہ یہ میں نے کنٹورنگ کے لیے لیا تھا اس میں بھی ایپلیکیشن موجود ہے دو فٹ ایپلیکیشن جس سے بہت ایزیلی سے اپلائی ہو جاتی ہے فاؤنڈیشن بھی اور کنسیلر بھی فاؤنڈیشن تو یہ ہے ٹھیک ہے تو اس کی جو پرائز ہے 950 سمتھنگ یہ بہت سستا تھا پہلے 850 ورڈ عمران خان سلام اپ کو لائک پرائزز سو اس کی جو پرائز ہے یہ 12 ہے یو ایس میں بڑی یہاں پے یہ اپ کو ملے گا 2000 رز میں سو جو ایف ٹو شیڈ ہے وہ ہے فیرس اسکین ٹون کے لئے ود لائٹ ییلو انڈر ٹون لیکن ایف تھری جو ہے وہ بھی فیئر سکن ٹون کے لئے ہے لیکن تھوڑا سا زیادہ یلو انڈر ٹون ہے دونوں میں دونوں کو مکس کرکے میں اپنے فیس پر اپلائی کرتی ہوں اس کا ٹیکسچر جو ہے وہ سوپر سوپر سوپر کریمی ہے اینڈ یہ کلیم کرتا ہے کہ یہ اپ کو فل کوریج دیتا ہے جو ابھی دیکھیں گے ہم اپلیکیشن کے دوران تو دونوں کس واچز میں ابھی اپ کو دکھا دیتی ہوں تو یہ والا شعر جو ہے اس میں اپ کو ملیں گے ٹوٹل 24 شیرز لائک لائٹ سے لے کر ڈاکٹر شیڈز اپ کو ملیں گے اس میں اویلیبل ہے\n","Predicted Sentiment: Positive\n","Prediction saved to /content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"6Q2uRDelv06D","outputId":"d7981b96-9f53-4d79-e1a1-ce08703bf9a3","executionInfo":{"status":"ok","timestamp":1716790935078,"user_tz":-300,"elapsed":5,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file modality     senti    Model1  Model2  Model3\n","0  Test.wav        T  Positive  Positive     NaN     NaN"],"text/html":["\n","  <div id=\"df-a8f1d939-5d70-4c2e-849f-22e587a92611\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>modality</th>\n","      <th>senti</th>\n","      <th>Model1</th>\n","      <th>Model2</th>\n","      <th>Model3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test.wav</td>\n","      <td>T</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8f1d939-5d70-4c2e-849f-22e587a92611')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a8f1d939-5d70-4c2e-849f-22e587a92611 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a8f1d939-5d70-4c2e-849f-22e587a92611');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senti\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["**Text Model 2**"],"metadata":{"id":"dhQNXJWVXBMk"}},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n","import numpy as np\n","import speech_recognition as sr\n","from sklearn.preprocessing import LabelEncoder\n","import os\n","import pandas as pd\n","import joblib\n","\n","# Define custom tokenizer function\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Function to transcribe audio to text using Google Speech Recognition\n","def transcribe_audio(audio_path, language=\"ur-PK\"):\n","    recognizer = sr.Recognizer()\n","    audio_file = sr.AudioFile(audio_path)\n","    with audio_file as source:\n","        audio_data = recognizer.record(source)\n","    try:\n","        transcript = recognizer.recognize_google(audio_data, language=language)\n","        return transcript\n","    except sr.UnknownValueError:\n","        return \"Google Speech Recognition could not understand the audio\"\n","    except sr.RequestError as e:\n","        return f\"Could not request results from Google Speech Recognition service; {e}\"\n","\n","# Path to the new audio file\n","new_audio_path = '/content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav'\n","\n","# Transcribe the audio file\n","transcribed_text = transcribe_audio(new_audio_path)\n","\n","# Print the transcribed text\n","print(\"Transcribed Text:\", transcribed_text)\n","\n","# Load the saved BERT model and tokenizer\n","bert_model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model'\n","tokenizer = BertTokenizer.from_pretrained(bert_model_path)\n","bert_model = BertForSequenceClassification.from_pretrained(bert_model_path)\n","\n","# Tokenize the transcribed text\n","encoded_dict = tokenizer.encode_plus(\n","    transcribed_text,\n","    add_special_tokens=True,\n","    max_length=64,\n","    truncation=True,\n","    padding='max_length',\n","    return_attention_mask=True,\n","    return_tensors='pt'\n",")\n","\n","input_ids = encoded_dict['input_ids']\n","attention_masks = encoded_dict['attention_mask']\n","\n","# Create DataLoader for the transcribed text\n","dataset = TensorDataset(input_ids, attention_masks)\n","dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=1)\n","\n","# Prediction function for BERT model\n","def predict_bert(model, dataloader):\n","    model.eval()\n","    predictions = []\n","\n","    for batch in dataloader:\n","        batch = tuple(t.to('cpu') for t in batch)\n","        inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            logits = outputs[0]\n","        logits = logits.detach().cpu().numpy()\n","        predictions.append(logits)\n","\n","    return predictions\n","\n","# Get predictions for the transcribed text using BERT model\n","bert_predictions = predict_bert(bert_model, dataloader)\n","bert_predicted_label = np.argmax(bert_predictions, axis=2).flatten()\n","label_encoder = LabelEncoder()\n","label_encoder.fit(['Neutral', 'Positive', 'Negative'])  # Use the same labels used during training\n","bert_predicted_sentiment = label_encoder.inverse_transform(bert_predicted_label)\n","\n","# Load Logistic Regression models and vectorizers\n","lr_bow_model = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl')\n","lr_tfidf_model = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_3_logistic_regression_tfidf.pkl')\n","\n","# Define the custom tokenizer function again for loading the vectorizers\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Load vectorizers\n","bow_vectorizer = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl')\n","tfidf_vectorizer = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_3_tfidf_vectorizer.pkl')\n","\n","# Vectorize the transcribed text using BoW and TF-IDF vectorizers\n","transcribed_text_bow = bow_vectorizer.transform([transcribed_text])\n","transcribed_text_tfidf = tfidf_vectorizer.transform(transcribed_text_bow)\n","\n","# Predict using Logistic Regression models\n","bow_predicted_label = lr_bow_model.predict(transcribed_text_bow)\n","tfidf_predicted_label = lr_tfidf_model.predict(transcribed_text_tfidf)\n","\n","# Map the labels back to the sentiment\n","bow_predicted_sentiment = label_encoder.inverse_transform(bow_predicted_label)\n","tfidf_predicted_sentiment = label_encoder.inverse_transform(tfidf_predicted_label)\n","\n","# Print the predicted sentiments\n","print(f\"BERT Predicted Sentiment: {bert_predicted_sentiment[0]}\")\n","print(f\"BoW Logistic Regression Predicted Sentiment: {bow_predicted_sentiment[0]}\")\n","print(f\"TF-IDF Logistic Regression Predicted Sentiment: {tfidf_predicted_sentiment[0]}\")\n","\n","# Load the existing CSV file or create a new one if it doesn't exist\n","output_csv_path = '/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv'\n","if os.path.exists(output_csv_path):\n","    df_main = pd.read_csv(output_csv_path)\n","else:\n","    df_main = pd.DataFrame(columns=['file', 'modality', 'senti', 'Model1', 'Model2', 'Model3'])\n","\n","# Add new row for text modality if it doesn't exist\n","filename = os.path.basename(new_audio_path)\n","row_index = df_main[(df_main['file'] == filename) & (df_main['modality'] == 'T')].index\n","\n","if row_index.empty:\n","    new_row = {\n","        'file': filename,\n","        'modality': 'T',\n","        'senti': bert_predicted_sentiment[0],\n","        'Model1': bert_predicted_sentiment[0],\n","        'Model2': bow_predicted_sentiment[0],\n","        'Model3': tfidf_predicted_sentiment[0]\n","    }\n","    df_main = pd.concat([df_main, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n","else:\n","    # Update the row with new predictions\n","    df_main.at[row_index[0], 'Model2'] = bow_predicted_sentiment[0]\n","    df_main.at[row_index[0], 'Model3'] = tfidf_predicted_sentiment[0]\n","\n","# Save the updated DataFrame back to the CSV file\n","df_main.to_csv(output_csv_path, index=False)\n","\n","print(f\"Predictions saved to {output_csv_path}\")\n"],"metadata":{"id":"6h8uaQ-ZXD_4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716790971681,"user_tz":-300,"elapsed":36607,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"e268dab7-1ba0-489a-b51a-e0046278c573"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transcribed Text: سب سے پہلے ہم بات کریں گے اس کی پیکیجنگ کی پیکیجنگ کچھ اس طرح سے ہے روز گولڈ از مائی کمزوری لائک دس کلر ائی لو دس کلر گلاس پیکیجنگ ہے اس کی اس میں اپ کو ملے گی ٹوٹل 32 ایم ایل فاؤنڈیشن اس میں کوئی پمپ اویلیبل نہیں ہے اتا ہے یہ کچھ اس طرح سے دو فٹ ایپلیکیشن میں وچ از ہیوج لائک ہم کہہ سکتے ہیں کہ یہ ٹارچ فاؤنڈیشن کی جو ہے ڈیو ہے اس کا جو کنسیلر ہے وہ اس کا منی ورژن ہے ریڈ می شو یو سو یہ ہے کنسیلر اور یہ ہے فاؤنڈیشن دونوں کی پیکیجنگ سیم سیم ہے اور اس کا کینسل اینڈ ڈیفائن فاؤنڈیشن اس میں بھی ہے ایپلیکیشن کا کلر ڈارک ہے کیونکہ یہ میں نے کنٹورنگ کے لیے لیا تھا اس میں بھی ایپلیکیشن موجود ہے دو فٹ ایپلیکیشن جس سے بہت ایزیلی سے اپلائی ہو جاتی ہے فاؤنڈیشن بھی اور کنسیلر بھی فاؤنڈیشن تو یہ ہے ٹھیک ہے تو اس کی جو پرائز ہے 950 سمتھنگ یہ بہت سستا تھا پہلے 850 ورڈ عمران خان سلام اپ کو لائک پرائزز سو اس کی جو پرائز ہے یہ 12 ہے یو ایس میں بڑی یہاں پے یہ اپ کو ملے گا 2000 رز میں سو جو ایف ٹو شیڈ ہے وہ ہے فیرس اسکین ٹون کے لئے ود لائٹ ییلو انڈر ٹون لیکن ایف تھری جو ہے وہ بھی فیئر سکن ٹون کے لئے ہے لیکن تھوڑا سا زیادہ یلو انڈر ٹون ہے دونوں میں دونوں کو مکس کرکے میں اپنے فیس پر اپلائی کرتی ہوں اس کا ٹیکسچر جو ہے وہ سوپر سوپر سوپر کریمی ہے اینڈ یہ کلیم کرتا ہے کہ یہ اپ کو فل کوریج دیتا ہے جو ابھی دیکھیں گے ہم اپلیکیشن کے دوران تو دونوں کس واچز میں ابھی اپ کو دکھا دیتی ہوں تو یہ والا شعر جو ہے اس میں اپ کو ملیں گے ٹوٹل 24 شیرز لائک لائٹ سے لے کر ڈاکٹر شیڈز اپ کو ملیں گے اس میں اویلیبل ہے\n","BERT Predicted Sentiment: Positive\n","BoW Logistic Regression Predicted Sentiment: Positive\n","TF-IDF Logistic Regression Predicted Sentiment: Positive\n","Predictions saved to /content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"1MGgl1q6bE9h","executionInfo":{"status":"ok","timestamp":1716791059698,"user_tz":-300,"elapsed":428,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"c45c8cd6-568d-4e98-e9a0-176a0c30940e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file modality     senti    Model1    Model2    Model3\n","0  Test.wav        T  Positive  Positive  Positive  Positive"],"text/html":["\n","  <div id=\"df-d1a26d35-d796-4f50-a04b-b28e06e83734\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>modality</th>\n","      <th>senti</th>\n","      <th>Model1</th>\n","      <th>Model2</th>\n","      <th>Model3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test.wav</td>\n","      <td>T</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1a26d35-d796-4f50-a04b-b28e06e83734')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d1a26d35-d796-4f50-a04b-b28e06e83734 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d1a26d35-d796-4f50-a04b-b28e06e83734');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senti\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["**Video Model 1**"],"metadata":{"id":"eYAGKI_zvW--"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","import os\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    img = cv2.imread(filepath)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img, (224, 224))  # Resize to match MobileNetV2 input\n","    img = preprocess_input(img)  # Preprocess as per MobileNetV2 requirements\n","    return img\n","\n","# Load the saved model\n","model_path = '/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_1_CNN_with_MobileNetV2.h5'\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# Load the new frames CSV file\n","frames_csv_path = '/content/drive/MyDrive/Use_Case/frames_path/Test_frames_info.csv'\n","df_frames = pd.read_csv(frames_csv_path)\n","\n","# Apply preprocessing to each image and prepare for prediction\n","images = np.array([preprocess_image(fp) for fp in df_frames['Frame Path']])\n","\n","# Make predictions using the loaded model\n","predictions = loaded_model.predict(images)\n","\n","# Convert one-hot encoded predictions to class labels\n","predicted_labels = np.argmax(predictions, axis=1)\n","\n","# Add predictions to the DataFrame\n","df_frames['Predicted Sentiment'] = predicted_labels\n","\n","# Save the updated DataFrame to a new CSV file\n","predictions_csv_path = '/content/drive/MyDrive/Use_Case/frames_path/Use_Case2_with_all_models_predictions_1_mobilenet.csv'\n","df_frames.to_csv(predictions_csv_path, index=False)\n","\n","print(\"Predictions saved to\", predictions_csv_path)\n","\n","# Determine the overall sentiment for the MobileNetV2 model\n","most_repeated_values = df_frames['Predicted Sentiment'].value_counts().reindex([0, 1, 2], fill_value=0)\n","if most_repeated_values.idxmax() == 0:\n","    Senti = \"Neutral\"\n","elif most_repeated_values.idxmax() == 1:\n","    Senti = \"Positive\"\n","elif most_repeated_values.idxmax() == 2:\n","    Senti = \"Negative\"\n","\n","# Load the main CSV file\n","main_csv_path = '/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv'\n","df_main = pd.read_csv(main_csv_path)\n","\n","# Add new row for video modality if it doesn't exist\n","filename = 'Test.wav'\n","if df_main[(df_main['file'] == filename) & (df_main['modality'] == 'V')].empty:\n","    new_row = pd.DataFrame({'file': [filename], 'modality': ['V'], 'senti': [Senti], 'Model1': [Senti], 'Model2': [''], 'Model3': ['']})\n","    df_main = pd.concat([df_main, new_row], ignore_index=True)\n","else:\n","    # Update 'Model1' column value\n","    df_main.loc[(df_main['file'] == filename) & (df_main['modality'] == 'V'), 'Model1'] = Senti\n","\n","# Save the updated DataFrame back to the CSV file\n","df_main.to_csv(main_csv_path, index=False)\n","print(f\"Updated 'Model1' column for file {filename} with sentiment {Senti}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzfe27iXvaGw","outputId":"da91d4ba-ccc2-4ec6-f69e-2829772ba057","executionInfo":{"status":"ok","timestamp":1716182473979,"user_tz":-300,"elapsed":62818,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 5s 883ms/step\n","Predictions saved to /content/drive/MyDrive/Use_Case/frames_path/Use_Case2_with_all_models_predictions_1_mobilenet.csv\n","Updated 'Model1' column for file Test.wav with sentiment Positive.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PqNsH30KxVrB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"2i0s6A_RxMqI","outputId":"5eefd2e8-581d-45f6-803c-d6fea5eb2dab","executionInfo":{"status":"ok","timestamp":1716182496015,"user_tz":-300,"elapsed":1356,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file modality     senti    Model1    Model2    Model3\n","0  Test.wav        T  Positive  Positive  Positive  Positive\n","1  Test.wav        V  Positive  Positive       NaN       NaN"],"text/html":["\n","  <div id=\"df-b310a917-b4b8-4063-9351-3a3a517a340c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>modality</th>\n","      <th>senti</th>\n","      <th>Model1</th>\n","      <th>Model2</th>\n","      <th>Model3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test.wav</td>\n","      <td>T</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test.wav</td>\n","      <td>V</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b310a917-b4b8-4063-9351-3a3a517a340c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b310a917-b4b8-4063-9351-3a3a517a340c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b310a917-b4b8-4063-9351-3a3a517a340c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0fce7faf-4fd3-4040-8246-822cb798889c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fce7faf-4fd3-4040-8246-822cb798889c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0fce7faf-4fd3-4040-8246-822cb798889c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"V\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senti\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["**Video Model 2**"],"metadata":{"id":"w-Z_PTqoxW3X"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import joblib\n","from skimage.feature import hog\n","import os\n","\n","# Function to preprocess images\n","def preprocess_image(filepath):\n","    img = cv2.imread(filepath)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = cv2.resize(img, (48, 48))\n","    img = cv2.equalizeHist(img)\n","    return img\n","\n","# Load the model\n","model_path = \"/content/drive/MyDrive/work2/Final/Image_Models/Video_Model_2_random_forest_model.pkl\"\n","loaded_rf_model = joblib.load(model_path)\n","\n","# Load the new frames CSV file\n","frames_csv_path = '/content/drive/MyDrive/Use_Case/frames_path/Test_frames_info.csv'\n","df_frames = pd.read_csv(frames_csv_path)\n","\n","# Apply preprocessing to each image and prepare for prediction\n","images = np.array([preprocess_image(fp) for fp in df_frames['Frame Path']])\n","\n","# Extract HOG features from the images\n","hog_features = [hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys') for image in images]\n","\n","# Predict using the loaded model\n","y_pred = loaded_rf_model.predict(hog_features)\n","\n","# Save the predictions in the DataFrame\n","df_frames['Predicted Sentiment'] = y_pred\n","\n","# Save the updated DataFrame to a new CSV file\n","predictions_csv_path = '/content/drive/MyDrive/Use_Case/frames_path/Use_Case2_with_all_models_random_forest_on_1.csv'\n","df_frames.to_csv(predictions_csv_path, index=False)\n","\n","print(\"Predictions saved to\", predictions_csv_path)\n","\n","# Load the CSV file\n","df = pd.read_csv(predictions_csv_path)\n","\n","# Get the most repeated values in 'Predicted Sentiment'\n","most_repeated_values = df['Predicted Sentiment'].value_counts()\n","print(most_repeated_values)\n","\n","# Determine the overall sentiment\n","if most_repeated_values.idxmax() == 0:\n","    Senti = \"Neutral\"\n","elif most_repeated_values.idxmax() == 1:\n","    Senti = \"Positive\"\n","elif most_repeated_values.idxmax() == 2:\n","    Senti = \"Negative\"\n","\n","# Load the main CSV file\n","main_csv_path = '/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv'\n","df_main = pd.read_csv(main_csv_path)\n","\n","# Add new row for video modality if it doesn't exist\n","filename = 'Test.wav'\n","if df_main[(df_main['file'] == filename) & (df_main['modality'] == 'V')].empty:\n","    new_row = pd.DataFrame({'file': [filename], 'modality': ['V'], 'senti': [Senti], 'Model1': [''], 'Model2': [Senti], 'Model3': ['']})\n","    df_main = pd.concat([df_main, new_row], ignore_index=True)\n","else:\n","    # Update 'Model2' column value\n","    df_main.loc[(df_main['file'] == filename) & (df_main['modality'] == 'V'), 'Model2'] = Senti\n","\n","# Save the updated DataFrame back to the CSV file\n","df_main.to_csv(main_csv_path, index=False)\n","print(f\"Updated 'Model2' column for file {filename} with sentiment {Senti}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYSU9qW3xZfi","outputId":"041fda51-ec76-4940-8ed3-9c2a06faabb9","executionInfo":{"status":"ok","timestamp":1716182605763,"user_tz":-300,"elapsed":14019,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions saved to /content/drive/MyDrive/Use_Case/frames_path/Use_Case2_with_all_models_random_forest_on_1.csv\n","Predicted Sentiment\n","2    59\n","0    57\n","1     6\n","Name: count, dtype: int64\n","Updated 'Model2' column for file Test.wav with sentiment Negative.\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"Bc6GekNEyLT4","outputId":"1797b667-6d91-4eb3-a7da-67a902b79966","executionInfo":{"status":"ok","timestamp":1716182624521,"user_tz":-300,"elapsed":372,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file modality     senti    Model1    Model2    Model3\n","0  Test.wav        T  Positive  Positive  Positive  Positive\n","1  Test.wav        V  Positive  Positive  Negative       NaN"],"text/html":["\n","  <div id=\"df-a0611e9c-afa7-410c-8d0b-5ac8a72c3f01\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>modality</th>\n","      <th>senti</th>\n","      <th>Model1</th>\n","      <th>Model2</th>\n","      <th>Model3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test.wav</td>\n","      <td>T</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test.wav</td>\n","      <td>V</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Negative</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0611e9c-afa7-410c-8d0b-5ac8a72c3f01')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a0611e9c-afa7-410c-8d0b-5ac8a72c3f01 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a0611e9c-afa7-410c-8d0b-5ac8a72c3f01');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f77efb9e-223d-4433-9477-86c0d66711fd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f77efb9e-223d-4433-9477-86c0d66711fd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f77efb9e-223d-4433-9477-86c0d66711fd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"V\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senti\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["**Audio Model 1**"],"metadata":{"id":"wnEtpbJUyoa3"}},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","import tensorflow as tf\n","import joblib\n","from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","import os\n","\n","# Function to extract features from audio files\n","def extract_features(file_path):\n","    y, sr = librosa.load(file_path, duration=3)\n","    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n","    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n","    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n","    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n","    features = np.mean(np.concatenate((mfccs, chroma, mel, contrast), axis=0), axis=1)\n","    return features\n","\n","# Path to the saved model and scaler\n","model_path = '/content/drive/MyDrive/work2/Final/best_audio_model/best_model.h5'\n","scaler_path = '/content/drive/MyDrive/work2/Final/best_audio_model/scaler.pkl'\n","\n","# Load the saved model\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# Load the saved scaler\n","scaler = joblib.load(scaler_path)\n","\n","# Path to the new audio file\n","new_audio_path = '/content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav'\n","\n","# Extract features from the new audio file\n","new_features = extract_features(new_audio_path)\n","\n","# Standardize the features using the saved scaler\n","new_features = scaler.transform([new_features])\n","\n","# Reshape for LSTM input\n","new_features = np.expand_dims(new_features, -1)\n","\n","# Make predictions using the loaded model\n","prediction = loaded_model.predict(new_features)\n","\n","# Decode the prediction\n","predicted_label = np.argmax(prediction, axis=1)\n","\n","# Map the label back to the sentiment\n","label_encoder = LabelEncoder()\n","label_encoder.fit(['Neutral', 'Positive', 'Negative'])  # Use the same labels used during training\n","predicted_sentiment = label_encoder.inverse_transform(predicted_label)\n","\n","print(f\"Predicted Sentiment: {predicted_sentiment[0]}\")\n","\n","# Load the main CSV file\n","main_csv_path = '/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv'\n","if os.path.exists(main_csv_path):\n","    df_main = pd.read_csv(main_csv_path)\n","else:\n","    df_main = pd.DataFrame(columns=['file', 'modality', 'senti', 'Model1', 'Model2', 'Model3'])\n","\n","# Add new row for audio modality if it doesn't exist\n","filename = 'Test.wav'\n","if df_main[(df_main['file'] == filename) & (df_main['modality'] == 'A')].empty:\n","    new_row = pd.DataFrame({'file': [filename], 'modality': ['A'], 'senti': [predicted_sentiment[0]], 'Model1': [predicted_sentiment[0]], 'Model2': [''], 'Model3': ['']})\n","    df_main = pd.concat([df_main, new_row], ignore_index=True)\n","else:\n","    # Update 'Model1' column value\n","    df_main.loc[(df_main['file'] == filename) & (df_main['modality'] == 'A'), 'Model1'] = predicted_sentiment[0]\n","\n","# Save the updated DataFrame back to the CSV file\n","df_main.to_csv(main_csv_path, index=False)\n","print(f\"Updated 'Model1' column for file {filename} with sentiment {predicted_sentiment[0]}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgcIKVPnyuJH","outputId":"a5675b8f-6dc6-49b2-d0c6-de835f13e062","executionInfo":{"status":"ok","timestamp":1716182748653,"user_tz":-300,"elapsed":21198,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 823ms/step\n","Predicted Sentiment: Positive\n","Updated 'Model1' column for file Test.wav with sentiment Positive.\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"TGKUlT8wzk8g","outputId":"dab4de98-ef4a-4917-bac1-0e148e515cf8","executionInfo":{"status":"ok","timestamp":1716182751897,"user_tz":-300,"elapsed":360,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file modality     senti    Model1    Model2    Model3\n","0  Test.wav        T  Positive  Positive  Positive  Positive\n","1  Test.wav        V  Positive  Positive  Negative       NaN\n","2  Test.wav        A  Positive  Positive       NaN       NaN"],"text/html":["\n","  <div id=\"df-fb2502c2-a078-4412-a214-e81ee9589a29\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>modality</th>\n","      <th>senti</th>\n","      <th>Model1</th>\n","      <th>Model2</th>\n","      <th>Model3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test.wav</td>\n","      <td>T</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Test.wav</td>\n","      <td>V</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Negative</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test.wav</td>\n","      <td>A</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb2502c2-a078-4412-a214-e81ee9589a29')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fb2502c2-a078-4412-a214-e81ee9589a29 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fb2502c2-a078-4412-a214-e81ee9589a29');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1b54509c-778d-4987-9964-a83a871dea7a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b54509c-778d-4987-9964-a83a871dea7a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1b54509c-778d-4987-9964-a83a871dea7a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senti\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["**Audio Model 2**"],"metadata":{"id":"QzNQXSVTyrGW"}},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","import tensorflow as tf\n","import joblib\n","import pandas as pd\n","import os\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Function to extract features from audio files\n","def extract_features(file_path):\n","    y, sr = librosa.load(file_path, duration=3)\n","    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n","    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n","    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n","    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n","    features = np.mean(np.concatenate((mfccs, chroma, mel, contrast), axis=0), axis=1)\n","    return features\n","\n","# Path to the saved model and scaler\n","model_path = '/content/drive/MyDrive/work2/Final/audio_models/Audio_sentiment.h5'\n","scaler_path = '/content/drive/MyDrive/work2/Final/audio_models/scaler.pkl'\n","\n","# Load the saved model\n","loaded_model = tf.keras.models.load_model(model_path)\n","\n","# Load the saved scaler\n","scaler = joblib.load(scaler_path)\n","\n","# Path to the new audio file\n","new_audio_path = '/content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav'\n","\n","# Extract features from the new audio file\n","new_features = extract_features(new_audio_path)\n","\n","# Standardize the features using the saved scaler\n","new_features = scaler.transform([new_features])\n","\n","# Reshape for LSTM input\n","new_features = np.expand_dims(new_features, -1)\n","\n","# Make predictions using the loaded model\n","prediction = loaded_model.predict(new_features)\n","\n","# Decode the prediction\n","predicted_label = np.argmax(prediction, axis=1)\n","\n","# Map the label back to the sentiment\n","label_encoder = LabelEncoder()\n","label_encoder.fit(['Neutral', 'Positive', 'Negative'])  # Use the same labels used during training\n","predicted_sentiment = label_encoder.inverse_transform(predicted_label)\n","\n","print(f\"Predicted Sentiment: {predicted_sentiment[0]}\")\n","\n","# Define the output CSV file path\n","output_csv_path = '/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv'\n","\n","# Load the main CSV file\n","if os.path.exists(output_csv_path):\n","    df_main = pd.read_csv(output_csv_path)\n","else:\n","    df_main = pd.DataFrame(columns=['file', 'modality', 'senti', 'Model1', 'Model2', 'Model3'])\n","\n","# Find the corresponding row based on 'file' and 'modality'\n","filename = 'Test.wav'\n","row_index = df_main[(df_main['file'] == filename) & (df_main['modality'] == 'A')].index\n","\n","# Update 'Model2' column value\n","if not row_index.empty:\n","    df_main.at[row_index[0], 'Model2'] = predicted_sentiment[0]\n","else:\n","    # If the row doesn't exist, add a new row with modality 'A' and the new sentiment\n","    new_row = {\n","        'file': filename,\n","        'modality': 'A',\n","        'senti': '',  # This can be filled with appropriate value if needed\n","        'Model1': '',  # Assuming this will be filled later\n","        'Model2': predicted_sentiment[0],\n","        'Model3': ''  # Assuming this will be filled later\n","    }\n","    df_main = pd.concat([df_main, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n","\n","# Save the updated DataFrame back to the CSV file\n","df_main.to_csv(output_csv_path, index=False)\n","\n","print(f\"Updated 'Model2' column for file {filename} with sentiment {predicted_sentiment[0]}.\")\n","print(f\"Prediction saved to {output_csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaaL_xLDyuvy","outputId":"3ae03651-904a-4110-8c7c-d19f8e0e62f7","executionInfo":{"status":"ok","timestamp":1716182828684,"user_tz":-300,"elapsed":2885,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 786ms/step\n","Predicted Sentiment: Neutral\n","Updated 'Model2' column for file Test.wav with sentiment Neutral.\n","Prediction saved to /content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Use_Case/transcription/Use_Case2_with_all_models_report.csv')\n","df.head()"],"metadata":{"id":"qDXkjSw_0U0p","outputId":"77cc7f79-635c-4ac2-b897-fa206ee8b058","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1716789594238,"user_tz":-300,"elapsed":605,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file modality     senti    Model1    Model2    Model3\n","0  Test.wav        T  Positive  Positive  Positive  Positive"],"text/html":["\n","  <div id=\"df-20baae1d-0582-4668-b7b6-cae2e7c1110f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>modality</th>\n","      <th>senti</th>\n","      <th>Model1</th>\n","      <th>Model2</th>\n","      <th>Model3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test.wav</td>\n","      <td>T</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20baae1d-0582-4668-b7b6-cae2e7c1110f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-20baae1d-0582-4668-b7b6-cae2e7c1110f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-20baae1d-0582-4668-b7b6-cae2e7c1110f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senti\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["\n","df[df['file']=='Test.wav']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"c8QX2w2NeR7E","executionInfo":{"status":"ok","timestamp":1716793657093,"user_tz":-300,"elapsed":409,"user":{"displayName":"Muhammad Ayub","userId":"07918085563958052223"}},"outputId":"3a67e511-19aa-4d40-96c7-fb80d4ebcff7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       file modality     senti    Model1  Model2  Model3\n","0  Test.wav        T  Positive  Positive     NaN     NaN"],"text/html":["\n","  <div id=\"df-e5468f35-9f16-4274-90a3-300dda6067e6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>modality</th>\n","      <th>senti</th>\n","      <th>Model1</th>\n","      <th>Model2</th>\n","      <th>Model3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Test.wav</td>\n","      <td>T</td>\n","      <td>Positive</td>\n","      <td>Positive</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5468f35-9f16-4274-90a3-300dda6067e6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e5468f35-9f16-4274-90a3-300dda6067e6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e5468f35-9f16-4274-90a3-300dda6067e6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df[df['file']=='Test\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Test.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modality\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"senti\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[],"metadata":{"id":"f7kQBBzkm6dT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Test"],"metadata":{"id":"6N234Y-PuNqU"}},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n","import numpy as np\n","import pandas as pd\n","import joblib\n","from sklearn.preprocessing import LabelEncoder\n","import os\n","\n","# Load the saved BERT model and tokenizer\n","bert_model_path = '/content/drive/MyDrive/work2/Final/Text_Work/Text_model_1_BERT_Model'\n","tokenizer = BertTokenizer.from_pretrained(bert_model_path)\n","bert_model = BertForSequenceClassification.from_pretrained(bert_model_path)\n","\n","# Define custom tokenizer function\n","def custom_tokenizer(doc):\n","    return doc\n","\n","# Load BoW and TF-IDF models and vectorizers\n","lr_bow_model = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_logistic_regression_bow.pkl')\n","bow_vectorizer = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_2_bow_vectorizer.pkl')\n","lr_tfidf_model = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_3_logistic_regression_tfidf.pkl')\n","tfidf_vectorizer = joblib.load('/content/drive/MyDrive/work2/Final/Text_Work/Text_Models_2_and_3/Text_model_3_tfidf_vectorizer.pkl')\n","\n","# Function to preprocess text for BERT model\n","def preprocess_text(text, tokenizer, max_len=64):\n","    encoded_dict = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=max_len,\n","        truncation=True,\n","        padding='max_length',\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","    return encoded_dict['input_ids'], encoded_dict['attention_mask']\n","\n","# Function to predict using BERT model\n","def predict_bert(model, dataloader):\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            inputs = {'input_ids': batch[0].to('cpu'), 'attention_mask': batch[1].to('cpu')}\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            probabilities = torch.softmax(logits, dim=1).detach().cpu().numpy()\n","            predictions.append(probabilities)\n","    return np.concatenate(predictions, axis=0)\n","\n","# Path to the new audio file\n","new_audio_path = '/content/drive/MyDrive/Use_Case/test_converted_audio/Test.wav'\n","\n","# Function to transcribe audio to text using Google Speech Recognition\n","def transcribe_audio(audio_path, language=\"ur-PK\"):\n","    recognizer = sr.Recognizer()\n","    audio_file = sr.AudioFile(audio_path)\n","    with audio_file as source:\n","        audio_data = recognizer.record(source)\n","    try:\n","        transcript = recognizer.recognize_google(audio_data, language=language)\n","        return transcript\n","    except sr.UnknownValueError:\n","        return \"Google Speech Recognition could not understand the audio\"\n","    except sr.RequestError as e:\n","        return f\"Could not request results from Google Speech Recognition service; {e}\"\n","\n","# Transcribe the audio file\n","transcribed_text = transcribe_audio(new_audio_path)\n","print(\"Transcribed Text:\", transcribed_text)\n","\n","# Tokenize the transcribed text\n","input_ids, attention_masks = preprocess_text(transcribed_text, tokenizer)\n","dataset = TensorDataset(input_ids, attention_masks)\n","dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=1)\n","\n","# Get predictions for the transcribed text using BERT model\n","bert_predictions = predict_bert(bert_model, dataloader)\n","bert_predicted_label = np.argmax(bert_predictions, axis=1).flatten()\n","label_encoder = LabelEncoder()\n","label_encoder.fit(['Neutral', 'Positive', 'Negative'])  # Use the same labels used during training\n","bert_predicted_sentiment = label_encoder.inverse_transform(bert_predicted_label)[0]\n","bert_percentage = bert_predictions.max()\n","\n","# Vectorize the transcribed text using BoW and TF-IDF vectorizers\n","transcribed_text_bow = bow_vectorizer.transform([transcribed_text])\n","transcribed_text_tfidf = tfidf_vectorizer.transform([transcribed_text])\n","\n","# Predict using Logistic Regression models\n","bow_predictions = lr_bow_model.predict_proba(transcribed_text_bow)\n","bow_predicted_label = np.argmax(bow_predictions, axis=1).flatten()\n","bow_predicted_sentiment = label_encoder.inverse_transform(bow_predicted_label)[0]\n","bow_percentage = bow_predictions.max()\n","\n","tfidf_predictions = lr_tfidf_model.predict_proba(transcribed_text_tfidf)\n","tfidf_predicted_label = np.argmax(tfidf_predictions, axis=1).flatten()\n","tfidf_predicted_sentiment = label_encoder.inverse_transform(tfidf_predicted_label)[0]\n","tfidf_percentage = tfidf_predictions.max()\n","\n","# Initialize results list\n","results = []\n","\n","# Add new result for text modality\n","filename = os.path.splitext(os.path.basename(new_audio_path))[0]\n","results.append({\n","    'Senti': '',\n","    'audio file name': filename,\n","    'modality': 'T',\n","    'model1': bert_predicted_sentiment,\n","    'model 1 percentage': bert_percentage,\n","    'model2': bow_predicted_sentiment,\n","    'model 2 percentage': bow_percentage,\n","    'model3': tfidf_predicted_sentiment,\n","    'model 3 percentage': tfidf_percentage\n","})\n","\n","# Convert results to DataFrame and display\n","df_results = pd.DataFrame(results)\n","df_results.head()\n"],"metadata":{"id":"SkvG522i2p8J"},"execution_count":null,"outputs":[]}]}